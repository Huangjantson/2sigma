{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn import  preprocessing, ensemble\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.cross_validation import KFold\n",
    "import re\n",
    "import string\n",
    "from collections import defaultdict, Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#try xgboost\n",
    "#fucntion from SRK\n",
    "def runXGB(train_X, train_y, test_X, test_y=None, feature_names=None, seed_val=0, num_rounds=10000):\n",
    "    param = {}\n",
    "    param['objective'] = 'multi:softprob'\n",
    "    param['eta'] = 0.1\n",
    "    param['max_depth'] = 6\n",
    "    param['silent'] = 1\n",
    "    param['num_class'] = 3\n",
    "    param['eval_metric'] = \"mlogloss\"\n",
    "    param['min_child_weight'] = 1\n",
    "    param['subsample'] = 0.7\n",
    "    param['colsample_bytree'] = 0.7\n",
    "    param['seed'] = seed_val\n",
    "    num_rounds = num_rounds\n",
    "\n",
    "    plst = list(param.items())\n",
    "    xgtrain = xgb.DMatrix(train_X, label=train_y,feature_names=feature_names)\n",
    "\n",
    "    if test_y is not None:\n",
    "        xgtest = xgb.DMatrix(test_X, label=test_y,feature_names=feature_names)\n",
    "        watchlist = [ (xgtrain,'train'), (xgtest, 'test') ]\n",
    "        model = xgb.train(plst, xgtrain, num_rounds, watchlist, early_stopping_rounds=20)\n",
    "    else:\n",
    "        xgtest = xgb.DMatrix(test_X,feature_names=feature_names)\n",
    "        model = xgb.train(plst, xgtrain, num_rounds)\n",
    "\n",
    "    pred_test_y = model.predict(xgtest)\n",
    "    return pred_test_y, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#feature processing functions\n",
    "#define punctutaion filter\n",
    "def removePunctuation(x):\n",
    "    #filter the head or tail blanks\n",
    "    x = re.sub(r'^\\s+',r' ',x)\n",
    "    x = re.sub(r'\\s+$',r' ',x)\n",
    "    \n",
    "    # Lowercasing all words\n",
    "    x = x.lower()\n",
    "    # Removing non ASCII chars, warning if you are dealing with other languages!!!!!!!!!!!!!!!\n",
    "    x = re.sub(r'[^\\x00-\\x7f]',r' ',x)\n",
    "    #change all the blank to space\n",
    "    x = re.sub(r'\\s',r' ',x)\n",
    "    # Removing (replacing with empty spaces actually) all the punctuations\n",
    "    removing = string.punctuation#.replace('-','')# except '-'\n",
    "    removed = re.sub(\"[\"+removing+\"]\", \"\", x)\n",
    "    #removing the line-changing\n",
    "    #removed = re.sub('\\\\n',\" \",removed)    \n",
    "    return removed\n",
    "\n",
    "#feature processing functions\n",
    "def proecessStreet(address):\n",
    "    #remove the building number\n",
    "    pattern = re.compile('^[\\d-]*[\\s]+')\n",
    "    street = removePunctuation(pattern.sub('',address))\n",
    "    \n",
    "    #sub the st to street\n",
    "    pattern = re.compile('( st)$')\n",
    "    street = pattern.sub(' street',street)\n",
    "    \n",
    "    #sub the ave to avenue\n",
    "    pattern = re.compile('( ave)$')\n",
    "    street = pattern.sub(' avenue',street)\n",
    "    \n",
    "    pattern = re.compile('(\\d+)((th)|(st)|(rd)|(nd))')\n",
    "    street = pattern.sub('\\g<1>',street)\n",
    "    \n",
    "    #deal with the w 14 street => west 14 street\n",
    "    pattern = re.compile('(w)(\\s+)(\\d+)')    \n",
    "    street = pattern.sub('west \\g<3>',street)\n",
    "    \n",
    "    #deal with the e....\n",
    "    pattern = re.compile('(e)(\\s+)(\\d+)')    \n",
    "    street = pattern.sub('east \\g<3>',street)\n",
    "    \n",
    "    return street\n",
    "    \n",
    "#from \"this is a lit\"s python version by rakhlin\n",
    "def singleValueConvert(df1,df2,column,minimum_size=5):\n",
    "    ps = df1[column].append(df2[column])\n",
    "    grouped = ps.groupby(ps).size().to_frame().rename(columns={0: \"size\"})\n",
    "    df1.loc[df1.join(grouped, on=column, how=\"left\")[\"size\"] <= minimum_size, column] = -1\n",
    "    df2.loc[df2.join(grouped, on=column, how=\"left\")[\"size\"] <= minimum_size, column] = -1\n",
    "    return df1, df2\n",
    "\n",
    "def manager_skill_eval(train_df,test_df,unrank_threshold = 10):\n",
    "\n",
    "    target_num_map = {'High':2, 'Medium':1, 'Low':0}\n",
    "    temp=pd.concat([train_df.manager_id,pd.get_dummies(train_df.interest_level)], axis = 1).groupby('manager_id').mean()\n",
    "     \n",
    "    temp.columns = ['ManHigh','ManLow', 'ManMedium']\n",
    "    \n",
    "    print temp.columns\n",
    "    temp['count'] = train_df.groupby('manager_id').count().iloc[:,1]\n",
    "    \n",
    "    temp['manager_skill'] = temp['ManHigh']*2 + temp['ManMedium']\n",
    "    \n",
    "    #ixes of the managers with to few sample\n",
    "    unranked_managers_ixes = temp['count']<unrank_threshold\n",
    "    ranked_managers_ixes = ~unranked_managers_ixes\n",
    "    \n",
    "    #test for using rank or unrank part for the filling values\n",
    "    mean_values = temp.loc[unranked_managers_ixes, ['ManHigh','ManLow', 'ManMedium','manager_skill']].mean()\n",
    "    mean_values_total = temp.loc[:, ['ManHigh','ManLow', 'ManMedium','manager_skill']].mean()\n",
    "    \n",
    "    #reset their values to their average\n",
    "    temp.loc[unranked_managers_ixes,['ManHigh','ManLow', 'ManMedium','manager_skill']] = mean_values.values\n",
    "    \n",
    "    #assign the features for the train set\n",
    "    new_train_df = train_df.merge(temp.reset_index(),how='left', left_on='manager_id', right_on='manager_id')\n",
    "    \n",
    "    #assign the features for the test/val set\n",
    "    new_test_df = test_df.merge(temp.reset_index(),how='left', left_on='manager_id', right_on='manager_id')\n",
    "    new_manager_ixes = new_test_df['ManHigh'].isnull()\n",
    "    new_test_df.loc[new_manager_ixes,['ManHigh','ManLow', 'ManMedium','manager_skill']] = mean_values_total.values           \n",
    "    \n",
    "    return new_train_df,new_test_df\n",
    "\n",
    "#encoded by sorted value\n",
    "def hcc_sorting(train_df,test_df,feature,label=None,randomize=None):\n",
    "    \"\"\"\n",
    "    sort the hcc feature by their prior on label then encode\n",
    "    the train df should be with its labels get dummied\n",
    "    \n",
    "    return the list of all the possible features in order\n",
    "    \"\"\"\n",
    "    if label ==None:\n",
    "        train_df['tempScore'] = 2*train_df['high']+train_df['medium']\n",
    "    \n",
    "    label = 'tempScore'\n",
    "    #get dummies for the \n",
    "    grouped  = train_df.groupby(feature)[label].agg({'size':'size','mean':'mean'})\n",
    "    #unrankedMean = grouped.ix[grouped['size']<unrank_threshold,'mean'].mean()\n",
    "    #grouped.ix[grouped['size']<unrank_threshold,'mean'] = unrankedMean\n",
    "    grouped = grouped.reset_index()\n",
    "\n",
    "    #get the values for the test set\n",
    "    test_groupBy=test_df[feature].value_counts().to_frame().reset_index()\n",
    "    test_groupBy.columns = [feature,'testSize']\n",
    "\n",
    "    #merge together and reset the mean\n",
    "    totalFeature = grouped.merge(test_groupBy,on = feature, how='outer').fillna(0)\n",
    "\n",
    "    rankedMean = np.mean(grouped['mean'])\n",
    "\n",
    "    #reset those train size 0 to the ranked mean\n",
    "    totalFeature.ix[totalFeature['size']==0,'mean']=rankedMean\n",
    "    \n",
    "    #add some random \n",
    "    if randomize : \n",
    "        totalFeature['mean'] *= np.random.uniform(1 - randomize, 1 + randomize, len(totalFeature))\n",
    "\n",
    "    return list(totalFeature.sort('mean')[feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#functions for features\n",
    "def featureList(train_df,test_df,limit = 0.01):\n",
    "    #acquiring the feature lists\n",
    "    features_in_train = train_df[\"features\"].apply(pd.Series).unstack().reset_index(drop = True).dropna().value_counts()\n",
    "    features_in_train.sort(ascending  = False)\n",
    "    features_in_test = test_df[\"features\"].apply(pd.Series).unstack().reset_index(drop = True).dropna().value_counts()\n",
    "    features_in_test.sort(ascending  = False)\n",
    "    \n",
    "    filtered_features_in_train = features_in_train[features_in_train > limit*len(train_df)]\n",
    "    filtered_features_in_test = features_in_test[features_in_test > limit*len(test_df)]\n",
    "    accept_list = set(filtered_features_in_train.index).union(set(filtered_features_in_test.index))\n",
    "    return accept_list\n",
    "\n",
    "def featureMapping(train_df,test_df,feature_list):\n",
    "    for feature in feature_list:\n",
    "        #add the feature column for both\n",
    "        #if feature in the row, then set the value for (row,feature) to 1\n",
    "        train_df['with_'+feature]=train_df['features'].apply(lambda x : 1 if feature in x else 0)\n",
    "        test_df['with_'+feature]=test_df['features'].apply(lambda x : 1 if feature in x else 0)\n",
    "    return\n",
    "\n",
    "def clean(s):\n",
    "    x = s.replace(\"-\", \"\")\n",
    "    x = x.replace(\" \", \"\")\n",
    "    x = x.replace(\"twenty four hour\", \"24\")\n",
    "    x = x.replace(\"24/7\", \"24\")\n",
    "    x = x.replace(\"24hr\", \"24\")\n",
    "    x = x.replace(\"24-hour\", \"24\")\n",
    "    x = x.replace(\"24hour\", \"24\")\n",
    "    x = x.replace(\"24 hour\", \"24\")\n",
    "    \n",
    "    x = x.replace(\"common\", \"cm\")\n",
    "    x = x.replace(\"concierge\", \"doorman\")\n",
    "    x = x.replace(\"bicycle\", \"bike\")\n",
    "    x = x.replace(\"private\", \"pv\")\n",
    "    x = x.replace(\"deco\", \"dc\")\n",
    "    x = x.replace(\"decorative\", \"dc\")\n",
    "    x = x.replace(\"onsite\", \"os\")\n",
    "    x = x.replace(\"outdoor\", \"od\")\n",
    "    x = x.replace(\"ss appliances\", \"stainless\")\n",
    "    \n",
    "    x = x.replace(\"high_\",'hi')\n",
    "    x = x.replace(\"high\",'hi')\n",
    "    x = x.replace(\"hi_\",'hi')\n",
    "   \n",
    "    x = x.replace(\"live\",\"lv\")\n",
    "    x = x.replace(\"pre_\",\"pre\")\n",
    "    x = x.replace(\"all\",\"al\")\n",
    "    x = x.replace(\"flex\",\"fl\")\n",
    "    x = x.replace(\"residents\",\"rs\")\n",
    "    x = x.replace(\"close\",\"cl\")\n",
    "    x = x.replace(\"duplex\",\"dp\")\n",
    "    x = x.replace(\"share\",\"sh\")\n",
    "    x = x.replace(\"newly\",\"new\")\n",
    "    x = x.replace(\"on_site\",\"os\")\n",
    "    \n",
    "    x = x.replace(\"24_hour\",\"24\")\n",
    "    x = x.replace(\"full_time\",\"24\")\n",
    "\n",
    "\n",
    "    return x\n",
    "\n",
    "def feature_hash(x):\n",
    "    cleaned = clean(x, uniq)\n",
    "    key = cleaned[:4].strip()\n",
    "    return key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#central distance, see \"rental-listing-ny-map\" by Enrique Pérez Herrero\n",
    "def setOutlierNan(df):\n",
    "    for i in ['latitude', 'longitude']:\n",
    "        Q1 = df[i].quantile(0.25)\n",
    "        Q3 = df[i].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        upper = Q3 + 3*IQR\n",
    "        lower = Q1 - 3*IQR\n",
    "        df.ix[(df[i]>upper)|(df[i]<lower),i] = np.nan\n",
    "    return \n",
    "\n",
    "def getCentralDistance(df):\n",
    "    ny_lat = 40.785091\n",
    "    ny_lon = -73.968285\n",
    "    df['central_distance']= (df['latitude']-ny_lat)**2 + (df['longitude']-ny_lon)**2 \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49352, 15)\n",
      "(74659, 14)\n"
     ]
    }
   ],
   "source": [
    "#lodaing data\n",
    "data_path = \"../../kaggleData/2sigma/\"\n",
    "train_file = data_path + \"train.json\"\n",
    "test_file = data_path + \"test.json\"\n",
    "train_df = pd.read_json(train_file)\n",
    "test_df = pd.read_json(test_file)\n",
    "print(train_df.shape)\n",
    "print(test_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#basic numerical features\n",
    "features_to_use  = [\"bathrooms\", \"bedrooms\", \"latitude\", \"longitude\", \"price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#some new numerical features related to the price\n",
    "train_df[\"price_per_bath\"] =  train_df[\"price\"]*1.0/train_df[\"bathrooms\"]\n",
    "train_df[\"price_per_bed\"] = train_df[\"price\"]*1.0/train_df[\"bedrooms\"]\n",
    "train_df[\"bath_per_bed\"] = train_df[\"bathrooms\"]*1.0/train_df[\"bedrooms\"]\n",
    "train_df[\"price_per_room\"] = train_df[\"price\"]*1.0/(train_df[\"bedrooms\"]+train_df[\"bathrooms\"])\n",
    "\n",
    "test_df[\"price_per_bath\"] =  test_df[\"price\"]*1.0/test_df[\"bathrooms\"]\n",
    "test_df[\"price_per_bed\"] = test_df[\"price\"]*1.0/test_df[\"bedrooms\"]\n",
    "test_df[\"bath_per_bed\"] = test_df[\"bathrooms\"]*1.0/test_df[\"bedrooms\"]\n",
    "test_df[\"price_per_room\"] = test_df[\"price\"]*1.0/(test_df[\"bedrooms\"]+test_df[\"bathrooms\"])\n",
    "\n",
    "features_to_use.extend([\"price_per_bed\",\"bath_per_bed\",\"price_per_room\"])\n",
    "#features_to_use.append('price_per_bed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#some transfromed features\n",
    "# count of photos #\n",
    "train_df[\"num_photos\"] = train_df[\"photos\"].apply(len)\n",
    "test_df[\"num_photos\"] = test_df[\"photos\"].apply(len)\n",
    "\n",
    "# count of \"features\" #\n",
    "train_df[\"num_features\"] = train_df[\"features\"].apply(len)\n",
    "test_df[\"num_features\"] = test_df[\"features\"].apply(len)\n",
    "\n",
    "# count of words present in description column #\n",
    "train_df[\"num_description_words\"] = train_df[\"description\"].apply(lambda x: len(x.split(\" \")))\n",
    "test_df[\"num_description_words\"] = test_df[\"description\"].apply(lambda x: len(x.split(\" \")))\n",
    "\n",
    "# convert the created column to datetime object so as to extract more features \n",
    "train_df[\"created\"] = pd.to_datetime(train_df[\"created\"])\n",
    "test_df[\"created\"] = pd.to_datetime(test_df[\"created\"])\n",
    "\n",
    "# Let us extract some features like year, month, day, hour from date columns #\n",
    "train_df[\"created_year\"] = train_df[\"created\"].dt.year\n",
    "test_df[\"created_year\"] = test_df[\"created\"].dt.year\n",
    "train_df[\"created_month\"] = train_df[\"created\"].dt.month\n",
    "test_df[\"created_month\"] = test_df[\"created\"].dt.month\n",
    "train_df[\"created_day\"] = train_df[\"created\"].dt.day\n",
    "test_df[\"created_day\"] = test_df[\"created\"].dt.day\n",
    "train_df[\"created_hour\"] = train_df[\"created\"].dt.hour\n",
    "test_df[\"created_hour\"] = test_df[\"created\"].dt.hour\n",
    "\n",
    "# adding all these new features to use list # \"listing_id\",\n",
    "features_to_use.extend([\"num_photos\", \"num_features\", \"num_description_words\",\"created_year\",\"listing_id\", \"created_month\", \"created_day\", \"created_hour\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#setting the outliers (long,lat) in df to be nan \n",
    "setOutlierNan(train_df)\n",
    "setOutlierNan(test_df)\n",
    "\n",
    "#generate the central distance\n",
    "getCentralDistance(train_df)\n",
    "getCentralDistance(test_df)\n",
    "\n",
    "train_df['latitude'] = train_df['latitude'].fillna(0)\n",
    "train_df['longitude'] = train_df['longitude'].fillna(0)\n",
    "\n",
    "test_df['latitude'] = test_df['latitude'].fillna(0)\n",
    "test_df['longitude'] = test_df['longitude'].fillna(0)\n",
    "\n",
    "features_to_use.append('central_distance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_df['central_distance'] = test_df['central_distance'].fillna(0)\n",
    "train_df['central_distance'] = train_df['central_distance'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "new categorical data append and converting label dummies for future use\n",
    "\"\"\"\n",
    "#new feature for the street_address, use them instead of the original one\n",
    "train_df[\"street_name\"] = train_df[\"street_address\"].apply(proecessStreet)\n",
    "test_df[\"street_name\"] = test_df[\"street_address\"].apply(proecessStreet)\n",
    "\n",
    "train_df =train_df.join(pd.get_dummies(train_df[u'interest_level']).astype(int))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:5: FutureWarning: sort is deprecated, use sort_values(inplace=True) for INPLACE sorting\n",
      "C:\\Users\\dell\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:7: FutureWarning: sort is deprecated, use sort_values(inplace=True) for INPLACE sorting\n"
     ]
    }
   ],
   "source": [
    "#dealing with features\n",
    "\n",
    "#preprocessing for features\n",
    "train_df[\"features\"] = train_df[\"features\"].apply(lambda x:[\"_\".join(i.split(\" \")).lower().strip().replace('-','_') \\\n",
    "                                                            for i in x])\n",
    "test_df[\"features\"] = test_df[\"features\"].apply(lambda x:[\"_\".join(i.split(\" \")).lower().strip().replace('-','_')\\\n",
    "                                                          for i in x])\n",
    "\"\"\"remain to see if this is a good idead\"\"\"\n",
    "\"\"\"\n",
    "preaccept_list = list(featureList(train_df,test_df,limit = 0.0001))\n",
    "\n",
    "key2original = defaultdict(list)\n",
    "origin2key =  {}\n",
    "k = 4\n",
    "for f in preaccept_list:\n",
    "    cleaned = clean(f)\n",
    "    key = cleaned[:k].strip()\n",
    "    key2original[key].append(f)\n",
    "    origin2key[f] = key\n",
    "\n",
    "#combine some of the features\n",
    "train_df[\"features\"] = train_df[\"features\"].apply(lambda x : [origin2key[i] if i in origin2key else i for i in x ])\n",
    "test_df[\"features\"] = test_df[\"features\"].apply(lambda x : [origin2key[i] if i in origin2key else i for i in x ])\n",
    "\"\"\"\n",
    "#create the accept list\n",
    "accept_list = list(featureList(train_df,test_df,limit = 0.05))\n",
    "\n",
    "#map the feature to dummy slots\n",
    "featureMapping(train_df,test_df,accept_list)\n",
    "features_to_use.extend(map(lambda x : 'with_'+x,accept_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#prepare for training\n",
    "target_num_map = {'high':0, 'medium':1, 'low':2}\n",
    "\n",
    "train_y = np.array(train_df['interest_level'].apply(lambda x: target_num_map[x]))\n",
    "\n",
    "KF=KFold(len(train_df),5,shuffle=True,random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'ManHigh', u'ManLow', u'ManMedium'], dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:123: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:1.03043\ttest-mlogloss:1.03377\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 100 rounds.\n",
      "[1]\ttrain-mlogloss:0.97426\ttest-mlogloss:0.980126\n",
      "[2]\ttrain-mlogloss:0.925798\ttest-mlogloss:0.934647\n",
      "[3]\ttrain-mlogloss:0.884175\ttest-mlogloss:0.89505\n",
      "[4]\ttrain-mlogloss:0.847846\ttest-mlogloss:0.860921\n",
      "[5]\ttrain-mlogloss:0.815462\ttest-mlogloss:0.830454\n",
      "[6]\ttrain-mlogloss:0.787565\ttest-mlogloss:0.8038\n",
      "[7]\ttrain-mlogloss:0.761538\ttest-mlogloss:0.779703\n",
      "[8]\ttrain-mlogloss:0.738939\ttest-mlogloss:0.758559\n",
      "[9]\ttrain-mlogloss:0.719556\ttest-mlogloss:0.74082\n",
      "[10]\ttrain-mlogloss:0.700741\ttest-mlogloss:0.724013\n",
      "[11]\ttrain-mlogloss:0.685559\ttest-mlogloss:0.7099\n",
      "[12]\ttrain-mlogloss:0.671227\ttest-mlogloss:0.697174\n",
      "[13]\ttrain-mlogloss:0.658428\ttest-mlogloss:0.685532\n",
      "[14]\ttrain-mlogloss:0.646724\ttest-mlogloss:0.675258\n",
      "[15]\ttrain-mlogloss:0.636541\ttest-mlogloss:0.66584\n",
      "[16]\ttrain-mlogloss:0.62737\ttest-mlogloss:0.657354\n",
      "[17]\ttrain-mlogloss:0.618465\ttest-mlogloss:0.649868\n",
      "[18]\ttrain-mlogloss:0.611112\ttest-mlogloss:0.643252\n",
      "[19]\ttrain-mlogloss:0.603667\ttest-mlogloss:0.636733\n",
      "[20]\ttrain-mlogloss:0.596534\ttest-mlogloss:0.630893\n",
      "[21]\ttrain-mlogloss:0.590611\ttest-mlogloss:0.625946\n",
      "[22]\ttrain-mlogloss:0.584752\ttest-mlogloss:0.621525\n",
      "[23]\ttrain-mlogloss:0.579278\ttest-mlogloss:0.617018\n",
      "[24]\ttrain-mlogloss:0.574737\ttest-mlogloss:0.613307\n",
      "[25]\ttrain-mlogloss:0.570074\ttest-mlogloss:0.60976\n",
      "[26]\ttrain-mlogloss:0.566049\ttest-mlogloss:0.606553\n",
      "[27]\ttrain-mlogloss:0.562057\ttest-mlogloss:0.603715\n",
      "[28]\ttrain-mlogloss:0.558207\ttest-mlogloss:0.601011\n",
      "[29]\ttrain-mlogloss:0.555023\ttest-mlogloss:0.598616\n",
      "[30]\ttrain-mlogloss:0.551652\ttest-mlogloss:0.596115\n",
      "[31]\ttrain-mlogloss:0.548592\ttest-mlogloss:0.594245\n",
      "[32]\ttrain-mlogloss:0.545443\ttest-mlogloss:0.592266\n",
      "[33]\ttrain-mlogloss:0.542741\ttest-mlogloss:0.590332\n",
      "[34]\ttrain-mlogloss:0.540461\ttest-mlogloss:0.588594\n",
      "[35]\ttrain-mlogloss:0.537799\ttest-mlogloss:0.586965\n",
      "[36]\ttrain-mlogloss:0.535129\ttest-mlogloss:0.585448\n",
      "[37]\ttrain-mlogloss:0.533019\ttest-mlogloss:0.584181\n",
      "[38]\ttrain-mlogloss:0.530943\ttest-mlogloss:0.583198\n",
      "[39]\ttrain-mlogloss:0.528736\ttest-mlogloss:0.581685\n",
      "[40]\ttrain-mlogloss:0.526718\ttest-mlogloss:0.58059\n",
      "[41]\ttrain-mlogloss:0.52479\ttest-mlogloss:0.579537\n",
      "[42]\ttrain-mlogloss:0.522941\ttest-mlogloss:0.578726\n",
      "[43]\ttrain-mlogloss:0.521051\ttest-mlogloss:0.577716\n",
      "[44]\ttrain-mlogloss:0.519466\ttest-mlogloss:0.577185\n",
      "[45]\ttrain-mlogloss:0.518087\ttest-mlogloss:0.576645\n",
      "[46]\ttrain-mlogloss:0.516422\ttest-mlogloss:0.575902\n",
      "[47]\ttrain-mlogloss:0.514535\ttest-mlogloss:0.574779\n",
      "[48]\ttrain-mlogloss:0.513201\ttest-mlogloss:0.574229\n",
      "[49]\ttrain-mlogloss:0.511827\ttest-mlogloss:0.573764\n",
      "[50]\ttrain-mlogloss:0.510566\ttest-mlogloss:0.573354\n",
      "[51]\ttrain-mlogloss:0.509081\ttest-mlogloss:0.572736\n",
      "[52]\ttrain-mlogloss:0.507566\ttest-mlogloss:0.572174\n",
      "[53]\ttrain-mlogloss:0.506437\ttest-mlogloss:0.571873\n",
      "[54]\ttrain-mlogloss:0.5051\ttest-mlogloss:0.571475\n",
      "[55]\ttrain-mlogloss:0.503711\ttest-mlogloss:0.57091\n",
      "[56]\ttrain-mlogloss:0.50255\ttest-mlogloss:0.570558\n",
      "[57]\ttrain-mlogloss:0.501271\ttest-mlogloss:0.570367\n",
      "[58]\ttrain-mlogloss:0.500128\ttest-mlogloss:0.569955\n",
      "[59]\ttrain-mlogloss:0.499194\ttest-mlogloss:0.569948\n",
      "[60]\ttrain-mlogloss:0.497456\ttest-mlogloss:0.569094\n",
      "[61]\ttrain-mlogloss:0.496163\ttest-mlogloss:0.568747\n",
      "[62]\ttrain-mlogloss:0.494753\ttest-mlogloss:0.568313\n",
      "[63]\ttrain-mlogloss:0.493759\ttest-mlogloss:0.568257\n",
      "[64]\ttrain-mlogloss:0.492867\ttest-mlogloss:0.567903\n",
      "[65]\ttrain-mlogloss:0.491991\ttest-mlogloss:0.567791\n",
      "[66]\ttrain-mlogloss:0.490933\ttest-mlogloss:0.567474\n",
      "[67]\ttrain-mlogloss:0.490002\ttest-mlogloss:0.566952\n",
      "[68]\ttrain-mlogloss:0.488725\ttest-mlogloss:0.566429\n",
      "[69]\ttrain-mlogloss:0.487706\ttest-mlogloss:0.566189\n",
      "[70]\ttrain-mlogloss:0.486791\ttest-mlogloss:0.565965\n",
      "[71]\ttrain-mlogloss:0.485915\ttest-mlogloss:0.565804\n",
      "[72]\ttrain-mlogloss:0.48466\ttest-mlogloss:0.565447\n",
      "[73]\ttrain-mlogloss:0.483291\ttest-mlogloss:0.564644\n",
      "[74]\ttrain-mlogloss:0.482389\ttest-mlogloss:0.564354\n",
      "[75]\ttrain-mlogloss:0.480804\ttest-mlogloss:0.5636\n",
      "[76]\ttrain-mlogloss:0.479959\ttest-mlogloss:0.563457\n",
      "[77]\ttrain-mlogloss:0.478831\ttest-mlogloss:0.563117\n",
      "[78]\ttrain-mlogloss:0.477757\ttest-mlogloss:0.562787\n",
      "[79]\ttrain-mlogloss:0.476879\ttest-mlogloss:0.562599\n",
      "[80]\ttrain-mlogloss:0.475791\ttest-mlogloss:0.56227\n",
      "[81]\ttrain-mlogloss:0.474605\ttest-mlogloss:0.561907\n",
      "[82]\ttrain-mlogloss:0.473493\ttest-mlogloss:0.561825\n",
      "[83]\ttrain-mlogloss:0.472376\ttest-mlogloss:0.561434\n",
      "[84]\ttrain-mlogloss:0.47128\ttest-mlogloss:0.561088\n",
      "[85]\ttrain-mlogloss:0.470137\ttest-mlogloss:0.560698\n",
      "[86]\ttrain-mlogloss:0.469625\ttest-mlogloss:0.560836\n",
      "[87]\ttrain-mlogloss:0.468727\ttest-mlogloss:0.56048\n",
      "[88]\ttrain-mlogloss:0.467923\ttest-mlogloss:0.560313\n",
      "[89]\ttrain-mlogloss:0.467112\ttest-mlogloss:0.56013\n",
      "[90]\ttrain-mlogloss:0.466334\ttest-mlogloss:0.559901\n",
      "[91]\ttrain-mlogloss:0.465395\ttest-mlogloss:0.55996\n",
      "[92]\ttrain-mlogloss:0.464287\ttest-mlogloss:0.559614\n",
      "[93]\ttrain-mlogloss:0.463271\ttest-mlogloss:0.559217\n",
      "[94]\ttrain-mlogloss:0.462571\ttest-mlogloss:0.558908\n",
      "[95]\ttrain-mlogloss:0.461873\ttest-mlogloss:0.55868\n",
      "[96]\ttrain-mlogloss:0.460934\ttest-mlogloss:0.55836\n",
      "[97]\ttrain-mlogloss:0.459976\ttest-mlogloss:0.558269\n",
      "[98]\ttrain-mlogloss:0.45918\ttest-mlogloss:0.558001\n",
      "[99]\ttrain-mlogloss:0.458366\ttest-mlogloss:0.55795\n",
      "[100]\ttrain-mlogloss:0.457661\ttest-mlogloss:0.557853\n",
      "[101]\ttrain-mlogloss:0.456919\ttest-mlogloss:0.55774\n",
      "[102]\ttrain-mlogloss:0.455918\ttest-mlogloss:0.557516\n",
      "[103]\ttrain-mlogloss:0.455158\ttest-mlogloss:0.557446\n",
      "[104]\ttrain-mlogloss:0.45437\ttest-mlogloss:0.557212\n",
      "[105]\ttrain-mlogloss:0.453553\ttest-mlogloss:0.557062\n",
      "[106]\ttrain-mlogloss:0.45275\ttest-mlogloss:0.556812\n",
      "[107]\ttrain-mlogloss:0.451821\ttest-mlogloss:0.556581\n",
      "[108]\ttrain-mlogloss:0.451145\ttest-mlogloss:0.556352\n",
      "[109]\ttrain-mlogloss:0.450342\ttest-mlogloss:0.556198\n",
      "[110]\ttrain-mlogloss:0.449458\ttest-mlogloss:0.555977\n",
      "[111]\ttrain-mlogloss:0.448677\ttest-mlogloss:0.555883\n",
      "[112]\ttrain-mlogloss:0.447851\ttest-mlogloss:0.5557\n",
      "[113]\ttrain-mlogloss:0.447175\ttest-mlogloss:0.555632\n",
      "[114]\ttrain-mlogloss:0.446429\ttest-mlogloss:0.555587\n",
      "[115]\ttrain-mlogloss:0.445954\ttest-mlogloss:0.555622\n",
      "[116]\ttrain-mlogloss:0.44512\ttest-mlogloss:0.555194\n",
      "[117]\ttrain-mlogloss:0.444287\ttest-mlogloss:0.555164\n",
      "[118]\ttrain-mlogloss:0.443447\ttest-mlogloss:0.554979\n",
      "[119]\ttrain-mlogloss:0.442885\ttest-mlogloss:0.554855\n",
      "[120]\ttrain-mlogloss:0.44215\ttest-mlogloss:0.554614\n",
      "[121]\ttrain-mlogloss:0.441086\ttest-mlogloss:0.554377\n",
      "[122]\ttrain-mlogloss:0.440387\ttest-mlogloss:0.554061\n",
      "[123]\ttrain-mlogloss:0.439757\ttest-mlogloss:0.554023\n",
      "[124]\ttrain-mlogloss:0.439155\ttest-mlogloss:0.554106\n",
      "[125]\ttrain-mlogloss:0.438542\ttest-mlogloss:0.554105\n",
      "[126]\ttrain-mlogloss:0.43764\ttest-mlogloss:0.553834\n",
      "[127]\ttrain-mlogloss:0.436891\ttest-mlogloss:0.553593\n",
      "[128]\ttrain-mlogloss:0.436349\ttest-mlogloss:0.553497\n",
      "[129]\ttrain-mlogloss:0.435864\ttest-mlogloss:0.553553\n",
      "[130]\ttrain-mlogloss:0.435138\ttest-mlogloss:0.553568\n",
      "[131]\ttrain-mlogloss:0.434359\ttest-mlogloss:0.553468\n",
      "[132]\ttrain-mlogloss:0.433765\ttest-mlogloss:0.55345\n",
      "[133]\ttrain-mlogloss:0.433087\ttest-mlogloss:0.553369\n",
      "[134]\ttrain-mlogloss:0.432367\ttest-mlogloss:0.553241\n",
      "[135]\ttrain-mlogloss:0.431867\ttest-mlogloss:0.553128\n",
      "[136]\ttrain-mlogloss:0.431284\ttest-mlogloss:0.55297\n",
      "[137]\ttrain-mlogloss:0.43048\ttest-mlogloss:0.552732\n",
      "[138]\ttrain-mlogloss:0.429538\ttest-mlogloss:0.552601\n",
      "[139]\ttrain-mlogloss:0.428796\ttest-mlogloss:0.552538\n",
      "[140]\ttrain-mlogloss:0.427872\ttest-mlogloss:0.552368\n",
      "[141]\ttrain-mlogloss:0.426966\ttest-mlogloss:0.552346\n",
      "[142]\ttrain-mlogloss:0.426344\ttest-mlogloss:0.552288\n",
      "[143]\ttrain-mlogloss:0.425811\ttest-mlogloss:0.552322\n",
      "[144]\ttrain-mlogloss:0.425278\ttest-mlogloss:0.552214\n",
      "[145]\ttrain-mlogloss:0.424618\ttest-mlogloss:0.55206\n",
      "[146]\ttrain-mlogloss:0.423696\ttest-mlogloss:0.551975\n",
      "[147]\ttrain-mlogloss:0.423075\ttest-mlogloss:0.551923\n",
      "[148]\ttrain-mlogloss:0.422515\ttest-mlogloss:0.552025\n",
      "[149]\ttrain-mlogloss:0.422058\ttest-mlogloss:0.551921\n",
      "[150]\ttrain-mlogloss:0.421359\ttest-mlogloss:0.551733\n",
      "[151]\ttrain-mlogloss:0.420621\ttest-mlogloss:0.551612\n",
      "[152]\ttrain-mlogloss:0.420054\ttest-mlogloss:0.551601\n",
      "[153]\ttrain-mlogloss:0.419361\ttest-mlogloss:0.551488\n",
      "[154]\ttrain-mlogloss:0.418637\ttest-mlogloss:0.55123\n",
      "[155]\ttrain-mlogloss:0.418129\ttest-mlogloss:0.551126\n",
      "[156]\ttrain-mlogloss:0.417434\ttest-mlogloss:0.551274\n",
      "[157]\ttrain-mlogloss:0.416986\ttest-mlogloss:0.551236\n",
      "[158]\ttrain-mlogloss:0.416279\ttest-mlogloss:0.551185\n",
      "[159]\ttrain-mlogloss:0.415703\ttest-mlogloss:0.551189\n",
      "[160]\ttrain-mlogloss:0.415067\ttest-mlogloss:0.551144\n",
      "[161]\ttrain-mlogloss:0.414428\ttest-mlogloss:0.550996\n",
      "[162]\ttrain-mlogloss:0.413959\ttest-mlogloss:0.551096\n",
      "[163]\ttrain-mlogloss:0.413318\ttest-mlogloss:0.550951\n",
      "[164]\ttrain-mlogloss:0.412483\ttest-mlogloss:0.550975\n",
      "[165]\ttrain-mlogloss:0.411706\ttest-mlogloss:0.550845\n",
      "[166]\ttrain-mlogloss:0.41115\ttest-mlogloss:0.550681\n",
      "[167]\ttrain-mlogloss:0.41062\ttest-mlogloss:0.550726\n",
      "[168]\ttrain-mlogloss:0.409941\ttest-mlogloss:0.550648\n",
      "[169]\ttrain-mlogloss:0.40903\ttest-mlogloss:0.550453\n",
      "[170]\ttrain-mlogloss:0.408548\ttest-mlogloss:0.550401\n",
      "[171]\ttrain-mlogloss:0.408123\ttest-mlogloss:0.550404\n",
      "[172]\ttrain-mlogloss:0.407826\ttest-mlogloss:0.550292\n",
      "[173]\ttrain-mlogloss:0.407261\ttest-mlogloss:0.550404\n",
      "[174]\ttrain-mlogloss:0.406463\ttest-mlogloss:0.550341\n",
      "[175]\ttrain-mlogloss:0.405966\ttest-mlogloss:0.550325\n",
      "[176]\ttrain-mlogloss:0.405604\ttest-mlogloss:0.550271\n",
      "[177]\ttrain-mlogloss:0.405014\ttest-mlogloss:0.550191\n",
      "[178]\ttrain-mlogloss:0.40438\ttest-mlogloss:0.55021\n",
      "[179]\ttrain-mlogloss:0.403843\ttest-mlogloss:0.550176\n",
      "[180]\ttrain-mlogloss:0.403092\ttest-mlogloss:0.55013\n",
      "[181]\ttrain-mlogloss:0.4024\ttest-mlogloss:0.550077\n",
      "[182]\ttrain-mlogloss:0.401783\ttest-mlogloss:0.550038\n",
      "[183]\ttrain-mlogloss:0.401044\ttest-mlogloss:0.550029\n",
      "[184]\ttrain-mlogloss:0.400686\ttest-mlogloss:0.55013\n",
      "[185]\ttrain-mlogloss:0.399987\ttest-mlogloss:0.55004\n",
      "[186]\ttrain-mlogloss:0.399447\ttest-mlogloss:0.550018\n",
      "[187]\ttrain-mlogloss:0.398981\ttest-mlogloss:0.549948\n",
      "[188]\ttrain-mlogloss:0.398375\ttest-mlogloss:0.549928\n",
      "[189]\ttrain-mlogloss:0.397823\ttest-mlogloss:0.549899\n",
      "[190]\ttrain-mlogloss:0.397143\ttest-mlogloss:0.549787\n",
      "[191]\ttrain-mlogloss:0.396546\ttest-mlogloss:0.549745\n",
      "[192]\ttrain-mlogloss:0.395866\ttest-mlogloss:0.54979\n",
      "[193]\ttrain-mlogloss:0.39526\ttest-mlogloss:0.549662\n",
      "[194]\ttrain-mlogloss:0.394772\ttest-mlogloss:0.549688\n",
      "[195]\ttrain-mlogloss:0.394092\ttest-mlogloss:0.549734\n",
      "[196]\ttrain-mlogloss:0.39339\ttest-mlogloss:0.549709\n",
      "[197]\ttrain-mlogloss:0.393078\ttest-mlogloss:0.54971\n",
      "[198]\ttrain-mlogloss:0.392343\ttest-mlogloss:0.549626\n",
      "[199]\ttrain-mlogloss:0.391751\ttest-mlogloss:0.549415\n",
      "[200]\ttrain-mlogloss:0.391146\ttest-mlogloss:0.549315\n",
      "[201]\ttrain-mlogloss:0.390551\ttest-mlogloss:0.54915\n",
      "[202]\ttrain-mlogloss:0.390169\ttest-mlogloss:0.549195\n",
      "[203]\ttrain-mlogloss:0.389751\ttest-mlogloss:0.549125\n",
      "[204]\ttrain-mlogloss:0.389176\ttest-mlogloss:0.549106\n",
      "[205]\ttrain-mlogloss:0.388699\ttest-mlogloss:0.549053\n",
      "[206]\ttrain-mlogloss:0.38832\ttest-mlogloss:0.549101\n",
      "[207]\ttrain-mlogloss:0.3878\ttest-mlogloss:0.549263\n",
      "[208]\ttrain-mlogloss:0.387398\ttest-mlogloss:0.54918\n",
      "[209]\ttrain-mlogloss:0.386742\ttest-mlogloss:0.549067\n",
      "[210]\ttrain-mlogloss:0.386096\ttest-mlogloss:0.548865\n",
      "[211]\ttrain-mlogloss:0.385498\ttest-mlogloss:0.54887\n",
      "[212]\ttrain-mlogloss:0.384822\ttest-mlogloss:0.548847\n",
      "[213]\ttrain-mlogloss:0.384304\ttest-mlogloss:0.548795\n",
      "[214]\ttrain-mlogloss:0.38376\ttest-mlogloss:0.548805\n",
      "[215]\ttrain-mlogloss:0.383223\ttest-mlogloss:0.548898\n",
      "[216]\ttrain-mlogloss:0.382658\ttest-mlogloss:0.549086\n",
      "[217]\ttrain-mlogloss:0.382047\ttest-mlogloss:0.549243\n",
      "[218]\ttrain-mlogloss:0.381494\ttest-mlogloss:0.549113\n",
      "[219]\ttrain-mlogloss:0.380732\ttest-mlogloss:0.549004\n",
      "[220]\ttrain-mlogloss:0.380276\ttest-mlogloss:0.549168\n",
      "[221]\ttrain-mlogloss:0.37971\ttest-mlogloss:0.549271\n",
      "[222]\ttrain-mlogloss:0.379149\ttest-mlogloss:0.549248\n",
      "[223]\ttrain-mlogloss:0.378437\ttest-mlogloss:0.549127\n",
      "[224]\ttrain-mlogloss:0.377902\ttest-mlogloss:0.549029\n",
      "[225]\ttrain-mlogloss:0.377376\ttest-mlogloss:0.548865\n",
      "[226]\ttrain-mlogloss:0.376935\ttest-mlogloss:0.548804\n",
      "[227]\ttrain-mlogloss:0.376555\ttest-mlogloss:0.548929\n",
      "[228]\ttrain-mlogloss:0.375857\ttest-mlogloss:0.54896\n",
      "[229]\ttrain-mlogloss:0.375264\ttest-mlogloss:0.548953\n",
      "[230]\ttrain-mlogloss:0.374661\ttest-mlogloss:0.548949\n",
      "[231]\ttrain-mlogloss:0.374416\ttest-mlogloss:0.548944\n",
      "[232]\ttrain-mlogloss:0.373844\ttest-mlogloss:0.548879\n",
      "[233]\ttrain-mlogloss:0.373428\ttest-mlogloss:0.548904\n",
      "[234]\ttrain-mlogloss:0.372967\ttest-mlogloss:0.548867\n",
      "[235]\ttrain-mlogloss:0.372544\ttest-mlogloss:0.548916\n",
      "[236]\ttrain-mlogloss:0.372026\ttest-mlogloss:0.548752\n",
      "[237]\ttrain-mlogloss:0.371505\ttest-mlogloss:0.548691\n",
      "[238]\ttrain-mlogloss:0.371014\ttest-mlogloss:0.548708\n",
      "[239]\ttrain-mlogloss:0.370377\ttest-mlogloss:0.548668\n",
      "[240]\ttrain-mlogloss:0.369826\ttest-mlogloss:0.548646\n",
      "[241]\ttrain-mlogloss:0.369301\ttest-mlogloss:0.54859\n",
      "[242]\ttrain-mlogloss:0.368937\ttest-mlogloss:0.548569\n",
      "[243]\ttrain-mlogloss:0.368394\ttest-mlogloss:0.548582\n",
      "[244]\ttrain-mlogloss:0.367994\ttest-mlogloss:0.548605\n",
      "[245]\ttrain-mlogloss:0.367665\ttest-mlogloss:0.548587\n",
      "[246]\ttrain-mlogloss:0.367204\ttest-mlogloss:0.548568\n",
      "[247]\ttrain-mlogloss:0.366646\ttest-mlogloss:0.54857\n",
      "[248]\ttrain-mlogloss:0.366083\ttest-mlogloss:0.548557\n",
      "[249]\ttrain-mlogloss:0.365567\ttest-mlogloss:0.548494\n",
      "[250]\ttrain-mlogloss:0.365005\ttest-mlogloss:0.548477\n",
      "[251]\ttrain-mlogloss:0.364535\ttest-mlogloss:0.548418\n",
      "[252]\ttrain-mlogloss:0.364019\ttest-mlogloss:0.548395\n",
      "[253]\ttrain-mlogloss:0.363584\ttest-mlogloss:0.548523\n",
      "[254]\ttrain-mlogloss:0.363152\ttest-mlogloss:0.548559\n",
      "[255]\ttrain-mlogloss:0.362553\ttest-mlogloss:0.548465\n",
      "[256]\ttrain-mlogloss:0.362034\ttest-mlogloss:0.548469\n",
      "[257]\ttrain-mlogloss:0.361596\ttest-mlogloss:0.548541\n",
      "[258]\ttrain-mlogloss:0.361094\ttest-mlogloss:0.548424\n",
      "[259]\ttrain-mlogloss:0.360443\ttest-mlogloss:0.548415\n",
      "[260]\ttrain-mlogloss:0.359963\ttest-mlogloss:0.548455\n",
      "[261]\ttrain-mlogloss:0.359509\ttest-mlogloss:0.548527\n",
      "[262]\ttrain-mlogloss:0.358824\ttest-mlogloss:0.548617\n",
      "[263]\ttrain-mlogloss:0.358324\ttest-mlogloss:0.548521\n",
      "[264]\ttrain-mlogloss:0.357784\ttest-mlogloss:0.548542\n",
      "[265]\ttrain-mlogloss:0.35742\ttest-mlogloss:0.548646\n",
      "[266]\ttrain-mlogloss:0.356856\ttest-mlogloss:0.548625\n",
      "[267]\ttrain-mlogloss:0.356266\ttest-mlogloss:0.548703\n",
      "[268]\ttrain-mlogloss:0.355788\ttest-mlogloss:0.548582\n",
      "[269]\ttrain-mlogloss:0.355213\ttest-mlogloss:0.548518\n",
      "[270]\ttrain-mlogloss:0.354878\ttest-mlogloss:0.548458\n",
      "[271]\ttrain-mlogloss:0.354515\ttest-mlogloss:0.548419\n",
      "[272]\ttrain-mlogloss:0.354082\ttest-mlogloss:0.548511\n",
      "[273]\ttrain-mlogloss:0.353632\ttest-mlogloss:0.548497\n",
      "[274]\ttrain-mlogloss:0.353177\ttest-mlogloss:0.54843\n",
      "[275]\ttrain-mlogloss:0.35259\ttest-mlogloss:0.548452\n",
      "[276]\ttrain-mlogloss:0.352126\ttest-mlogloss:0.548378\n",
      "[277]\ttrain-mlogloss:0.351648\ttest-mlogloss:0.548432\n",
      "[278]\ttrain-mlogloss:0.351219\ttest-mlogloss:0.548459\n",
      "[279]\ttrain-mlogloss:0.350883\ttest-mlogloss:0.548516\n",
      "[280]\ttrain-mlogloss:0.350306\ttest-mlogloss:0.548631\n",
      "[281]\ttrain-mlogloss:0.349875\ttest-mlogloss:0.548697\n",
      "[282]\ttrain-mlogloss:0.349393\ttest-mlogloss:0.548732\n",
      "[283]\ttrain-mlogloss:0.34888\ttest-mlogloss:0.548757\n",
      "[284]\ttrain-mlogloss:0.348431\ttest-mlogloss:0.54869\n",
      "[285]\ttrain-mlogloss:0.347906\ttest-mlogloss:0.548745\n",
      "[286]\ttrain-mlogloss:0.347596\ttest-mlogloss:0.548765\n",
      "[287]\ttrain-mlogloss:0.346997\ttest-mlogloss:0.548829\n",
      "[288]\ttrain-mlogloss:0.346508\ttest-mlogloss:0.548661\n",
      "[289]\ttrain-mlogloss:0.346089\ttest-mlogloss:0.548651\n",
      "[290]\ttrain-mlogloss:0.345603\ttest-mlogloss:0.548697\n",
      "[291]\ttrain-mlogloss:0.345125\ttest-mlogloss:0.548682\n",
      "[292]\ttrain-mlogloss:0.344691\ttest-mlogloss:0.548747\n",
      "[293]\ttrain-mlogloss:0.344297\ttest-mlogloss:0.54874\n",
      "[294]\ttrain-mlogloss:0.343717\ttest-mlogloss:0.548816\n",
      "[295]\ttrain-mlogloss:0.343136\ttest-mlogloss:0.548933\n",
      "[296]\ttrain-mlogloss:0.342622\ttest-mlogloss:0.549026\n",
      "[297]\ttrain-mlogloss:0.342002\ttest-mlogloss:0.548997\n",
      "[298]\ttrain-mlogloss:0.341617\ttest-mlogloss:0.548943\n",
      "[299]\ttrain-mlogloss:0.341139\ttest-mlogloss:0.548846\n",
      "[300]\ttrain-mlogloss:0.340645\ttest-mlogloss:0.54887\n",
      "[301]\ttrain-mlogloss:0.340233\ttest-mlogloss:0.548896\n",
      "[302]\ttrain-mlogloss:0.339861\ttest-mlogloss:0.548989\n",
      "[303]\ttrain-mlogloss:0.339387\ttest-mlogloss:0.549105\n",
      "[304]\ttrain-mlogloss:0.338866\ttest-mlogloss:0.548934\n",
      "[305]\ttrain-mlogloss:0.338383\ttest-mlogloss:0.549073\n",
      "[306]\ttrain-mlogloss:0.337855\ttest-mlogloss:0.548982\n",
      "[307]\ttrain-mlogloss:0.33749\ttest-mlogloss:0.549157\n",
      "[308]\ttrain-mlogloss:0.337061\ttest-mlogloss:0.5492\n",
      "[309]\ttrain-mlogloss:0.336666\ttest-mlogloss:0.549218\n",
      "[310]\ttrain-mlogloss:0.336247\ttest-mlogloss:0.549228\n",
      "[311]\ttrain-mlogloss:0.335923\ttest-mlogloss:0.549224\n",
      "[312]\ttrain-mlogloss:0.335521\ttest-mlogloss:0.549183\n",
      "[313]\ttrain-mlogloss:0.335162\ttest-mlogloss:0.549363\n",
      "[314]\ttrain-mlogloss:0.334811\ttest-mlogloss:0.549353\n",
      "[315]\ttrain-mlogloss:0.33438\ttest-mlogloss:0.549428\n",
      "[316]\ttrain-mlogloss:0.333847\ttest-mlogloss:0.549402\n",
      "[317]\ttrain-mlogloss:0.333298\ttest-mlogloss:0.549224\n",
      "[318]\ttrain-mlogloss:0.332948\ttest-mlogloss:0.549186\n",
      "[319]\ttrain-mlogloss:0.332414\ttest-mlogloss:0.549175\n",
      "[320]\ttrain-mlogloss:0.332017\ttest-mlogloss:0.549201\n",
      "[321]\ttrain-mlogloss:0.331766\ttest-mlogloss:0.549226\n",
      "[322]\ttrain-mlogloss:0.331328\ttest-mlogloss:0.549236\n",
      "[323]\ttrain-mlogloss:0.330886\ttest-mlogloss:0.549204\n",
      "[324]\ttrain-mlogloss:0.330367\ttest-mlogloss:0.549269\n",
      "[325]\ttrain-mlogloss:0.329894\ttest-mlogloss:0.549251\n",
      "[326]\ttrain-mlogloss:0.329516\ttest-mlogloss:0.54931\n",
      "[327]\ttrain-mlogloss:0.329089\ttest-mlogloss:0.549347\n",
      "[328]\ttrain-mlogloss:0.328741\ttest-mlogloss:0.549475\n",
      "[329]\ttrain-mlogloss:0.328327\ttest-mlogloss:0.549569\n",
      "[330]\ttrain-mlogloss:0.327842\ttest-mlogloss:0.549501\n",
      "[331]\ttrain-mlogloss:0.327386\ttest-mlogloss:0.549543\n",
      "[332]\ttrain-mlogloss:0.327013\ttest-mlogloss:0.549546\n",
      "[333]\ttrain-mlogloss:0.326597\ttest-mlogloss:0.549618\n",
      "[334]\ttrain-mlogloss:0.326098\ttest-mlogloss:0.549651\n",
      "[335]\ttrain-mlogloss:0.325635\ttest-mlogloss:0.5497\n",
      "[336]\ttrain-mlogloss:0.32526\ttest-mlogloss:0.54971\n",
      "[337]\ttrain-mlogloss:0.324856\ttest-mlogloss:0.549923\n",
      "[338]\ttrain-mlogloss:0.32444\ttest-mlogloss:0.549957\n",
      "[339]\ttrain-mlogloss:0.323907\ttest-mlogloss:0.549934\n",
      "[340]\ttrain-mlogloss:0.323454\ttest-mlogloss:0.549955\n",
      "[341]\ttrain-mlogloss:0.323078\ttest-mlogloss:0.549974\n",
      "[342]\ttrain-mlogloss:0.322685\ttest-mlogloss:0.550096\n",
      "[343]\ttrain-mlogloss:0.322296\ttest-mlogloss:0.550131\n",
      "[344]\ttrain-mlogloss:0.321896\ttest-mlogloss:0.550157\n",
      "[345]\ttrain-mlogloss:0.321528\ttest-mlogloss:0.55026\n",
      "[346]\ttrain-mlogloss:0.321093\ttest-mlogloss:0.550268\n",
      "[347]\ttrain-mlogloss:0.320633\ttest-mlogloss:0.550321\n",
      "[348]\ttrain-mlogloss:0.320276\ttest-mlogloss:0.550357\n",
      "[349]\ttrain-mlogloss:0.31993\ttest-mlogloss:0.550357\n",
      "[350]\ttrain-mlogloss:0.319485\ttest-mlogloss:0.550489\n",
      "[351]\ttrain-mlogloss:0.318942\ttest-mlogloss:0.550549\n",
      "[352]\ttrain-mlogloss:0.318512\ttest-mlogloss:0.550502\n",
      "[353]\ttrain-mlogloss:0.318112\ttest-mlogloss:0.550619\n",
      "[354]\ttrain-mlogloss:0.317693\ttest-mlogloss:0.55048\n",
      "[355]\ttrain-mlogloss:0.317145\ttest-mlogloss:0.550413\n",
      "[356]\ttrain-mlogloss:0.316599\ttest-mlogloss:0.550531\n",
      "[357]\ttrain-mlogloss:0.316276\ttest-mlogloss:0.550523\n",
      "[358]\ttrain-mlogloss:0.315828\ttest-mlogloss:0.550515\n",
      "[359]\ttrain-mlogloss:0.315384\ttest-mlogloss:0.550471\n",
      "[360]\ttrain-mlogloss:0.314971\ttest-mlogloss:0.550474\n",
      "[361]\ttrain-mlogloss:0.314526\ttest-mlogloss:0.550491\n",
      "[362]\ttrain-mlogloss:0.314178\ttest-mlogloss:0.550471\n",
      "[363]\ttrain-mlogloss:0.313821\ttest-mlogloss:0.550489\n",
      "[364]\ttrain-mlogloss:0.313542\ttest-mlogloss:0.550561\n",
      "[365]\ttrain-mlogloss:0.313109\ttest-mlogloss:0.55072\n",
      "[366]\ttrain-mlogloss:0.312854\ttest-mlogloss:0.550674\n",
      "[367]\ttrain-mlogloss:0.312491\ttest-mlogloss:0.550683\n",
      "[368]\ttrain-mlogloss:0.312122\ttest-mlogloss:0.550729\n",
      "[369]\ttrain-mlogloss:0.311756\ttest-mlogloss:0.550829\n",
      "[370]\ttrain-mlogloss:0.311296\ttest-mlogloss:0.551034\n",
      "[371]\ttrain-mlogloss:0.310977\ttest-mlogloss:0.550982\n",
      "[372]\ttrain-mlogloss:0.310544\ttest-mlogloss:0.551108\n",
      "[373]\ttrain-mlogloss:0.310113\ttest-mlogloss:0.551147\n",
      "[374]\ttrain-mlogloss:0.309768\ttest-mlogloss:0.551213\n",
      "[375]\ttrain-mlogloss:0.309332\ttest-mlogloss:0.551358\n",
      "[376]\ttrain-mlogloss:0.309044\ttest-mlogloss:0.551429\n",
      "Stopping. Best iteration:\n",
      "[276]\ttrain-mlogloss:0.352126\ttest-mlogloss:0.548378\n",
      "\n",
      "[0.55142875416830295]\n"
     ]
    }
   ],
   "source": [
    "features_to_use.append('manager_skill')\n",
    "categorical = [\"display_address\", \"manager_id\", \"building_id\", \"street_address\",\"street_name\"]\n",
    "features_to_use.extend(categorical)\n",
    "cv_scores = []\n",
    "\n",
    "mini_ranking = 5\n",
    "\n",
    "for dev_index, val_index in KF:\n",
    "        #split the orginal train set into dev_set and val_set\n",
    "        dev_set, val_set = train_df.iloc[dev_index,:] , train_df.iloc[val_index,:] \n",
    "        \n",
    "        #special feature engineering for the trainset\n",
    "        \n",
    "        \n",
    "#====================================================================        \n",
    "        \"\"\"feature engineerings for the categorical features\"\"\"\n",
    "        \n",
    "        dev_set, val_set =manager_skill_eval(dev_set,val_set,\\\n",
    "        unrank_threshold = mini_ranking)\n",
    "        \n",
    "        \n",
    "        #fill substitute the small size values by their mean\n",
    "        for f in categorical:\n",
    "            dev_set,val_set  = singleValueConvert(dev_set,val_set,f,mini_ranking)\n",
    "        \n",
    "            if dev_set[f].dtype=='object':\n",
    "                #print(f)\n",
    "                lbl = preprocessing.LabelEncoder()\n",
    "                lbl.fit(hcc_sorting(dev_set,val_set,f,randomize = 0.05))\n",
    "                dev_set[f] = lbl.transform(list(dev_set[f].values))\n",
    "                val_set[f] = lbl.transform(list(val_set[f].values))\n",
    "                \n",
    "#===================================================================\n",
    "                \n",
    "        #filter the features\n",
    "        dev_X, val_X = dev_set[features_to_use].as_matrix(), val_set[features_to_use].as_matrix()\n",
    "        dev_y, val_y = train_y[dev_index], train_y[val_index]\n",
    "        \n",
    "        preds, model = runXGB(dev_X, dev_y, val_X, val_y,feature_names=features_to_use)\n",
    "        cv_scores.append(log_loss(val_y, preds))\n",
    "        break\n",
    "print cv_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'ManHigh', u'ManLow', u'ManMedium'], dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:123: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n"
     ]
    }
   ],
   "source": [
    "#====================================================================        \n",
    "\"\"\"feature engineerings for the categorical features\"\"\"\n",
    "\n",
    "train_set, test_set =manager_skill_eval(train_df,test_df,\\\n",
    "unrank_threshold = mini_ranking)\n",
    "\n",
    "\n",
    "#fill substitute the small size values by their mean\n",
    "for f in categorical:\n",
    "    train_set,test_set  = singleValueConvert(train_set,test_set,f,mini_ranking)\n",
    "\n",
    "    if train_set[f].dtype=='object':\n",
    "        #print(f)\n",
    "        lbl = preprocessing.LabelEncoder()\n",
    "        lbl.fit(hcc_sorting(train_set,test_set,f,randomize = 0.05))\n",
    "        train_set[f] = lbl.transform(list(train_set[f].values))\n",
    "        test_set[f] = lbl.transform(list(test_set[f].values))\n",
    "                \n",
    "#===================================================================\n",
    "\n",
    "train_X = train_set[features_to_use]\n",
    "test_X = test_set[features_to_use]\n",
    "\n",
    "train_X_m = train_X.as_matrix()\n",
    "test_X_m = test_X.as_matrix()\n",
    "\n",
    "preds, model = runXGB(train_X_m, train_y, test_X_m, num_rounds=280)\n",
    "out_df = pd.DataFrame(preds)\n",
    "out_df.columns = [\"high\", \"medium\", \"low\"]\n",
    "out_df[\"listing_id\"] = test_df.listing_id.values\n",
    "out_df.to_csv(\"xgb_beta1point25addCentralDistance.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([            u'bathrooms',              u'bedrooms',\n",
       "                 u'building_id',               u'created',\n",
       "                 u'description',       u'display_address',\n",
       "                    u'features',        u'interest_level',\n",
       "                    u'latitude',            u'listing_id',\n",
       "                   u'longitude',            u'manager_id',\n",
       "                      u'photos',                 u'price',\n",
       "              u'street_address',            u'num_photos',\n",
       "                u'num_features', u'num_description_words',\n",
       "                u'created_year',         u'created_month',\n",
       "                 u'created_day',          u'created_hour'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_set.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bathrooms': 0.010285346346753424,\n",
       " 'bedrooms': 0.030466314219872576,\n",
       " 'building_id': 0.06857462383082553,\n",
       " 'created_day': 0.046309475396502646,\n",
       " 'created_hour': 0.04346278975193168,\n",
       " 'created_month': 0.006015317879896977,\n",
       " 'display_address': 0.0806899823776603,\n",
       " 'latitude': 0.09202589128371967,\n",
       " 'listing_id': 0.09887149247661652,\n",
       " 'longitude': 0.07911413853870138,\n",
       " 'manager_id': 0.09904093805069812,\n",
       " 'num_description_words': 0.0829605530703538,\n",
       " 'num_features': 0.04493696624644164,\n",
       " 'num_photos': 0.04109055171478921,\n",
       " 'price': 0.0970753693913515,\n",
       " 'street_address': 0.07908024942388504}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ananlysis by the feature importance by weight\n",
    "weight = model.get_score()\n",
    "total = sum(weight.values())\n",
    "for key in weight:\n",
    "    weight[key] = weight[key]*1.0/total\n",
    "weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#ananlysis by the feature importance by gain\n",
    "gain = model.get_score(importance_type='gain')\n",
    "total = sum(gain.values())\n",
    "#for key in gain:\n",
    "#    gain[key] = gain[key]*1.0/total\n",
    "gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bathrooms': 0.15003324661763429,\n",
       " 'bedrooms': 0.11847222747849985,\n",
       " 'building_id': 0.05966144646752775,\n",
       " 'created_day': 0.027908091350767217,\n",
       " 'created_hour': 0.04913703475375256,\n",
       " 'created_month': 0.015463921187964249,\n",
       " 'display_address': 0.051917534421511584,\n",
       " 'latitude': 0.062329192852910546,\n",
       " 'listing_id': 0.05823796559748455,\n",
       " 'longitude': 0.05796867229011468,\n",
       " 'manager_id': 0.0658834209429622,\n",
       " 'num_description_words': 0.04385875263322271,\n",
       " 'num_features': 0.05493240649113651,\n",
       " 'num_photos': 0.053803480057786596,\n",
       " 'price': 0.07955324745771991,\n",
       " 'street_address': 0.050839359399004566}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ananlysis by the feature importance by coverage\n",
    "cover = model.get_score(importance_type='cover')\n",
    "total = sum(cover.values())\n",
    "for key in cover:\n",
    "    cover[key] = cover[key]*1.0/total\n",
    "cover"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
