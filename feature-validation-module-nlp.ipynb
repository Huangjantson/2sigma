{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn import  preprocessing, ensemble\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.cross_validation import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "from mochi import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#try xgboost\n",
    "#fucntion from SRK\n",
    "def runXGB(train_X, train_y, test_X, test_y=None, feature_names=None, \\\n",
    "     seed_val=0, early_stop = 20,num_rounds=10000, eta = 0.1,\\\n",
    "     max_depth = 6,cv_dict = None,verbose_eval=True):\n",
    "    param = {}\n",
    "    param['objective'] = 'multi:softprob'\n",
    "    param['eta'] = eta\n",
    "    param['max_depth'] = max_depth\n",
    "    param['silent'] = 1\n",
    "    param['num_class'] = 3\n",
    "    param['eval_metric'] = \"mlogloss\"\n",
    "    param['min_child_weight'] = 1\n",
    "    param['subsample'] = 0.7\n",
    "    param['colsample_bytree'] = 0.7\n",
    "    param['seed'] = seed_val\n",
    "    num_rounds = num_rounds\n",
    "\n",
    "    plst = list(param.items())\n",
    "    xgtrain = xgb.DMatrix(train_X, label=train_y,feature_names=feature_names)\n",
    "\n",
    "    if test_y is not None:\n",
    "        xgtest = xgb.DMatrix(test_X, label=test_y,feature_names=feature_names)\n",
    "        watchlist = [ (xgtrain,'train'), (xgtest, 'test') ]\n",
    "        model = xgb.train(plst, xgtrain, num_rounds, watchlist,\\\n",
    "        early_stopping_rounds=early_stop,evals_result = cv_dict,verbose_eval = verbose_eval)\n",
    "    else:\n",
    "        xgtest = xgb.DMatrix(test_X,feature_names=feature_names)\n",
    "        model = xgb.train(plst, xgtrain, num_rounds)\n",
    "\n",
    "    pred_test_y = model.predict(xgtest)\n",
    "    return pred_test_y, model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49352, 15)\n",
      "(74659, 14)\n"
     ]
    }
   ],
   "source": [
    "#lodaing data\n",
    "data_path = \"../../kaggleData/2sigma/\"\n",
    "train_file = data_path + \"train.json\"\n",
    "test_file = data_path + \"test.json\"\n",
    "train_df = pd.read_json(train_file)\n",
    "test_df = pd.read_json(test_file)\n",
    "print(train_df.shape)\n",
    "print(test_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#basic numerical features\n",
    "features_to_use  = [\"bathrooms\", \"bedrooms\", \"latitude\", \"longitude\", \"price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#some transfromed features\n",
    "# count of photos #\n",
    "train_df[\"num_photos\"] = train_df[\"photos\"].apply(len)\n",
    "\n",
    "# count of \"features\" #\n",
    "train_df[\"num_features\"] = train_df[\"features\"].apply(len)\n",
    "\n",
    "# count of words present in description column #\n",
    "train_df[\"num_description_words\"] = train_df[\"description\"].apply(lambda x: len(x.split(\" \")))\n",
    "\n",
    "# convert the created column to datetime object so as to extract more features \n",
    "train_df[\"created\"] = pd.to_datetime(train_df[\"created\"])\n",
    "\n",
    "# Let us extract some features like year, month, day, hour from date columns #\n",
    "train_df[\"created_year\"] = train_df[\"created\"].dt.year\n",
    "train_df[\"created_month\"] = train_df[\"created\"].dt.month\n",
    "train_df[\"created_day\"] = train_df[\"created\"].dt.day\n",
    "train_df[\"created_hour\"] = train_df[\"created\"].dt.hour\n",
    "\n",
    "#some new numerical features related to the price\n",
    "train_df[\"price_per_bath\"] =  (train_df[\"price\"]*1.0/train_df[\"bathrooms\"]).replace(np.Inf,-1)\n",
    "train_df[\"price_per_bed\"] = (train_df[\"price\"]*1.0/train_df[\"bedrooms\"]).replace(np.Inf,-1)\n",
    "train_df[\"bath_per_bed\"] = (train_df[\"bathrooms\"]*1.0/train_df[\"bedrooms\"]).replace(np.Inf,-1)\n",
    "train_df[\"price_per_room\"] = (train_df[\"price\"]*1.0/(train_df[\"bedrooms\"]+train_df[\"bathrooms\"])).replace(np.Inf,-1)\n",
    "\n",
    "# adding all these new features to use list # \"listing_id\",\n",
    "features_to_use.extend([\"num_photos\", \"num_features\", \"num_description_words\",\\\n",
    "                        \"created_year\",\"listing_id\", \"created_month\", \"created_day\", \"created_hour\"])\n",
    "#price new features\n",
    "features_to_use.extend([\"price_per_bed\",\"bath_per_bed\",\"price_per_room\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#prepare for training\n",
    "target_num_map = {'high':0, 'medium':1, 'low':2}\n",
    "\n",
    "train_y = np.array(train_df['interest_level'].apply(lambda x: target_num_map[x]))\n",
    "\n",
    "KF=KFold(len(train_df),5,shuffle=True,random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def stripTagsAndUris(x):\n",
    "    uri_re = r'(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:\\'\".,<>???“”‘’]))'\n",
    "    if x:\n",
    "        # BeautifulSoup on content\n",
    "        soup = BeautifulSoup(x, \"html.parser\")\n",
    "        # Stripping all <code> tags with their content if any\n",
    "        if soup.code:\n",
    "            soup.code.decompose()\n",
    "        # Get all the text out of the html\n",
    "        text =  soup.get_text()\n",
    "        # Returning text stripping out all uris\n",
    "        return re.sub(uri_re, \"\", text)\n",
    "    else:\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define punctutaion filter\n",
    "def removePunctuationAndNumber(x):\n",
    "    x = re.sub(r'[^\\x00-\\x7f]',r' ',x)\n",
    "    removing = string.punctuation\n",
    "    removed = re.sub(\"[\"+removing+\"]\", \" \", x)\n",
    "    removed = re.sub(r\"\\d\",'',removed)\n",
    "    return removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getUpperTokens(tokenList):\n",
    "    number = 0\n",
    "    for word in tokenList:\n",
    "        if re.match('[A-Z]{2,}',word)!=None:\n",
    "            number+=1\n",
    "    if len(tokenList) > 0:\n",
    "        return number*1.0/len(tokenList)\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "temp = train_df['description']\\\n",
    "       .apply(stripTagsAndUris)\\\n",
    "       .apply(removePunctuationAndNumber)\\\n",
    "       .apply(lambda x : x.split() if x is not None else [])\\\n",
    "       .apply(getUpperTokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:1.04113\ttest-mlogloss:1.04253\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[1]\ttrain-mlogloss:0.990764\ttest-mlogloss:0.993263\n",
      "[2]\ttrain-mlogloss:0.951165\ttest-mlogloss:0.954688\n",
      "[3]\ttrain-mlogloss:0.913401\ttest-mlogloss:0.918126\n",
      "[4]\ttrain-mlogloss:0.880869\ttest-mlogloss:0.886504\n",
      "[5]\ttrain-mlogloss:0.852162\ttest-mlogloss:0.858837\n",
      "[6]\ttrain-mlogloss:0.826243\ttest-mlogloss:0.833794\n",
      "[7]\ttrain-mlogloss:0.803247\ttest-mlogloss:0.811797\n",
      "[8]\ttrain-mlogloss:0.784647\ttest-mlogloss:0.794119\n",
      "[9]\ttrain-mlogloss:0.767616\ttest-mlogloss:0.778038\n",
      "[10]\ttrain-mlogloss:0.752352\ttest-mlogloss:0.763476\n",
      "[11]\ttrain-mlogloss:0.738303\ttest-mlogloss:0.750363\n",
      "[12]\ttrain-mlogloss:0.725814\ttest-mlogloss:0.738471\n",
      "[13]\ttrain-mlogloss:0.714862\ttest-mlogloss:0.728451\n",
      "[14]\ttrain-mlogloss:0.704626\ttest-mlogloss:0.719134\n",
      "[15]\ttrain-mlogloss:0.695417\ttest-mlogloss:0.710734\n",
      "[16]\ttrain-mlogloss:0.686302\ttest-mlogloss:0.70267\n",
      "[17]\ttrain-mlogloss:0.67857\ttest-mlogloss:0.695723\n",
      "[18]\ttrain-mlogloss:0.671394\ttest-mlogloss:0.689401\n",
      "[19]\ttrain-mlogloss:0.664736\ttest-mlogloss:0.683473\n",
      "[20]\ttrain-mlogloss:0.659317\ttest-mlogloss:0.678666\n",
      "[21]\ttrain-mlogloss:0.653746\ttest-mlogloss:0.673797\n",
      "[22]\ttrain-mlogloss:0.648577\ttest-mlogloss:0.669398\n",
      "[23]\ttrain-mlogloss:0.644442\ttest-mlogloss:0.665839\n",
      "[24]\ttrain-mlogloss:0.640382\ttest-mlogloss:0.662516\n",
      "[25]\ttrain-mlogloss:0.636601\ttest-mlogloss:0.659226\n",
      "[26]\ttrain-mlogloss:0.632969\ttest-mlogloss:0.656146\n",
      "[27]\ttrain-mlogloss:0.629728\ttest-mlogloss:0.653313\n",
      "[28]\ttrain-mlogloss:0.626514\ttest-mlogloss:0.650681\n",
      "[29]\ttrain-mlogloss:0.623363\ttest-mlogloss:0.647926\n",
      "[30]\ttrain-mlogloss:0.620498\ttest-mlogloss:0.645591\n",
      "[31]\ttrain-mlogloss:0.617524\ttest-mlogloss:0.643078\n",
      "[32]\ttrain-mlogloss:0.614783\ttest-mlogloss:0.640943\n",
      "[33]\ttrain-mlogloss:0.612311\ttest-mlogloss:0.639125\n",
      "[34]\ttrain-mlogloss:0.609997\ttest-mlogloss:0.637294\n",
      "[35]\ttrain-mlogloss:0.607574\ttest-mlogloss:0.635588\n",
      "[36]\ttrain-mlogloss:0.605202\ttest-mlogloss:0.634072\n",
      "[37]\ttrain-mlogloss:0.603199\ttest-mlogloss:0.632769\n",
      "[38]\ttrain-mlogloss:0.600822\ttest-mlogloss:0.63122\n",
      "[39]\ttrain-mlogloss:0.598718\ttest-mlogloss:0.629559\n",
      "[40]\ttrain-mlogloss:0.596824\ttest-mlogloss:0.628141\n",
      "[41]\ttrain-mlogloss:0.595071\ttest-mlogloss:0.626807\n",
      "[42]\ttrain-mlogloss:0.593051\ttest-mlogloss:0.625362\n",
      "[43]\ttrain-mlogloss:0.591698\ttest-mlogloss:0.624397\n",
      "[44]\ttrain-mlogloss:0.589857\ttest-mlogloss:0.623241\n",
      "[45]\ttrain-mlogloss:0.588405\ttest-mlogloss:0.622312\n",
      "[46]\ttrain-mlogloss:0.586206\ttest-mlogloss:0.621174\n",
      "[47]\ttrain-mlogloss:0.584723\ttest-mlogloss:0.620274\n",
      "[48]\ttrain-mlogloss:0.583171\ttest-mlogloss:0.619359\n",
      "[49]\ttrain-mlogloss:0.581602\ttest-mlogloss:0.618611\n",
      "[50]\ttrain-mlogloss:0.579985\ttest-mlogloss:0.617667\n",
      "[51]\ttrain-mlogloss:0.578545\ttest-mlogloss:0.616635\n",
      "[52]\ttrain-mlogloss:0.577623\ttest-mlogloss:0.61607\n",
      "[53]\ttrain-mlogloss:0.576386\ttest-mlogloss:0.615478\n",
      "[54]\ttrain-mlogloss:0.575435\ttest-mlogloss:0.614877\n",
      "[55]\ttrain-mlogloss:0.574022\ttest-mlogloss:0.614208\n",
      "[56]\ttrain-mlogloss:0.572909\ttest-mlogloss:0.613607\n",
      "[57]\ttrain-mlogloss:0.571584\ttest-mlogloss:0.613068\n",
      "[58]\ttrain-mlogloss:0.570315\ttest-mlogloss:0.612415\n",
      "[59]\ttrain-mlogloss:0.569141\ttest-mlogloss:0.611836\n",
      "[60]\ttrain-mlogloss:0.568071\ttest-mlogloss:0.611329\n",
      "[61]\ttrain-mlogloss:0.566953\ttest-mlogloss:0.61081\n",
      "[62]\ttrain-mlogloss:0.56553\ttest-mlogloss:0.610152\n",
      "[63]\ttrain-mlogloss:0.564436\ttest-mlogloss:0.609669\n",
      "[64]\ttrain-mlogloss:0.563468\ttest-mlogloss:0.609245\n",
      "[65]\ttrain-mlogloss:0.562345\ttest-mlogloss:0.608747\n",
      "[66]\ttrain-mlogloss:0.561422\ttest-mlogloss:0.608389\n",
      "[67]\ttrain-mlogloss:0.560522\ttest-mlogloss:0.6079\n",
      "[68]\ttrain-mlogloss:0.559126\ttest-mlogloss:0.607351\n",
      "[69]\ttrain-mlogloss:0.557913\ttest-mlogloss:0.606789\n",
      "[70]\ttrain-mlogloss:0.557348\ttest-mlogloss:0.60641\n",
      "[71]\ttrain-mlogloss:0.556075\ttest-mlogloss:0.605878\n",
      "[72]\ttrain-mlogloss:0.554962\ttest-mlogloss:0.605347\n",
      "[73]\ttrain-mlogloss:0.554131\ttest-mlogloss:0.605123\n",
      "[74]\ttrain-mlogloss:0.55311\ttest-mlogloss:0.604779\n",
      "[75]\ttrain-mlogloss:0.552245\ttest-mlogloss:0.60447\n",
      "[76]\ttrain-mlogloss:0.551038\ttest-mlogloss:0.603964\n",
      "[77]\ttrain-mlogloss:0.550193\ttest-mlogloss:0.60366\n",
      "[78]\ttrain-mlogloss:0.549495\ttest-mlogloss:0.603289\n",
      "[79]\ttrain-mlogloss:0.548604\ttest-mlogloss:0.602954\n",
      "[80]\ttrain-mlogloss:0.547684\ttest-mlogloss:0.602603\n",
      "[81]\ttrain-mlogloss:0.546718\ttest-mlogloss:0.6023\n",
      "[82]\ttrain-mlogloss:0.545804\ttest-mlogloss:0.601961\n",
      "[83]\ttrain-mlogloss:0.544924\ttest-mlogloss:0.601578\n",
      "[84]\ttrain-mlogloss:0.544036\ttest-mlogloss:0.601158\n",
      "[85]\ttrain-mlogloss:0.543161\ttest-mlogloss:0.600805\n",
      "[86]\ttrain-mlogloss:0.542272\ttest-mlogloss:0.600491\n",
      "[87]\ttrain-mlogloss:0.541374\ttest-mlogloss:0.60017\n",
      "[88]\ttrain-mlogloss:0.540473\ttest-mlogloss:0.599865\n",
      "[89]\ttrain-mlogloss:0.53945\ttest-mlogloss:0.599454\n",
      "[90]\ttrain-mlogloss:0.538743\ttest-mlogloss:0.599173\n",
      "[91]\ttrain-mlogloss:0.537789\ttest-mlogloss:0.598714\n",
      "[92]\ttrain-mlogloss:0.536795\ttest-mlogloss:0.598439\n",
      "[93]\ttrain-mlogloss:0.536015\ttest-mlogloss:0.598358\n",
      "[94]\ttrain-mlogloss:0.535571\ttest-mlogloss:0.598136\n",
      "[95]\ttrain-mlogloss:0.53458\ttest-mlogloss:0.597976\n",
      "[96]\ttrain-mlogloss:0.533772\ttest-mlogloss:0.597792\n",
      "[97]\ttrain-mlogloss:0.533129\ttest-mlogloss:0.597504\n",
      "[98]\ttrain-mlogloss:0.532044\ttest-mlogloss:0.597155\n",
      "[99]\ttrain-mlogloss:0.53134\ttest-mlogloss:0.596954\n",
      "[100]\ttrain-mlogloss:0.530516\ttest-mlogloss:0.596574\n",
      "[101]\ttrain-mlogloss:0.529916\ttest-mlogloss:0.596442\n",
      "[102]\ttrain-mlogloss:0.529141\ttest-mlogloss:0.596242\n",
      "[103]\ttrain-mlogloss:0.528547\ttest-mlogloss:0.596048\n",
      "[104]\ttrain-mlogloss:0.527761\ttest-mlogloss:0.595844\n",
      "[105]\ttrain-mlogloss:0.527036\ttest-mlogloss:0.59567\n",
      "[106]\ttrain-mlogloss:0.52614\ttest-mlogloss:0.595568\n",
      "[107]\ttrain-mlogloss:0.525339\ttest-mlogloss:0.595472\n",
      "[108]\ttrain-mlogloss:0.52458\ttest-mlogloss:0.595331\n",
      "[109]\ttrain-mlogloss:0.523726\ttest-mlogloss:0.59509\n",
      "[110]\ttrain-mlogloss:0.522847\ttest-mlogloss:0.594826\n",
      "[111]\ttrain-mlogloss:0.522284\ttest-mlogloss:0.594726\n",
      "[112]\ttrain-mlogloss:0.521381\ttest-mlogloss:0.594453\n",
      "[113]\ttrain-mlogloss:0.520623\ttest-mlogloss:0.594218\n",
      "[114]\ttrain-mlogloss:0.519943\ttest-mlogloss:0.594152\n",
      "[115]\ttrain-mlogloss:0.519388\ttest-mlogloss:0.594118\n",
      "[116]\ttrain-mlogloss:0.51879\ttest-mlogloss:0.593871\n",
      "[117]\ttrain-mlogloss:0.518372\ttest-mlogloss:0.593663\n",
      "[118]\ttrain-mlogloss:0.517704\ttest-mlogloss:0.593641\n",
      "[119]\ttrain-mlogloss:0.517115\ttest-mlogloss:0.59346\n",
      "[120]\ttrain-mlogloss:0.516524\ttest-mlogloss:0.593218\n",
      "[121]\ttrain-mlogloss:0.516186\ttest-mlogloss:0.59314\n",
      "[122]\ttrain-mlogloss:0.515361\ttest-mlogloss:0.592914\n",
      "[123]\ttrain-mlogloss:0.514758\ttest-mlogloss:0.592769\n",
      "[124]\ttrain-mlogloss:0.514182\ttest-mlogloss:0.592618\n",
      "[125]\ttrain-mlogloss:0.513517\ttest-mlogloss:0.592492\n",
      "[126]\ttrain-mlogloss:0.512949\ttest-mlogloss:0.592411\n",
      "[127]\ttrain-mlogloss:0.512317\ttest-mlogloss:0.592404\n",
      "[128]\ttrain-mlogloss:0.511558\ttest-mlogloss:0.592214\n",
      "[129]\ttrain-mlogloss:0.510929\ttest-mlogloss:0.592122\n",
      "[130]\ttrain-mlogloss:0.510467\ttest-mlogloss:0.592013\n",
      "[131]\ttrain-mlogloss:0.509826\ttest-mlogloss:0.591896\n",
      "[132]\ttrain-mlogloss:0.509188\ttest-mlogloss:0.59185\n",
      "[133]\ttrain-mlogloss:0.508444\ttest-mlogloss:0.591703\n",
      "[134]\ttrain-mlogloss:0.507752\ttest-mlogloss:0.591612\n",
      "[135]\ttrain-mlogloss:0.507012\ttest-mlogloss:0.591588\n",
      "[136]\ttrain-mlogloss:0.506397\ttest-mlogloss:0.591438\n",
      "[137]\ttrain-mlogloss:0.505828\ttest-mlogloss:0.591459\n",
      "[138]\ttrain-mlogloss:0.505329\ttest-mlogloss:0.591296\n",
      "[139]\ttrain-mlogloss:0.504676\ttest-mlogloss:0.591158\n",
      "[140]\ttrain-mlogloss:0.504146\ttest-mlogloss:0.591069\n",
      "[141]\ttrain-mlogloss:0.503516\ttest-mlogloss:0.591012\n",
      "[142]\ttrain-mlogloss:0.503118\ttest-mlogloss:0.590965\n",
      "[143]\ttrain-mlogloss:0.502587\ttest-mlogloss:0.590981\n",
      "[144]\ttrain-mlogloss:0.501939\ttest-mlogloss:0.590868\n",
      "[145]\ttrain-mlogloss:0.501389\ttest-mlogloss:0.590871\n",
      "[146]\ttrain-mlogloss:0.500685\ttest-mlogloss:0.590738\n",
      "[147]\ttrain-mlogloss:0.500247\ttest-mlogloss:0.59065\n",
      "[148]\ttrain-mlogloss:0.499435\ttest-mlogloss:0.590385\n",
      "[149]\ttrain-mlogloss:0.49881\ttest-mlogloss:0.590288\n",
      "[150]\ttrain-mlogloss:0.498346\ttest-mlogloss:0.590151\n",
      "[151]\ttrain-mlogloss:0.49794\ttest-mlogloss:0.590119\n",
      "[152]\ttrain-mlogloss:0.497562\ttest-mlogloss:0.590068\n",
      "[153]\ttrain-mlogloss:0.497115\ttest-mlogloss:0.590012\n",
      "[154]\ttrain-mlogloss:0.496463\ttest-mlogloss:0.589863\n",
      "[155]\ttrain-mlogloss:0.495778\ttest-mlogloss:0.589743\n",
      "[156]\ttrain-mlogloss:0.495226\ttest-mlogloss:0.58972\n",
      "[157]\ttrain-mlogloss:0.49452\ttest-mlogloss:0.589556\n",
      "[158]\ttrain-mlogloss:0.494028\ttest-mlogloss:0.589407\n",
      "[159]\ttrain-mlogloss:0.493316\ttest-mlogloss:0.589317\n",
      "[160]\ttrain-mlogloss:0.492508\ttest-mlogloss:0.589043\n",
      "[161]\ttrain-mlogloss:0.49186\ttest-mlogloss:0.588783\n",
      "[162]\ttrain-mlogloss:0.491259\ttest-mlogloss:0.588684\n",
      "[163]\ttrain-mlogloss:0.49068\ttest-mlogloss:0.588443\n",
      "[164]\ttrain-mlogloss:0.490201\ttest-mlogloss:0.588508\n",
      "[165]\ttrain-mlogloss:0.489545\ttest-mlogloss:0.588425\n",
      "[166]\ttrain-mlogloss:0.48903\ttest-mlogloss:0.588368\n",
      "[167]\ttrain-mlogloss:0.488289\ttest-mlogloss:0.588122\n",
      "[168]\ttrain-mlogloss:0.48766\ttest-mlogloss:0.587952\n",
      "[169]\ttrain-mlogloss:0.487038\ttest-mlogloss:0.587909\n",
      "[170]\ttrain-mlogloss:0.486546\ttest-mlogloss:0.587879\n",
      "[171]\ttrain-mlogloss:0.485882\ttest-mlogloss:0.587777\n",
      "[172]\ttrain-mlogloss:0.485507\ttest-mlogloss:0.587778\n",
      "[173]\ttrain-mlogloss:0.484826\ttest-mlogloss:0.587674\n",
      "[174]\ttrain-mlogloss:0.484311\ttest-mlogloss:0.587639\n",
      "[175]\ttrain-mlogloss:0.483764\ttest-mlogloss:0.587467\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-ebfe6420e4f8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         preds, model = runXGB(dev_X, dev_y, val_X, val_y,early_stop  = 20,\\\n\u001b[1;32m---> 26\u001b[1;33m                               feature_names = features_to_use,cv_dict = result_dict,verbose_eval=True)\n\u001b[0m\u001b[0;32m     27\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlog_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0mcv_scores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-7edf1623e341>\u001b[0m in \u001b[0;36mrunXGB\u001b[1;34m(train_X, train_y, test_X, test_y, feature_names, seed_val, early_stop, num_rounds, eta, max_depth, cv_dict, verbose_eval)\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mxgtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDMatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mwatchlist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mxgtrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mxgtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'test'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxgtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_rounds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwatchlist\u001b[0m\u001b[1;33m,\u001b[0m        \u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mearly_stop\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mevals_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose_eval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mverbose_eval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mxgtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDMatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\dell\\Anaconda2\\lib\\site-packages\\xgboost-0.6-py2.7.egg\\xgboost\\training.pyc\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, learning_rates, xgb_model, callbacks)\u001b[0m\n\u001b[0;32m    201\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 203\u001b[1;33m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[0;32m    204\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\dell\\Anaconda2\\lib\\site-packages\\xgboost-0.6-py2.7.egg\\xgboost\\training.pyc\u001b[0m in \u001b[0;36m_train_internal\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[1;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\dell\\Anaconda2\\lib\\site-packages\\xgboost-0.6-py2.7.egg\\xgboost\\core.pyc\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m             \u001b[0m_check_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXGBoosterUpdateOneIter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    820\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m             \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#running and getting the cv from xgboost\n",
    "cv_scores = []\n",
    "cv_result = []\n",
    "\n",
    "#K-FOLD already defined.If not ,use\n",
    "#KF=KFold(len(train_X),5,shuffle=True,random_state = 42)\n",
    "i=0\n",
    "for dev_index, val_index in KF:\n",
    "        result_dict = {}\n",
    "        \n",
    "        \"\"\"some preprocessing like feature constructed in cv manners\"\"\"\n",
    "        \n",
    "        #split the orginal train set into dev_set and val_set\n",
    "        dev_set, val_set = train_df.iloc[dev_index,:] , train_df.iloc[val_index,:] \n",
    "        \n",
    "        dev_X, val_X = dev_set[features_to_use].as_matrix(), val_set[features_to_use].as_matrix()\n",
    "        dev_y, val_y = train_y[dev_index], train_y[val_index]\n",
    "        \n",
    "        \"\"\" \n",
    "         runXGB(train_X, train_y, test_X, test_y=None, feature_names=None, \\\n",
    "         seed_val=0, early_stop = 20,num_rounds=10000, eta = 0.1,\\\n",
    "         max_depth = 6,cv_dict = None):\n",
    "         \"\"\"\n",
    "        \n",
    "        preds, model = runXGB(dev_X, dev_y, val_X, val_y,early_stop  = 20,\\\n",
    "                              feature_names = features_to_use,cv_dict = result_dict,verbose_eval=True)\n",
    "        loss = log_loss(val_y, preds)\n",
    "        cv_scores.append(loss)\n",
    "        cv_result.append(result_dict)\n",
    "        i+=1\n",
    "        print 'loss for the turn '+str(i)+' is '+str(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "test0    254\n",
       "test1    260\n",
       "test2    342\n",
       "test3    296\n",
       "test4    273\n",
       "Name: 341, dtype: int32"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#plot the validation curv\n",
    "cvResult = CVstatistics(cv_result,'mlogloss')\n",
    "cvResult.turns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.58505953557896273"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cvResult.validCurve(stop=False)\n",
    "#some errors at certain turn to see the descending\n",
    "cv_scores\n",
    "np.mean(cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('bathrooms', 0.09725565800916634), ('price', 0.09499099365937312), ('price_per_room', 0.09205531264056366), ('created_hour', 0.09194288123746672), ('price_per_bed', 0.08666569315447636), ('num_photos', 0.07428368001559033), ('bedrooms', 0.07012971325635668), ('bath_per_bed', 0.061415666612366956), ('num_features', 0.06043546567125035), ('latitude', 0.058875420604080596), ('longitude', 0.05741437403240373), ('num_description_words', 0.04480527126354566), ('listing_id', 0.042255845208890516), ('created_day', 0.03503384908900436), ('created_month', 0.03244017554546452)]\n"
     ]
    }
   ],
   "source": [
    "#show the importance of the features\n",
    "showImportance(model,'gain')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
