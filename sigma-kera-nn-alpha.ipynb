{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.cross_validation import KFold,StratifiedKFold\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_path = '/home/raku/kaggleData/2sigma/lr4/'\n",
    "store = '/home/raku/kaggleData/2sigma/nn'\n",
    "\n",
    "train_df=pd.read_json(data_path+'lr4-n-train.json')\n",
    "test_df=pd.read_json(data_path+'lr4-n-test.json')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "223\n"
     ]
    }
   ],
   "source": [
    "pickl_file = '/home/raku/kaggleData/2sigma/loglr/'+'loglrfeatures.pickle'\n",
    "fileObject = open(pickl_file,'r') \n",
    "features=pickle.load(fileObject)   \n",
    "fileObject.close()\n",
    "print len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.regularizers import l2\n",
    "from keras import optimizers\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nn_model(features,num_classes=3,lr=0.1):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64,  \n",
    "                    activation='softplus',\n",
    "                    input_shape = (len(features),),\n",
    "                                  kernel_initializer='he_normal',\n",
    "                                  kernel_regularizer=l2(0.000025)\n",
    "                                  ))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Dense(16,\n",
    "                    activation='softplus', \n",
    "                    kernel_initializer='he_normal',\n",
    "                    kernel_regularizer=l2(0.000025)\n",
    "                    ))\n",
    "    model.add(Dropout(0.1))\n",
    "\n",
    "    model.add(Dense(units=num_classes, \n",
    "                    activation='softmax', \n",
    "                    kernel_initializer='he_normal',\n",
    "                    ))\n",
    "    opt = optimizers.Adadelta(lr=1)\n",
    "    model.compile(loss='sparse_categorical_crossentropy', \n",
    "                  optimizer=opt,\n",
    "                  metrics=['accuracy']\n",
    "                  )\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#prepare for training\n",
    "target_num_map = {'high':0, 'medium':1, 'low':2}\n",
    "\n",
    "train_y = np.array(train_df['interest_level'].apply(lambda x: target_num_map[x]))\n",
    "\n",
    "KF=StratifiedKFold(train_y,5,shuffle=True,random_state = 2333)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 39481 samples, validate on 9871 samples\n",
      "Epoch 1/1000\n",
      "8s - loss: 0.7119 - acc: 0.7015 - val_loss: 0.6261 - val_acc: 0.7236\n",
      "Epoch 2/1000\n",
      "9s - loss: 0.6252 - acc: 0.7243 - val_loss: 0.6121 - val_acc: 0.7269\n",
      "Epoch 3/1000\n",
      "9s - loss: 0.6096 - acc: 0.7309 - val_loss: 0.6084 - val_acc: 0.7297\n",
      "Epoch 4/1000\n",
      "8s - loss: 0.6038 - acc: 0.7346 - val_loss: 0.6044 - val_acc: 0.7292\n",
      "Epoch 5/1000\n",
      "8s - loss: 0.5984 - acc: 0.7358 - val_loss: 0.6031 - val_acc: 0.7283\n",
      "Epoch 6/1000\n",
      "9s - loss: 0.5959 - acc: 0.7377 - val_loss: 0.6019 - val_acc: 0.7294\n",
      "Epoch 7/1000\n",
      "7s - loss: 0.5930 - acc: 0.7381 - val_loss: 0.6009 - val_acc: 0.7295\n",
      "Epoch 8/1000\n",
      "10s - loss: 0.5889 - acc: 0.7400 - val_loss: 0.5997 - val_acc: 0.7327\n",
      "Epoch 9/1000\n",
      "9s - loss: 0.5876 - acc: 0.7397 - val_loss: 0.5991 - val_acc: 0.7344\n",
      "Epoch 10/1000\n",
      "9s - loss: 0.5874 - acc: 0.7411 - val_loss: 0.5971 - val_acc: 0.7343\n",
      "Epoch 11/1000\n",
      "9s - loss: 0.5860 - acc: 0.7414 - val_loss: 0.5958 - val_acc: 0.7345\n",
      "Epoch 12/1000\n",
      "7s - loss: 0.5827 - acc: 0.7415 - val_loss: 0.5959 - val_acc: 0.7344\n",
      "Epoch 13/1000\n",
      "9s - loss: 0.5827 - acc: 0.7430 - val_loss: 0.5946 - val_acc: 0.7349\n",
      "Epoch 14/1000\n",
      "9s - loss: 0.5816 - acc: 0.7426 - val_loss: 0.5954 - val_acc: 0.7329\n",
      "Epoch 15/1000\n",
      "8s - loss: 0.5801 - acc: 0.7435 - val_loss: 0.5947 - val_acc: 0.7350\n",
      "Epoch 16/1000\n",
      "7s - loss: 0.5801 - acc: 0.7432 - val_loss: 0.5924 - val_acc: 0.7354\n",
      "Epoch 17/1000\n",
      "7s - loss: 0.5788 - acc: 0.7437 - val_loss: 0.5926 - val_acc: 0.7364\n",
      "Epoch 18/1000\n",
      "7s - loss: 0.5775 - acc: 0.7444 - val_loss: 0.5927 - val_acc: 0.7341\n",
      "Epoch 19/1000\n",
      "7s - loss: 0.5765 - acc: 0.7451 - val_loss: 0.5926 - val_acc: 0.7363\n",
      "Epoch 20/1000\n",
      "7s - loss: 0.5746 - acc: 0.7451 - val_loss: 0.5900 - val_acc: 0.7353\n",
      "Epoch 21/1000\n",
      "7s - loss: 0.5745 - acc: 0.7467 - val_loss: 0.5910 - val_acc: 0.7362\n",
      "Epoch 22/1000\n",
      "8s - loss: 0.5737 - acc: 0.7449 - val_loss: 0.5906 - val_acc: 0.7355\n",
      "Epoch 23/1000\n",
      "7s - loss: 0.5732 - acc: 0.7464 - val_loss: 0.5923 - val_acc: 0.7368\n",
      "Epoch 24/1000\n",
      "7s - loss: 0.5711 - acc: 0.7456 - val_loss: 0.5898 - val_acc: 0.7369\n",
      "Epoch 25/1000\n",
      "7s - loss: 0.5726 - acc: 0.7461 - val_loss: 0.5909 - val_acc: 0.7359\n",
      "Epoch 26/1000\n",
      "7s - loss: 0.5714 - acc: 0.7464 - val_loss: 0.5894 - val_acc: 0.7379\n",
      "Epoch 27/1000\n",
      "7s - loss: 0.5699 - acc: 0.7469 - val_loss: 0.5887 - val_acc: 0.7360\n",
      "Epoch 28/1000\n",
      "8s - loss: 0.5693 - acc: 0.7484 - val_loss: 0.5892 - val_acc: 0.7386\n",
      "Epoch 29/1000\n",
      "7s - loss: 0.5679 - acc: 0.7471 - val_loss: 0.5896 - val_acc: 0.7374\n",
      "Epoch 30/1000\n",
      "8s - loss: 0.5687 - acc: 0.7498 - val_loss: 0.5888 - val_acc: 0.7372\n",
      "Epoch 31/1000\n",
      "8s - loss: 0.5679 - acc: 0.7477 - val_loss: 0.5882 - val_acc: 0.7374\n",
      "Epoch 32/1000\n",
      "7s - loss: 0.5666 - acc: 0.7486 - val_loss: 0.5883 - val_acc: 0.7382\n",
      "Epoch 33/1000\n",
      "6s - loss: 0.5674 - acc: 0.7509 - val_loss: 0.5876 - val_acc: 0.7379\n",
      "Epoch 34/1000\n",
      "7s - loss: 0.5661 - acc: 0.7514 - val_loss: 0.5898 - val_acc: 0.7387\n",
      "Epoch 35/1000\n",
      "7s - loss: 0.5674 - acc: 0.7474 - val_loss: 0.5882 - val_acc: 0.7379\n",
      "Epoch 36/1000\n",
      "8s - loss: 0.5662 - acc: 0.7488 - val_loss: 0.5877 - val_acc: 0.7379\n",
      "Epoch 37/1000\n",
      "7s - loss: 0.5645 - acc: 0.7504 - val_loss: 0.5886 - val_acc: 0.7393\n",
      "Epoch 38/1000\n",
      "8s - loss: 0.5648 - acc: 0.7513 - val_loss: 0.5891 - val_acc: 0.7387\n",
      "Epoch 39/1000\n",
      "8s - loss: 0.5655 - acc: 0.7491 - val_loss: 0.5876 - val_acc: 0.7381\n",
      "Epoch 40/1000\n",
      "7s - loss: 0.5643 - acc: 0.7505 - val_loss: 0.5876 - val_acc: 0.7401\n",
      "Epoch 41/1000\n",
      "6s - loss: 0.5625 - acc: 0.7516 - val_loss: 0.5879 - val_acc: 0.7401\n",
      "Epoch 42/1000\n",
      "7s - loss: 0.5626 - acc: 0.7506 - val_loss: 0.5887 - val_acc: 0.7393\n",
      "Epoch 43/1000\n",
      "8s - loss: 0.5619 - acc: 0.7510 - val_loss: 0.5867 - val_acc: 0.7398\n",
      "Epoch 44/1000\n",
      "7s - loss: 0.5623 - acc: 0.7522 - val_loss: 0.5873 - val_acc: 0.7383\n",
      "Epoch 45/1000\n",
      "8s - loss: 0.5628 - acc: 0.7506 - val_loss: 0.5864 - val_acc: 0.7392\n",
      "Epoch 46/1000\n",
      "9s - loss: 0.5616 - acc: 0.7546 - val_loss: 0.5882 - val_acc: 0.7378\n",
      "Epoch 47/1000\n",
      "7s - loss: 0.5616 - acc: 0.7508 - val_loss: 0.5891 - val_acc: 0.7385\n",
      "Epoch 48/1000\n",
      "8s - loss: 0.5604 - acc: 0.7519 - val_loss: 0.5873 - val_acc: 0.7394\n",
      "Epoch 49/1000\n",
      "7s - loss: 0.5590 - acc: 0.7541 - val_loss: 0.5874 - val_acc: 0.7382\n",
      "Epoch 50/1000\n",
      "8s - loss: 0.5606 - acc: 0.7523 - val_loss: 0.5876 - val_acc: 0.7380\n",
      "Epoch 51/1000\n",
      "8s - loss: 0.5593 - acc: 0.7533 - val_loss: 0.5877 - val_acc: 0.7384\n",
      "Epoch 52/1000\n",
      "7s - loss: 0.5587 - acc: 0.7527 - val_loss: 0.5884 - val_acc: 0.7379\n",
      "Epoch 53/1000\n",
      "8s - loss: 0.5586 - acc: 0.7542 - val_loss: 0.5895 - val_acc: 0.7373\n",
      "Epoch 54/1000\n",
      "8s - loss: 0.5587 - acc: 0.7517 - val_loss: 0.5888 - val_acc: 0.7379\n",
      "Epoch 55/1000\n",
      "7s - loss: 0.5562 - acc: 0.7560 - val_loss: 0.5878 - val_acc: 0.7404\n",
      "Epoch 56/1000\n",
      "8s - loss: 0.5601 - acc: 0.7532 - val_loss: 0.5894 - val_acc: 0.7370\n",
      "Epoch 57/1000\n",
      "8s - loss: 0.5582 - acc: 0.7542 - val_loss: 0.5893 - val_acc: 0.7402\n",
      "Epoch 58/1000\n",
      "7s - loss: 0.5578 - acc: 0.7553 - val_loss: 0.5879 - val_acc: 0.7384\n",
      "Epoch 59/1000\n",
      "6s - loss: 0.5583 - acc: 0.7552 - val_loss: 0.5888 - val_acc: 0.7408\n",
      "Epoch 60/1000\n",
      "9s - loss: 0.5594 - acc: 0.7533 - val_loss: 0.5886 - val_acc: 0.7396\n",
      "Epoch 61/1000\n",
      "7s - loss: 0.5595 - acc: 0.7554 - val_loss: 0.5891 - val_acc: 0.7404\n",
      "Epoch 62/1000\n",
      "8s - loss: 0.5550 - acc: 0.7562 - val_loss: 0.5910 - val_acc: 0.7374\n",
      "Epoch 63/1000\n",
      "7s - loss: 0.5595 - acc: 0.7523 - val_loss: 0.5889 - val_acc: 0.7378\n",
      "Epoch 64/1000\n",
      "8s - loss: 0.5548 - acc: 0.7543 - val_loss: 0.5882 - val_acc: 0.7386\n",
      "Epoch 65/1000\n",
      "7s - loss: 0.5577 - acc: 0.7553 - val_loss: 0.5880 - val_acc: 0.7386\n",
      "Epoch 66/1000\n",
      "7s - loss: 0.5565 - acc: 0.7551 - val_loss: 0.5894 - val_acc: 0.7385\n",
      "9184/9871 [==========================>...] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bthe cv_score for the 1 turn is:\n",
      "0.578195601839\n",
      "Train on 39481 samples, validate on 9871 samples\n",
      "Epoch 1/1000\n",
      "8s - loss: 0.7153 - acc: 0.7034 - val_loss: 0.6068 - val_acc: 0.7322\n",
      "Epoch 2/1000\n",
      "7s - loss: 0.6313 - acc: 0.7251 - val_loss: 0.5924 - val_acc: 0.7378\n",
      "Epoch 3/1000\n",
      "7s - loss: 0.6150 - acc: 0.7283 - val_loss: 0.5866 - val_acc: 0.7380\n",
      "Epoch 4/1000\n",
      "8s - loss: 0.6093 - acc: 0.7299 - val_loss: 0.5850 - val_acc: 0.7405\n",
      "Epoch 5/1000\n",
      "7s - loss: 0.6031 - acc: 0.7325 - val_loss: 0.5821 - val_acc: 0.7433\n",
      "Epoch 6/1000\n",
      "8s - loss: 0.5996 - acc: 0.7351 - val_loss: 0.5811 - val_acc: 0.7414\n",
      "Epoch 7/1000\n",
      "6s - loss: 0.5972 - acc: 0.7352 - val_loss: 0.5795 - val_acc: 0.7431\n",
      "Epoch 8/1000\n",
      "7s - loss: 0.5952 - acc: 0.7368 - val_loss: 0.5781 - val_acc: 0.7420\n",
      "Epoch 9/1000\n",
      "6s - loss: 0.5914 - acc: 0.7381 - val_loss: 0.5771 - val_acc: 0.7428\n",
      "Epoch 10/1000\n",
      "8s - loss: 0.5922 - acc: 0.7376 - val_loss: 0.5763 - val_acc: 0.7436\n",
      "Epoch 11/1000\n",
      "7s - loss: 0.5889 - acc: 0.7394 - val_loss: 0.5764 - val_acc: 0.7420\n",
      "Epoch 12/1000\n",
      "8s - loss: 0.5879 - acc: 0.7407 - val_loss: 0.5749 - val_acc: 0.7443\n",
      "Epoch 13/1000\n",
      "7s - loss: 0.5858 - acc: 0.7394 - val_loss: 0.5747 - val_acc: 0.7449\n",
      "Epoch 14/1000\n",
      "7s - loss: 0.5857 - acc: 0.7407 - val_loss: 0.5746 - val_acc: 0.7440\n",
      "Epoch 15/1000\n",
      "7s - loss: 0.5832 - acc: 0.7411 - val_loss: 0.5736 - val_acc: 0.7436\n",
      "Epoch 16/1000\n",
      "8s - loss: 0.5843 - acc: 0.7415 - val_loss: 0.5740 - val_acc: 0.7441\n",
      "Epoch 17/1000\n",
      "8s - loss: 0.5815 - acc: 0.7414 - val_loss: 0.5734 - val_acc: 0.7428\n",
      "Epoch 18/1000\n",
      "7s - loss: 0.5814 - acc: 0.7425 - val_loss: 0.5726 - val_acc: 0.7427\n",
      "Epoch 19/1000\n",
      "9s - loss: 0.5792 - acc: 0.7435 - val_loss: 0.5727 - val_acc: 0.7432\n",
      "Epoch 20/1000\n",
      "6s - loss: 0.5797 - acc: 0.7442 - val_loss: 0.5731 - val_acc: 0.7439\n",
      "Epoch 21/1000\n",
      "7s - loss: 0.5780 - acc: 0.7445 - val_loss: 0.5718 - val_acc: 0.7441\n",
      "Epoch 22/1000\n",
      "6s - loss: 0.5792 - acc: 0.7436 - val_loss: 0.5720 - val_acc: 0.7436\n",
      "Epoch 23/1000\n",
      "7s - loss: 0.5769 - acc: 0.7440 - val_loss: 0.5715 - val_acc: 0.7441\n",
      "Epoch 24/1000\n",
      "5s - loss: 0.5764 - acc: 0.7449 - val_loss: 0.5713 - val_acc: 0.7443\n",
      "Epoch 25/1000\n",
      "7s - loss: 0.5762 - acc: 0.7448 - val_loss: 0.5710 - val_acc: 0.7447\n",
      "Epoch 26/1000\n",
      "7s - loss: 0.5752 - acc: 0.7445 - val_loss: 0.5709 - val_acc: 0.7451\n",
      "Epoch 27/1000\n",
      "7s - loss: 0.5759 - acc: 0.7459 - val_loss: 0.5706 - val_acc: 0.7441\n",
      "Epoch 28/1000\n",
      "7s - loss: 0.5725 - acc: 0.7463 - val_loss: 0.5703 - val_acc: 0.7440\n",
      "Epoch 29/1000\n",
      "5s - loss: 0.5727 - acc: 0.7476 - val_loss: 0.5704 - val_acc: 0.7441\n",
      "Epoch 30/1000\n",
      "8s - loss: 0.5713 - acc: 0.7458 - val_loss: 0.5706 - val_acc: 0.7442\n",
      "Epoch 31/1000\n",
      "7s - loss: 0.5718 - acc: 0.7466 - val_loss: 0.5699 - val_acc: 0.7445\n",
      "Epoch 32/1000\n",
      "8s - loss: 0.5706 - acc: 0.7480 - val_loss: 0.5703 - val_acc: 0.7435\n",
      "Epoch 33/1000\n",
      "7s - loss: 0.5703 - acc: 0.7469 - val_loss: 0.5692 - val_acc: 0.7429\n",
      "Epoch 34/1000\n",
      "8s - loss: 0.5693 - acc: 0.7467 - val_loss: 0.5704 - val_acc: 0.7449\n",
      "Epoch 35/1000\n",
      "7s - loss: 0.5689 - acc: 0.7463 - val_loss: 0.5702 - val_acc: 0.7439\n",
      "Epoch 36/1000\n",
      "7s - loss: 0.5682 - acc: 0.7482 - val_loss: 0.5695 - val_acc: 0.7442\n",
      "Epoch 37/1000\n",
      "8s - loss: 0.5676 - acc: 0.7480 - val_loss: 0.5698 - val_acc: 0.7431\n",
      "Epoch 38/1000\n",
      "7s - loss: 0.5676 - acc: 0.7484 - val_loss: 0.5694 - val_acc: 0.7450\n",
      "Epoch 39/1000\n",
      "6s - loss: 0.5667 - acc: 0.7501 - val_loss: 0.5688 - val_acc: 0.7451\n",
      "Epoch 40/1000\n",
      "7s - loss: 0.5673 - acc: 0.7492 - val_loss: 0.5697 - val_acc: 0.7459\n",
      "Epoch 41/1000\n",
      "7s - loss: 0.5670 - acc: 0.7468 - val_loss: 0.5703 - val_acc: 0.7449\n",
      "Epoch 42/1000\n",
      "7s - loss: 0.5666 - acc: 0.7509 - val_loss: 0.5699 - val_acc: 0.7442\n",
      "Epoch 43/1000\n",
      "8s - loss: 0.5668 - acc: 0.7496 - val_loss: 0.5690 - val_acc: 0.7449\n",
      "Epoch 44/1000\n",
      "7s - loss: 0.5658 - acc: 0.7495 - val_loss: 0.5702 - val_acc: 0.7430\n",
      "Epoch 45/1000\n",
      "6s - loss: 0.5645 - acc: 0.7516 - val_loss: 0.5695 - val_acc: 0.7463\n",
      "Epoch 46/1000\n",
      "6s - loss: 0.5647 - acc: 0.7519 - val_loss: 0.5695 - val_acc: 0.7448\n",
      "Epoch 47/1000\n",
      "6s - loss: 0.5656 - acc: 0.7519 - val_loss: 0.5701 - val_acc: 0.7453\n",
      "Epoch 48/1000\n",
      "8s - loss: 0.5656 - acc: 0.7520 - val_loss: 0.5702 - val_acc: 0.7443\n",
      "Epoch 49/1000\n",
      "7s - loss: 0.5627 - acc: 0.7505 - val_loss: 0.5712 - val_acc: 0.7455\n",
      "Epoch 50/1000\n",
      "8s - loss: 0.5629 - acc: 0.7504 - val_loss: 0.5704 - val_acc: 0.7450\n",
      "Epoch 51/1000\n",
      "7s - loss: 0.5629 - acc: 0.7518 - val_loss: 0.5697 - val_acc: 0.7438\n",
      "Epoch 52/1000\n",
      "9s - loss: 0.5622 - acc: 0.7518 - val_loss: 0.5707 - val_acc: 0.7447\n",
      "Epoch 53/1000\n",
      "7s - loss: 0.5628 - acc: 0.7498 - val_loss: 0.5705 - val_acc: 0.7446\n",
      "Epoch 54/1000\n",
      "7s - loss: 0.5622 - acc: 0.7517 - val_loss: 0.5710 - val_acc: 0.7441\n",
      "Epoch 55/1000\n",
      "6s - loss: 0.5612 - acc: 0.7519 - val_loss: 0.5709 - val_acc: 0.7446\n",
      "Epoch 56/1000\n",
      "7s - loss: 0.5606 - acc: 0.7530 - val_loss: 0.5710 - val_acc: 0.7450\n",
      "Epoch 57/1000\n",
      "7s - loss: 0.5608 - acc: 0.7508 - val_loss: 0.5716 - val_acc: 0.7440\n",
      "Epoch 58/1000\n",
      "7s - loss: 0.5624 - acc: 0.7527 - val_loss: 0.5713 - val_acc: 0.7446\n",
      "Epoch 59/1000\n",
      "8s - loss: 0.5611 - acc: 0.7526 - val_loss: 0.5711 - val_acc: 0.7442\n",
      "Epoch 60/1000\n",
      "6s - loss: 0.5615 - acc: 0.7536 - val_loss: 0.5724 - val_acc: 0.7445\n",
      "9792/9871 [============================>.] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bthe cv_score for the 2 turn is:\n",
      "0.561210018075\n",
      "Train on 39481 samples, validate on 9871 samples\n",
      "Epoch 1/1000\n",
      "8s - loss: 0.7088 - acc: 0.7025 - val_loss: 0.6116 - val_acc: 0.7291\n",
      "Epoch 2/1000\n",
      "8s - loss: 0.6275 - acc: 0.7259 - val_loss: 0.5992 - val_acc: 0.7360\n",
      "Epoch 3/1000\n",
      "9s - loss: 0.6126 - acc: 0.7311 - val_loss: 0.5944 - val_acc: 0.7347\n",
      "Epoch 4/1000\n",
      "7s - loss: 0.6061 - acc: 0.7335 - val_loss: 0.5912 - val_acc: 0.7344\n",
      "Epoch 5/1000\n",
      "8s - loss: 0.6015 - acc: 0.7359 - val_loss: 0.5897 - val_acc: 0.7376\n",
      "Epoch 6/1000\n",
      "7s - loss: 0.5972 - acc: 0.7356 - val_loss: 0.5879 - val_acc: 0.7376\n",
      "Epoch 7/1000\n",
      "7s - loss: 0.5974 - acc: 0.7350 - val_loss: 0.5871 - val_acc: 0.7372\n",
      "Epoch 8/1000\n",
      "7s - loss: 0.5928 - acc: 0.7381 - val_loss: 0.5868 - val_acc: 0.7381\n",
      "Epoch 9/1000\n",
      "7s - loss: 0.5920 - acc: 0.7391 - val_loss: 0.5853 - val_acc: 0.7383\n",
      "Epoch 10/1000\n",
      "7s - loss: 0.5913 - acc: 0.7383 - val_loss: 0.5848 - val_acc: 0.7362\n",
      "Epoch 11/1000\n",
      "7s - loss: 0.5871 - acc: 0.7405 - val_loss: 0.5832 - val_acc: 0.7392\n",
      "Epoch 12/1000\n",
      "7s - loss: 0.5875 - acc: 0.7403 - val_loss: 0.5836 - val_acc: 0.7391\n",
      "Epoch 13/1000\n",
      "6s - loss: 0.5864 - acc: 0.7400 - val_loss: 0.5818 - val_acc: 0.7390\n",
      "Epoch 14/1000\n",
      "8s - loss: 0.5852 - acc: 0.7419 - val_loss: 0.5814 - val_acc: 0.7405\n",
      "Epoch 15/1000\n",
      "8s - loss: 0.5836 - acc: 0.7410 - val_loss: 0.5808 - val_acc: 0.7400\n",
      "Epoch 16/1000\n",
      "8s - loss: 0.5833 - acc: 0.7420 - val_loss: 0.5799 - val_acc: 0.7391\n",
      "Epoch 17/1000\n",
      "7s - loss: 0.5810 - acc: 0.7420 - val_loss: 0.5797 - val_acc: 0.7408\n",
      "Epoch 18/1000\n",
      "8s - loss: 0.5813 - acc: 0.7432 - val_loss: 0.5797 - val_acc: 0.7379\n",
      "Epoch 19/1000\n",
      "8s - loss: 0.5795 - acc: 0.7412 - val_loss: 0.5788 - val_acc: 0.7405\n",
      "Epoch 20/1000\n",
      "8s - loss: 0.5786 - acc: 0.7431 - val_loss: 0.5777 - val_acc: 0.7395\n",
      "Epoch 21/1000\n",
      "8s - loss: 0.5767 - acc: 0.7452 - val_loss: 0.5771 - val_acc: 0.7409\n",
      "Epoch 22/1000\n",
      "7s - loss: 0.5766 - acc: 0.7438 - val_loss: 0.5772 - val_acc: 0.7421\n",
      "Epoch 23/1000\n",
      "8s - loss: 0.5768 - acc: 0.7436 - val_loss: 0.5770 - val_acc: 0.7400\n",
      "Epoch 24/1000\n",
      "7s - loss: 0.5759 - acc: 0.7446 - val_loss: 0.5767 - val_acc: 0.7413\n",
      "Epoch 25/1000\n",
      "8s - loss: 0.5756 - acc: 0.7459 - val_loss: 0.5763 - val_acc: 0.7416\n",
      "Epoch 26/1000\n",
      "8s - loss: 0.5722 - acc: 0.7464 - val_loss: 0.5749 - val_acc: 0.7433\n",
      "Epoch 27/1000\n",
      "9s - loss: 0.5750 - acc: 0.7453 - val_loss: 0.5754 - val_acc: 0.7433\n",
      "Epoch 28/1000\n",
      "7s - loss: 0.5715 - acc: 0.7455 - val_loss: 0.5756 - val_acc: 0.7429\n",
      "Epoch 29/1000\n",
      "7s - loss: 0.5724 - acc: 0.7462 - val_loss: 0.5758 - val_acc: 0.7429\n",
      "Epoch 30/1000\n",
      "8s - loss: 0.5709 - acc: 0.7478 - val_loss: 0.5761 - val_acc: 0.7437\n",
      "Epoch 31/1000\n",
      "8s - loss: 0.5727 - acc: 0.7487 - val_loss: 0.5748 - val_acc: 0.7448\n",
      "Epoch 32/1000\n",
      "7s - loss: 0.5711 - acc: 0.7485 - val_loss: 0.5750 - val_acc: 0.7422\n",
      "Epoch 33/1000\n",
      "7s - loss: 0.5708 - acc: 0.7487 - val_loss: 0.5745 - val_acc: 0.7426\n",
      "Epoch 34/1000\n",
      "7s - loss: 0.5694 - acc: 0.7482 - val_loss: 0.5749 - val_acc: 0.7431\n",
      "Epoch 35/1000\n",
      "7s - loss: 0.5692 - acc: 0.7496 - val_loss: 0.5743 - val_acc: 0.7431\n",
      "Epoch 36/1000\n",
      "7s - loss: 0.5694 - acc: 0.7504 - val_loss: 0.5743 - val_acc: 0.7446\n",
      "Epoch 37/1000\n",
      "8s - loss: 0.5679 - acc: 0.7489 - val_loss: 0.5742 - val_acc: 0.7427\n",
      "Epoch 38/1000\n",
      "8s - loss: 0.5684 - acc: 0.7481 - val_loss: 0.5744 - val_acc: 0.7423\n",
      "Epoch 39/1000\n",
      "6s - loss: 0.5672 - acc: 0.7506 - val_loss: 0.5733 - val_acc: 0.7436\n",
      "Epoch 40/1000\n",
      "7s - loss: 0.5657 - acc: 0.7498 - val_loss: 0.5731 - val_acc: 0.7450\n",
      "Epoch 41/1000\n",
      "7s - loss: 0.5670 - acc: 0.7494 - val_loss: 0.5729 - val_acc: 0.7452\n",
      "Epoch 42/1000\n",
      "7s - loss: 0.5671 - acc: 0.7483 - val_loss: 0.5732 - val_acc: 0.7446\n",
      "Epoch 43/1000\n",
      "7s - loss: 0.5660 - acc: 0.7506 - val_loss: 0.5733 - val_acc: 0.7456\n",
      "Epoch 44/1000\n",
      "10s - loss: 0.5655 - acc: 0.7474 - val_loss: 0.5725 - val_acc: 0.7444\n",
      "Epoch 45/1000\n",
      "7s - loss: 0.5638 - acc: 0.7504 - val_loss: 0.5733 - val_acc: 0.7462\n",
      "Epoch 46/1000\n",
      "8s - loss: 0.5644 - acc: 0.7513 - val_loss: 0.5725 - val_acc: 0.7468\n",
      "Epoch 47/1000\n",
      "7s - loss: 0.5646 - acc: 0.7515 - val_loss: 0.5725 - val_acc: 0.7472\n",
      "Epoch 48/1000\n",
      "7s - loss: 0.5619 - acc: 0.7520 - val_loss: 0.5730 - val_acc: 0.7453\n",
      "Epoch 49/1000\n",
      "8s - loss: 0.5650 - acc: 0.7522 - val_loss: 0.5729 - val_acc: 0.7460\n",
      "Epoch 50/1000\n",
      "7s - loss: 0.5637 - acc: 0.7516 - val_loss: 0.5742 - val_acc: 0.7464\n",
      "Epoch 51/1000\n",
      "8s - loss: 0.5650 - acc: 0.7529 - val_loss: 0.5731 - val_acc: 0.7479\n",
      "Epoch 52/1000\n",
      "9s - loss: 0.5630 - acc: 0.7501 - val_loss: 0.5731 - val_acc: 0.7466\n",
      "Epoch 53/1000\n",
      "7s - loss: 0.5630 - acc: 0.7496 - val_loss: 0.5731 - val_acc: 0.7454\n",
      "Epoch 54/1000\n",
      "7s - loss: 0.5615 - acc: 0.7523 - val_loss: 0.5724 - val_acc: 0.7454\n",
      "Epoch 55/1000\n",
      "9s - loss: 0.5631 - acc: 0.7512 - val_loss: 0.5736 - val_acc: 0.7460\n",
      "Epoch 56/1000\n",
      "8s - loss: 0.5618 - acc: 0.7531 - val_loss: 0.5725 - val_acc: 0.7477\n",
      "Epoch 57/1000\n",
      "6s - loss: 0.5605 - acc: 0.7521 - val_loss: 0.5728 - val_acc: 0.7478\n",
      "Epoch 58/1000\n",
      "8s - loss: 0.5620 - acc: 0.7509 - val_loss: 0.5722 - val_acc: 0.7477\n",
      "Epoch 59/1000\n",
      "8s - loss: 0.5614 - acc: 0.7534 - val_loss: 0.5732 - val_acc: 0.7487\n",
      "Epoch 60/1000\n",
      "8s - loss: 0.5600 - acc: 0.7533 - val_loss: 0.5730 - val_acc: 0.7485\n",
      "Epoch 61/1000\n",
      "6s - loss: 0.5611 - acc: 0.7531 - val_loss: 0.5733 - val_acc: 0.7467\n",
      "Epoch 62/1000\n",
      "8s - loss: 0.5608 - acc: 0.7545 - val_loss: 0.5731 - val_acc: 0.7466\n",
      "Epoch 63/1000\n",
      "7s - loss: 0.5613 - acc: 0.7523 - val_loss: 0.5716 - val_acc: 0.7475\n",
      "Epoch 64/1000\n",
      "7s - loss: 0.5598 - acc: 0.7528 - val_loss: 0.5728 - val_acc: 0.7467\n",
      "Epoch 65/1000\n",
      "7s - loss: 0.5621 - acc: 0.7531 - val_loss: 0.5718 - val_acc: 0.7485\n",
      "Epoch 66/1000\n",
      "8s - loss: 0.5580 - acc: 0.7545 - val_loss: 0.5725 - val_acc: 0.7480\n",
      "Epoch 67/1000\n",
      "7s - loss: 0.5595 - acc: 0.7534 - val_loss: 0.5721 - val_acc: 0.7482\n",
      "Epoch 68/1000\n",
      "10s - loss: 0.5591 - acc: 0.7536 - val_loss: 0.5738 - val_acc: 0.7487\n",
      "Epoch 69/1000\n",
      "8s - loss: 0.5594 - acc: 0.7561 - val_loss: 0.5720 - val_acc: 0.7471\n",
      "Epoch 70/1000\n",
      "8s - loss: 0.5587 - acc: 0.7550 - val_loss: 0.5726 - val_acc: 0.7479\n",
      "Epoch 71/1000\n",
      "7s - loss: 0.5595 - acc: 0.7538 - val_loss: 0.5726 - val_acc: 0.7458\n",
      "Epoch 72/1000\n",
      "7s - loss: 0.5580 - acc: 0.7545 - val_loss: 0.5726 - val_acc: 0.7483\n",
      "Epoch 73/1000\n",
      "7s - loss: 0.5579 - acc: 0.7533 - val_loss: 0.5726 - val_acc: 0.7480\n",
      "Epoch 74/1000\n",
      "10s - loss: 0.5561 - acc: 0.7562 - val_loss: 0.5733 - val_acc: 0.7488\n",
      "Epoch 75/1000\n",
      "8s - loss: 0.5562 - acc: 0.7562 - val_loss: 0.5735 - val_acc: 0.7475\n",
      "Epoch 76/1000\n",
      "8s - loss: 0.5570 - acc: 0.7551 - val_loss: 0.5732 - val_acc: 0.7493\n",
      "Epoch 77/1000\n",
      "6s - loss: 0.5571 - acc: 0.7553 - val_loss: 0.5731 - val_acc: 0.7470\n",
      "Epoch 78/1000\n",
      "9s - loss: 0.5579 - acc: 0.7558 - val_loss: 0.5735 - val_acc: 0.7480\n",
      "Epoch 79/1000\n",
      "9s - loss: 0.5574 - acc: 0.7543 - val_loss: 0.5736 - val_acc: 0.7469\n",
      "Epoch 80/1000\n",
      "7s - loss: 0.5569 - acc: 0.7533 - val_loss: 0.5750 - val_acc: 0.7486\n",
      "Epoch 81/1000\n",
      "9s - loss: 0.5563 - acc: 0.7544 - val_loss: 0.5737 - val_acc: 0.7472\n",
      "Epoch 82/1000\n",
      "8s - loss: 0.5576 - acc: 0.7548 - val_loss: 0.5739 - val_acc: 0.7482\n",
      "Epoch 83/1000\n",
      "6s - loss: 0.5568 - acc: 0.7570 - val_loss: 0.5735 - val_acc: 0.7473\n",
      "Epoch 84/1000\n",
      "8s - loss: 0.5543 - acc: 0.7584 - val_loss: 0.5743 - val_acc: 0.7477\n",
      "9871/9871 [==============================] - 0s     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "the cv_score for the 3 turn is:\n",
      "0.565270944195\n",
      "Train on 39481 samples, validate on 9871 samples\n",
      "Epoch 1/1000\n",
      "7s - loss: 0.7055 - acc: 0.7051 - val_loss: 0.6159 - val_acc: 0.7302\n",
      "Epoch 2/1000\n",
      "8s - loss: 0.6272 - acc: 0.7254 - val_loss: 0.6019 - val_acc: 0.7331\n",
      "Epoch 3/1000\n",
      "8s - loss: 0.6145 - acc: 0.7294 - val_loss: 0.5978 - val_acc: 0.7335\n",
      "Epoch 4/1000\n",
      "7s - loss: 0.6053 - acc: 0.7335 - val_loss: 0.5938 - val_acc: 0.7373\n",
      "Epoch 5/1000\n",
      "8s - loss: 0.6011 - acc: 0.7332 - val_loss: 0.5923 - val_acc: 0.7371\n",
      "Epoch 6/1000\n",
      "8s - loss: 0.5974 - acc: 0.7356 - val_loss: 0.5910 - val_acc: 0.7397\n",
      "Epoch 7/1000\n",
      "8s - loss: 0.5948 - acc: 0.7364 - val_loss: 0.5902 - val_acc: 0.7388\n",
      "Epoch 8/1000\n",
      "7s - loss: 0.5917 - acc: 0.7382 - val_loss: 0.5895 - val_acc: 0.7368\n",
      "Epoch 9/1000\n",
      "7s - loss: 0.5901 - acc: 0.7388 - val_loss: 0.5876 - val_acc: 0.7395\n",
      "Epoch 10/1000\n",
      "7s - loss: 0.5886 - acc: 0.7395 - val_loss: 0.5868 - val_acc: 0.7409\n",
      "Epoch 11/1000\n",
      "8s - loss: 0.5867 - acc: 0.7389 - val_loss: 0.5861 - val_acc: 0.7406\n",
      "Epoch 12/1000\n",
      "9s - loss: 0.5852 - acc: 0.7401 - val_loss: 0.5850 - val_acc: 0.7404\n",
      "Epoch 13/1000\n",
      "8s - loss: 0.5838 - acc: 0.7388 - val_loss: 0.5844 - val_acc: 0.7409\n",
      "Epoch 14/1000\n",
      "7s - loss: 0.5832 - acc: 0.7405 - val_loss: 0.5840 - val_acc: 0.7421\n",
      "Epoch 15/1000\n",
      "6s - loss: 0.5803 - acc: 0.7411 - val_loss: 0.5840 - val_acc: 0.7417\n",
      "Epoch 16/1000\n",
      "6s - loss: 0.5803 - acc: 0.7423 - val_loss: 0.5833 - val_acc: 0.7433\n",
      "Epoch 17/1000\n",
      "8s - loss: 0.5803 - acc: 0.7435 - val_loss: 0.5831 - val_acc: 0.7428\n",
      "Epoch 18/1000\n",
      "7s - loss: 0.5797 - acc: 0.7449 - val_loss: 0.5827 - val_acc: 0.7416\n",
      "Epoch 19/1000\n",
      "8s - loss: 0.5772 - acc: 0.7417 - val_loss: 0.5818 - val_acc: 0.7422\n",
      "Epoch 20/1000\n",
      "5s - loss: 0.5765 - acc: 0.7431 - val_loss: 0.5813 - val_acc: 0.7420\n",
      "Epoch 21/1000\n",
      "7s - loss: 0.5773 - acc: 0.7438 - val_loss: 0.5804 - val_acc: 0.7415\n",
      "Epoch 22/1000\n",
      "7s - loss: 0.5754 - acc: 0.7447 - val_loss: 0.5804 - val_acc: 0.7429\n",
      "Epoch 23/1000\n",
      "10s - loss: 0.5746 - acc: 0.7455 - val_loss: 0.5800 - val_acc: 0.7436\n",
      "Epoch 24/1000\n",
      "7s - loss: 0.5752 - acc: 0.7452 - val_loss: 0.5801 - val_acc: 0.7444\n",
      "Epoch 25/1000\n",
      "7s - loss: 0.5724 - acc: 0.7446 - val_loss: 0.5796 - val_acc: 0.7432\n",
      "Epoch 26/1000\n",
      "9s - loss: 0.5720 - acc: 0.7456 - val_loss: 0.5797 - val_acc: 0.7437\n",
      "Epoch 27/1000\n",
      "7s - loss: 0.5726 - acc: 0.7460 - val_loss: 0.5789 - val_acc: 0.7440\n",
      "Epoch 28/1000\n",
      "7s - loss: 0.5729 - acc: 0.7445 - val_loss: 0.5791 - val_acc: 0.7448\n",
      "Epoch 29/1000\n",
      "8s - loss: 0.5712 - acc: 0.7462 - val_loss: 0.5788 - val_acc: 0.7438\n",
      "Epoch 30/1000\n",
      "9s - loss: 0.5721 - acc: 0.7468 - val_loss: 0.5788 - val_acc: 0.7448\n",
      "Epoch 31/1000\n",
      "8s - loss: 0.5714 - acc: 0.7455 - val_loss: 0.5782 - val_acc: 0.7444\n",
      "Epoch 32/1000\n",
      "7s - loss: 0.5686 - acc: 0.7462 - val_loss: 0.5791 - val_acc: 0.7440\n",
      "Epoch 33/1000\n",
      "7s - loss: 0.5698 - acc: 0.7472 - val_loss: 0.5779 - val_acc: 0.7454\n",
      "Epoch 34/1000\n",
      "7s - loss: 0.5681 - acc: 0.7480 - val_loss: 0.5773 - val_acc: 0.7460\n",
      "Epoch 35/1000\n",
      "7s - loss: 0.5689 - acc: 0.7480 - val_loss: 0.5780 - val_acc: 0.7466\n",
      "Epoch 36/1000\n",
      "7s - loss: 0.5688 - acc: 0.7482 - val_loss: 0.5775 - val_acc: 0.7474\n",
      "Epoch 37/1000\n",
      "9s - loss: 0.5671 - acc: 0.7489 - val_loss: 0.5775 - val_acc: 0.7483\n",
      "Epoch 38/1000\n",
      "6s - loss: 0.5665 - acc: 0.7462 - val_loss: 0.5780 - val_acc: 0.7456\n",
      "Epoch 39/1000\n",
      "8s - loss: 0.5651 - acc: 0.7491 - val_loss: 0.5770 - val_acc: 0.7472\n",
      "Epoch 40/1000\n",
      "8s - loss: 0.5669 - acc: 0.7483 - val_loss: 0.5785 - val_acc: 0.7458\n",
      "Epoch 41/1000\n",
      "10s - loss: 0.5675 - acc: 0.7466 - val_loss: 0.5769 - val_acc: 0.7444\n",
      "Epoch 42/1000\n",
      "9s - loss: 0.5651 - acc: 0.7496 - val_loss: 0.5772 - val_acc: 0.7466\n",
      "Epoch 43/1000\n",
      "9s - loss: 0.5650 - acc: 0.7483 - val_loss: 0.5781 - val_acc: 0.7469\n",
      "Epoch 44/1000\n",
      "9s - loss: 0.5643 - acc: 0.7503 - val_loss: 0.5777 - val_acc: 0.7465\n",
      "Epoch 45/1000\n",
      "7s - loss: 0.5635 - acc: 0.7502 - val_loss: 0.5776 - val_acc: 0.7465\n",
      "Epoch 46/1000\n",
      "8s - loss: 0.5649 - acc: 0.7500 - val_loss: 0.5780 - val_acc: 0.7485\n",
      "Epoch 47/1000\n",
      "9s - loss: 0.5636 - acc: 0.7511 - val_loss: 0.5770 - val_acc: 0.7485\n",
      "Epoch 48/1000\n",
      "8s - loss: 0.5626 - acc: 0.7501 - val_loss: 0.5764 - val_acc: 0.7500\n",
      "Epoch 49/1000\n",
      "7s - loss: 0.5620 - acc: 0.7494 - val_loss: 0.5778 - val_acc: 0.7461\n",
      "Epoch 50/1000\n",
      "8s - loss: 0.5635 - acc: 0.7513 - val_loss: 0.5764 - val_acc: 0.7482\n",
      "Epoch 51/1000\n",
      "7s - loss: 0.5609 - acc: 0.7521 - val_loss: 0.5775 - val_acc: 0.7476\n",
      "Epoch 52/1000\n",
      "8s - loss: 0.5616 - acc: 0.7515 - val_loss: 0.5775 - val_acc: 0.7474\n",
      "Epoch 53/1000\n",
      "7s - loss: 0.5612 - acc: 0.7522 - val_loss: 0.5799 - val_acc: 0.7465\n",
      "Epoch 54/1000\n",
      "8s - loss: 0.5610 - acc: 0.7545 - val_loss: 0.5782 - val_acc: 0.7487\n",
      "Epoch 55/1000\n",
      "7s - loss: 0.5611 - acc: 0.7505 - val_loss: 0.5787 - val_acc: 0.7479\n",
      "Epoch 56/1000\n",
      "9s - loss: 0.5596 - acc: 0.7511 - val_loss: 0.5776 - val_acc: 0.7487\n",
      "Epoch 57/1000\n",
      "7s - loss: 0.5592 - acc: 0.7523 - val_loss: 0.5777 - val_acc: 0.7465\n",
      "Epoch 58/1000\n",
      "8s - loss: 0.5583 - acc: 0.7538 - val_loss: 0.5774 - val_acc: 0.7478\n",
      "Epoch 59/1000\n",
      "9s - loss: 0.5609 - acc: 0.7520 - val_loss: 0.5782 - val_acc: 0.7479\n",
      "Epoch 60/1000\n",
      "9s - loss: 0.5598 - acc: 0.7520 - val_loss: 0.5776 - val_acc: 0.7489\n",
      "Epoch 61/1000\n",
      "8s - loss: 0.5591 - acc: 0.7532 - val_loss: 0.5779 - val_acc: 0.7491\n",
      "Epoch 62/1000\n",
      "10s - loss: 0.5598 - acc: 0.7520 - val_loss: 0.5785 - val_acc: 0.7476\n",
      "Epoch 63/1000\n",
      "8s - loss: 0.5590 - acc: 0.7529 - val_loss: 0.5784 - val_acc: 0.7486\n",
      "Epoch 64/1000\n",
      "7s - loss: 0.5572 - acc: 0.7551 - val_loss: 0.5781 - val_acc: 0.7496\n",
      "Epoch 65/1000\n",
      "8s - loss: 0.5583 - acc: 0.7528 - val_loss: 0.5783 - val_acc: 0.7478\n",
      "Epoch 66/1000\n",
      "10s - loss: 0.5583 - acc: 0.7538 - val_loss: 0.5780 - val_acc: 0.7486\n",
      "Epoch 67/1000\n",
      "8s - loss: 0.5578 - acc: 0.7526 - val_loss: 0.5787 - val_acc: 0.7491\n",
      "Epoch 68/1000\n",
      "7s - loss: 0.5579 - acc: 0.7534 - val_loss: 0.5781 - val_acc: 0.7483\n",
      "Epoch 69/1000\n",
      "9s - loss: 0.5571 - acc: 0.7537 - val_loss: 0.5793 - val_acc: 0.7467\n",
      "Epoch 70/1000\n",
      "7s - loss: 0.5571 - acc: 0.7531 - val_loss: 0.5790 - val_acc: 0.7500\n",
      "Epoch 71/1000\n",
      "7s - loss: 0.5570 - acc: 0.7546 - val_loss: 0.5776 - val_acc: 0.7479\n",
      "9088/9871 [==========================>...] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bthe cv_score for the 4 turn is:\n",
      "0.565889514863\n",
      "Train on 39484 samples, validate on 9868 samples\n",
      "Epoch 1/1000\n",
      "10s - loss: 0.7086 - acc: 0.7019 - val_loss: 0.6101 - val_acc: 0.7353\n",
      "Epoch 2/1000\n",
      "9s - loss: 0.6283 - acc: 0.7236 - val_loss: 0.5966 - val_acc: 0.7410\n",
      "Epoch 3/1000\n",
      "10s - loss: 0.6155 - acc: 0.7278 - val_loss: 0.5917 - val_acc: 0.7435\n",
      "Epoch 4/1000\n",
      "8s - loss: 0.6070 - acc: 0.7315 - val_loss: 0.5882 - val_acc: 0.7440\n",
      "Epoch 5/1000\n",
      "8s - loss: 0.6025 - acc: 0.7349 - val_loss: 0.5860 - val_acc: 0.7447\n",
      "Epoch 6/1000\n",
      "9s - loss: 0.5987 - acc: 0.7347 - val_loss: 0.5842 - val_acc: 0.7464\n",
      "Epoch 7/1000\n",
      "8s - loss: 0.5959 - acc: 0.7370 - val_loss: 0.5829 - val_acc: 0.7451\n",
      "Epoch 8/1000\n",
      "10s - loss: 0.5933 - acc: 0.7350 - val_loss: 0.5822 - val_acc: 0.7459\n",
      "Epoch 9/1000\n",
      "9s - loss: 0.5928 - acc: 0.7359 - val_loss: 0.5811 - val_acc: 0.7441\n",
      "Epoch 10/1000\n",
      "10s - loss: 0.5890 - acc: 0.7385 - val_loss: 0.5805 - val_acc: 0.7454\n",
      "Epoch 11/1000\n",
      "10s - loss: 0.5893 - acc: 0.7388 - val_loss: 0.5791 - val_acc: 0.7441\n",
      "Epoch 12/1000\n",
      "8s - loss: 0.5861 - acc: 0.7377 - val_loss: 0.5790 - val_acc: 0.7456\n",
      "Epoch 13/1000\n",
      "9s - loss: 0.5873 - acc: 0.7381 - val_loss: 0.5781 - val_acc: 0.7470\n",
      "Epoch 14/1000\n",
      "10s - loss: 0.5855 - acc: 0.7407 - val_loss: 0.5779 - val_acc: 0.7475\n",
      "Epoch 15/1000\n",
      "9s - loss: 0.5832 - acc: 0.7414 - val_loss: 0.5765 - val_acc: 0.7458\n",
      "Epoch 16/1000\n",
      "7s - loss: 0.5838 - acc: 0.7410 - val_loss: 0.5764 - val_acc: 0.7463\n",
      "Epoch 17/1000\n",
      "9s - loss: 0.5823 - acc: 0.7422 - val_loss: 0.5741 - val_acc: 0.7483\n",
      "Epoch 18/1000\n",
      "9s - loss: 0.5829 - acc: 0.7407 - val_loss: 0.5743 - val_acc: 0.7473\n",
      "Epoch 19/1000\n",
      "6s - loss: 0.5815 - acc: 0.7402 - val_loss: 0.5740 - val_acc: 0.7454\n",
      "Epoch 20/1000\n",
      "8s - loss: 0.5793 - acc: 0.7426 - val_loss: 0.5727 - val_acc: 0.7482\n",
      "Epoch 21/1000\n",
      "8s - loss: 0.5789 - acc: 0.7405 - val_loss: 0.5729 - val_acc: 0.7471\n",
      "Epoch 22/1000\n",
      "7s - loss: 0.5783 - acc: 0.7413 - val_loss: 0.5726 - val_acc: 0.7473\n",
      "Epoch 23/1000\n",
      "8s - loss: 0.5783 - acc: 0.7438 - val_loss: 0.5713 - val_acc: 0.7483\n",
      "Epoch 24/1000\n",
      "8s - loss: 0.5767 - acc: 0.7431 - val_loss: 0.5717 - val_acc: 0.7478\n",
      "Epoch 25/1000\n",
      "10s - loss: 0.5751 - acc: 0.7433 - val_loss: 0.5715 - val_acc: 0.7476\n",
      "Epoch 26/1000\n",
      "9s - loss: 0.5763 - acc: 0.7428 - val_loss: 0.5713 - val_acc: 0.7486\n",
      "Epoch 27/1000\n",
      "9s - loss: 0.5754 - acc: 0.7466 - val_loss: 0.5715 - val_acc: 0.7487\n",
      "Epoch 28/1000\n",
      "9s - loss: 0.5727 - acc: 0.7452 - val_loss: 0.5701 - val_acc: 0.7480\n",
      "Epoch 29/1000\n",
      "8s - loss: 0.5726 - acc: 0.7447 - val_loss: 0.5699 - val_acc: 0.7497\n",
      "Epoch 30/1000\n",
      "9s - loss: 0.5725 - acc: 0.7449 - val_loss: 0.5712 - val_acc: 0.7480\n",
      "Epoch 31/1000\n",
      "8s - loss: 0.5733 - acc: 0.7445 - val_loss: 0.5686 - val_acc: 0.7481\n",
      "Epoch 32/1000\n",
      "9s - loss: 0.5723 - acc: 0.7456 - val_loss: 0.5690 - val_acc: 0.7493\n",
      "Epoch 33/1000\n",
      "7s - loss: 0.5726 - acc: 0.7461 - val_loss: 0.5691 - val_acc: 0.7495\n",
      "Epoch 34/1000\n",
      "8s - loss: 0.5716 - acc: 0.7464 - val_loss: 0.5686 - val_acc: 0.7500\n",
      "Epoch 35/1000\n",
      "8s - loss: 0.5728 - acc: 0.7455 - val_loss: 0.5684 - val_acc: 0.7487\n",
      "Epoch 36/1000\n",
      "11s - loss: 0.5697 - acc: 0.7438 - val_loss: 0.5690 - val_acc: 0.7488\n",
      "Epoch 37/1000\n",
      "9s - loss: 0.5706 - acc: 0.7488 - val_loss: 0.5686 - val_acc: 0.7515\n",
      "Epoch 38/1000\n",
      "8s - loss: 0.5705 - acc: 0.7473 - val_loss: 0.5674 - val_acc: 0.7492\n",
      "Epoch 39/1000\n",
      "8s - loss: 0.5686 - acc: 0.7471 - val_loss: 0.5676 - val_acc: 0.7487\n",
      "Epoch 40/1000\n",
      "9s - loss: 0.5690 - acc: 0.7463 - val_loss: 0.5681 - val_acc: 0.7481\n",
      "Epoch 41/1000\n",
      "8s - loss: 0.5682 - acc: 0.7473 - val_loss: 0.5676 - val_acc: 0.7492\n",
      "Epoch 42/1000\n",
      "9s - loss: 0.5686 - acc: 0.7469 - val_loss: 0.5664 - val_acc: 0.7505\n",
      "Epoch 43/1000\n",
      "7s - loss: 0.5676 - acc: 0.7484 - val_loss: 0.5668 - val_acc: 0.7498\n",
      "Epoch 44/1000\n",
      "6s - loss: 0.5656 - acc: 0.7490 - val_loss: 0.5670 - val_acc: 0.7495\n",
      "Epoch 45/1000\n",
      "7s - loss: 0.5667 - acc: 0.7479 - val_loss: 0.5670 - val_acc: 0.7501\n",
      "Epoch 46/1000\n",
      "8s - loss: 0.5664 - acc: 0.7486 - val_loss: 0.5668 - val_acc: 0.7496\n",
      "Epoch 47/1000\n",
      "8s - loss: 0.5654 - acc: 0.7479 - val_loss: 0.5666 - val_acc: 0.7501\n",
      "Epoch 48/1000\n",
      "7s - loss: 0.5666 - acc: 0.7496 - val_loss: 0.5678 - val_acc: 0.7514\n",
      "Epoch 49/1000\n",
      "7s - loss: 0.5637 - acc: 0.7510 - val_loss: 0.5668 - val_acc: 0.7507\n",
      "Epoch 50/1000\n",
      "7s - loss: 0.5672 - acc: 0.7495 - val_loss: 0.5665 - val_acc: 0.7500\n",
      "Epoch 51/1000\n",
      "8s - loss: 0.5659 - acc: 0.7483 - val_loss: 0.5668 - val_acc: 0.7498\n",
      "Epoch 52/1000\n",
      "9s - loss: 0.5641 - acc: 0.7502 - val_loss: 0.5674 - val_acc: 0.7504\n",
      "Epoch 53/1000\n",
      "8s - loss: 0.5637 - acc: 0.7502 - val_loss: 0.5673 - val_acc: 0.7511\n",
      "Epoch 54/1000\n",
      "8s - loss: 0.5636 - acc: 0.7502 - val_loss: 0.5677 - val_acc: 0.7484\n",
      "Epoch 55/1000\n",
      "7s - loss: 0.5644 - acc: 0.7508 - val_loss: 0.5665 - val_acc: 0.7511\n",
      "Epoch 56/1000\n",
      "8s - loss: 0.5648 - acc: 0.7496 - val_loss: 0.5672 - val_acc: 0.7490\n",
      "Epoch 57/1000\n",
      "9s - loss: 0.5626 - acc: 0.7528 - val_loss: 0.5666 - val_acc: 0.7502\n",
      "Epoch 58/1000\n",
      "8s - loss: 0.5622 - acc: 0.7508 - val_loss: 0.5660 - val_acc: 0.7517\n",
      "Epoch 59/1000\n",
      "6s - loss: 0.5624 - acc: 0.7499 - val_loss: 0.5667 - val_acc: 0.7501\n",
      "Epoch 60/1000\n",
      "7s - loss: 0.5627 - acc: 0.7518 - val_loss: 0.5660 - val_acc: 0.7503\n",
      "Epoch 61/1000\n",
      "7s - loss: 0.5623 - acc: 0.7516 - val_loss: 0.5658 - val_acc: 0.7501\n",
      "Epoch 62/1000\n",
      "9s - loss: 0.5617 - acc: 0.7531 - val_loss: 0.5650 - val_acc: 0.7498\n",
      "Epoch 63/1000\n",
      "7s - loss: 0.5606 - acc: 0.7535 - val_loss: 0.5657 - val_acc: 0.7513\n",
      "Epoch 64/1000\n",
      "7s - loss: 0.5624 - acc: 0.7509 - val_loss: 0.5657 - val_acc: 0.7504\n",
      "Epoch 65/1000\n",
      "9s - loss: 0.5612 - acc: 0.7507 - val_loss: 0.5663 - val_acc: 0.7506\n",
      "Epoch 66/1000\n",
      "7s - loss: 0.5609 - acc: 0.7506 - val_loss: 0.5670 - val_acc: 0.7513\n",
      "Epoch 67/1000\n",
      "8s - loss: 0.5609 - acc: 0.7532 - val_loss: 0.5655 - val_acc: 0.7490\n",
      "Epoch 68/1000\n",
      "8s - loss: 0.5622 - acc: 0.7508 - val_loss: 0.5670 - val_acc: 0.7495\n",
      "Epoch 69/1000\n",
      "7s - loss: 0.5615 - acc: 0.7532 - val_loss: 0.5660 - val_acc: 0.7487\n",
      "Epoch 70/1000\n",
      "9s - loss: 0.5592 - acc: 0.7529 - val_loss: 0.5664 - val_acc: 0.7517\n",
      "Epoch 71/1000\n",
      "7s - loss: 0.5583 - acc: 0.7544 - val_loss: 0.5653 - val_acc: 0.7508\n",
      "Epoch 72/1000\n",
      "9s - loss: 0.5595 - acc: 0.7529 - val_loss: 0.5666 - val_acc: 0.7499\n",
      "Epoch 73/1000\n",
      "7s - loss: 0.5575 - acc: 0.7529 - val_loss: 0.5660 - val_acc: 0.7512\n",
      "Epoch 74/1000\n",
      "6s - loss: 0.5599 - acc: 0.7534 - val_loss: 0.5673 - val_acc: 0.7519\n",
      "Epoch 75/1000\n",
      "7s - loss: 0.5586 - acc: 0.7541 - val_loss: 0.5665 - val_acc: 0.7488\n",
      "Epoch 76/1000\n",
      "8s - loss: 0.5596 - acc: 0.7529 - val_loss: 0.5679 - val_acc: 0.7520\n",
      "Epoch 77/1000\n",
      "9s - loss: 0.5577 - acc: 0.7539 - val_loss: 0.5669 - val_acc: 0.7515\n",
      "Epoch 78/1000\n",
      "6s - loss: 0.5582 - acc: 0.7539 - val_loss: 0.5664 - val_acc: 0.7502\n",
      "Epoch 79/1000\n",
      "8s - loss: 0.5579 - acc: 0.7547 - val_loss: 0.5670 - val_acc: 0.7487\n",
      "Epoch 80/1000\n",
      "8s - loss: 0.5574 - acc: 0.7535 - val_loss: 0.5693 - val_acc: 0.7495\n",
      "Epoch 81/1000\n",
      "8s - loss: 0.5579 - acc: 0.7540 - val_loss: 0.5674 - val_acc: 0.7491\n",
      "Epoch 82/1000\n",
      "7s - loss: 0.5578 - acc: 0.7535 - val_loss: 0.5681 - val_acc: 0.7494\n",
      "Epoch 83/1000\n",
      "9s - loss: 0.5602 - acc: 0.7520 - val_loss: 0.5664 - val_acc: 0.7510\n",
      "9632/9868 [============================>.] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bthe cv_score for the 5 turn is:\n",
      "0.554544523339\n",
      "0.565022120462\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for batch_size in [64]:\n",
    "\n",
    "    i=0\n",
    "    cv_scores=[]\n",
    "    cv_result=[]\n",
    "    for dev_index, val_index in KF:\n",
    "        dev_set, val_set = train_df.iloc[dev_index,:] , train_df.iloc[val_index,:] \n",
    "        dev_X, val_X = dev_set[features].as_matrix(), val_set[features].as_matrix()\n",
    "        dev_y, val_y = train_y[dev_index], train_y[val_index]\n",
    "    \n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=20)\n",
    "\n",
    "        seed = 0\n",
    "        np.random.seed(seed)\n",
    "        model = nn_model(features,lr=0.1)\n",
    "        history=model.fit(dev_X, dev_y, epochs = 1000, batch_size=batch_size, verbose = 2, \n",
    "          validation_data=[val_X, val_y], callbacks=[early_stopping])\n",
    "\n",
    "        preds =  model.predict_proba(val_X)\n",
    "        \"\"\"\n",
    "        #save the pickles for futures use\n",
    "        pickl_file = store+'nn-5fold-out-'+str(i)+'.pickle'\n",
    "        fileObject = open(pickl_file,'wb') \n",
    "        pickle.dump(preds,fileObject)   \n",
    "        fileObject.close()    \n",
    "        \"\"\"\n",
    "        lls=log_loss(val_y, preds)\n",
    "        cv_scores.append(lls)\n",
    "        cv_result.append(history)\n",
    "        i+=1\n",
    "        print 'the cv_score for the '+str(i)+' turn is:'\n",
    "        print(lls)\n",
    "    \n",
    "    print np.mean(cv_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.callbacks.History at 0x7f7cf0265ed0>,\n",
       " <keras.callbacks.History at 0x7f7d53e1f890>,\n",
       " <keras.callbacks.History at 0x7f7c9c5415d0>,\n",
       " <keras.callbacks.History at 0x7f7c6a057850>,\n",
       " <keras.callbacks.History at 0x7f7cf5f35850>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.62606498579427761,\n",
       " 0.61213838925490616,\n",
       " 0.60841578445636491,\n",
       " 0.60436816580715103,\n",
       " 0.60310107293842463,\n",
       " 0.60187766285921329,\n",
       " 0.60087456179418752,\n",
       " 0.59972067699160891,\n",
       " 0.59913021746334871,\n",
       " 0.59711539933123781,\n",
       " 0.59582158282177267,\n",
       " 0.59593743994030446,\n",
       " 0.59455101442438485,\n",
       " 0.59542512690184046,\n",
       " 0.59469518580222702,\n",
       " 0.5923505682324991,\n",
       " 0.59261432500514033,\n",
       " 0.59269209234031694,\n",
       " 0.59263453171639902,\n",
       " 0.58997414772929113,\n",
       " 0.59098968372653171,\n",
       " 0.59063844262448595,\n",
       " 0.59226828722373626,\n",
       " 0.58984572048571782,\n",
       " 0.59089995122537975,\n",
       " 0.58936574094117489,\n",
       " 0.58871431120525752,\n",
       " 0.58916067796907534,\n",
       " 0.58955185714795488,\n",
       " 0.58879555207643697,\n",
       " 0.58815046192338649,\n",
       " 0.58825219645469751,\n",
       " 0.58760493066871,\n",
       " 0.58978645340938141,\n",
       " 0.58824349365726136,\n",
       " 0.58774308901211858,\n",
       " 0.58860097692532332,\n",
       " 0.58907870870268875,\n",
       " 0.58758846954569466,\n",
       " 0.58762531247427374,\n",
       " 0.58785817132461349,\n",
       " 0.58869448884764575,\n",
       " 0.58665946105755684,\n",
       " 0.58728366602325788,\n",
       " 0.58638138355497238,\n",
       " 0.58817404180707789,\n",
       " 0.5890853110689146,\n",
       " 0.58733142436112262,\n",
       " 0.58741140376469636,\n",
       " 0.58764152651366441,\n",
       " 0.58767563664989264,\n",
       " 0.58840688051948942,\n",
       " 0.5895485403858749,\n",
       " 0.58877360415596358,\n",
       " 0.58779861476329331,\n",
       " 0.5893926120990316,\n",
       " 0.58925532559809402,\n",
       " 0.58789947141981236,\n",
       " 0.58880029407850387,\n",
       " 0.58856704332656795,\n",
       " 0.5890627375804548,\n",
       " 0.59096108160051775,\n",
       " 0.58888715956665416,\n",
       " 0.58821396539788784,\n",
       " 0.58802565098678361,\n",
       " 0.58936265090741036]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_result[0].history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test={}\n",
    "for i in range(len(cv_result)):\n",
    "    test[i]=cv_result[i].history['val_loss'][:59]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val_history=pd.DataFrame(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0.614080\n",
       "1     0.600461\n",
       "2     0.595790\n",
       "3     0.592497\n",
       "4     0.590640\n",
       "5     0.589203\n",
       "6     0.588110\n",
       "7     0.587252\n",
       "8     0.586053\n",
       "9     0.585096\n",
       "10    0.584148\n",
       "11    0.583692\n",
       "12    0.582710\n",
       "13    0.582650\n",
       "14    0.581915\n",
       "15    0.581202\n",
       "16    0.580591\n",
       "17    0.580409\n",
       "18    0.579975\n",
       "19    0.578951\n",
       "20    0.578642\n",
       "21    0.578572\n",
       "22    0.578416\n",
       "23    0.577913\n",
       "24    0.577859\n",
       "25    0.577238\n",
       "26    0.577030\n",
       "27    0.576846\n",
       "28    0.576900\n",
       "29    0.577103\n",
       "30    0.575953\n",
       "31    0.576324\n",
       "32    0.575653\n",
       "33    0.576207\n",
       "34    0.575818\n",
       "35    0.575610\n",
       "36    0.575744\n",
       "37    0.575663\n",
       "38    0.574865\n",
       "39    0.575395\n",
       "40    0.575109\n",
       "41    0.575079\n",
       "42    0.574784\n",
       "43    0.574955\n",
       "44    0.574745\n",
       "45    0.574985\n",
       "46    0.575029\n",
       "47    0.574945\n",
       "48    0.575239\n",
       "49    0.575043\n",
       "50    0.574956\n",
       "51    0.575428\n",
       "52    0.576071\n",
       "53    0.575606\n",
       "54    0.575508\n",
       "55    0.575538\n",
       "56    0.575587\n",
       "57    0.574966\n",
       "58    0.575614\n",
       "dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(val_history,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "14s - loss: 0.7119 - acc: 0.7015\n",
      "Epoch 2/40\n",
      "15s - loss: 0.6268 - acc: 0.7254\n",
      "Epoch 3/40\n",
      "17s - loss: 0.6083 - acc: 0.7319\n",
      "Epoch 4/40\n",
      "13s - loss: 0.6014 - acc: 0.7351\n",
      "Epoch 5/40\n",
      "13s - loss: 0.5984 - acc: 0.7362\n",
      "Epoch 6/40\n",
      "17s - loss: 0.5960 - acc: 0.7379\n",
      "Epoch 7/40\n",
      "14s - loss: 0.5936 - acc: 0.7382\n",
      "Epoch 8/40\n",
      "12s - loss: 0.5901 - acc: 0.7391\n",
      "Epoch 9/40\n",
      "13s - loss: 0.5892 - acc: 0.7394\n",
      "Epoch 10/40\n",
      "15s - loss: 0.5856 - acc: 0.7404\n",
      "Epoch 11/40\n",
      "16s - loss: 0.5854 - acc: 0.7404\n",
      "Epoch 12/40\n",
      "12s - loss: 0.5834 - acc: 0.7428\n",
      "Epoch 13/40\n",
      "16s - loss: 0.5831 - acc: 0.7433\n",
      "Epoch 14/40\n",
      "15s - loss: 0.5810 - acc: 0.7417\n",
      "Epoch 15/40\n",
      "14s - loss: 0.5808 - acc: 0.7424\n",
      "Epoch 16/40\n",
      "9s - loss: 0.5798 - acc: 0.7430\n",
      "Epoch 17/40\n",
      "14s - loss: 0.5764 - acc: 0.7437\n",
      "Epoch 18/40\n",
      "17s - loss: 0.5757 - acc: 0.7431\n",
      "Epoch 19/40\n",
      "16s - loss: 0.5765 - acc: 0.7447\n",
      "Epoch 20/40\n",
      "15s - loss: 0.5760 - acc: 0.7445\n",
      "Epoch 21/40\n",
      "12s - loss: 0.5745 - acc: 0.7451\n",
      "Epoch 22/40\n",
      "17s - loss: 0.5747 - acc: 0.7456\n",
      "Epoch 23/40\n",
      "16s - loss: 0.5730 - acc: 0.7469\n",
      "Epoch 24/40\n",
      "15s - loss: 0.5728 - acc: 0.7471\n",
      "Epoch 25/40\n",
      "15s - loss: 0.5700 - acc: 0.7472\n",
      "Epoch 26/40\n",
      "16s - loss: 0.5689 - acc: 0.7478\n",
      "Epoch 27/40\n",
      "15s - loss: 0.5698 - acc: 0.7484\n",
      "Epoch 28/40\n",
      "14s - loss: 0.5698 - acc: 0.7476\n",
      "Epoch 29/40\n",
      "18s - loss: 0.5689 - acc: 0.7483\n",
      "Epoch 30/40\n",
      "15s - loss: 0.5672 - acc: 0.7468\n",
      "Epoch 31/40\n",
      "17s - loss: 0.5678 - acc: 0.7486\n",
      "Epoch 32/40\n",
      "17s - loss: 0.5664 - acc: 0.7481\n",
      "Epoch 33/40\n",
      "14s - loss: 0.5666 - acc: 0.7492\n",
      "Epoch 34/40\n",
      "15s - loss: 0.5656 - acc: 0.7495\n",
      "Epoch 35/40\n",
      "17s - loss: 0.5641 - acc: 0.7504\n",
      "Epoch 36/40\n",
      "15s - loss: 0.5636 - acc: 0.7495\n",
      "Epoch 37/40\n",
      "17s - loss: 0.5653 - acc: 0.7514\n",
      "Epoch 38/40\n",
      "12s - loss: 0.5636 - acc: 0.7499\n",
      "Epoch 39/40\n",
      "13s - loss: 0.5644 - acc: 0.7513\n",
      "Epoch 40/40\n",
      "12s - loss: 0.5639 - acc: 0.7501\n",
      "9824/9871 [============================>.] - ETA: 0s \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bthe cv_score for the 1 turn is:\n",
      "0.578788215259\n",
      "Epoch 1/40\n",
      "16s - loss: 0.7153 - acc: 0.7034\n",
      "Epoch 2/40\n",
      "16s - loss: 0.6312 - acc: 0.7251\n",
      "Epoch 3/40\n",
      "13s - loss: 0.6149 - acc: 0.7308\n",
      "Epoch 4/40\n",
      "15s - loss: 0.6067 - acc: 0.7314\n",
      "Epoch 5/40\n",
      "15s - loss: 0.6050 - acc: 0.7331\n",
      "Epoch 6/40\n",
      "14s - loss: 0.5999 - acc: 0.7347\n",
      "Epoch 7/40\n",
      "13s - loss: 0.5962 - acc: 0.7356\n",
      "Epoch 8/40\n",
      "14s - loss: 0.5956 - acc: 0.7372\n",
      "Epoch 9/40\n",
      "15s - loss: 0.5927 - acc: 0.7380\n",
      "Epoch 10/40\n",
      "15s - loss: 0.5911 - acc: 0.7383\n",
      "Epoch 11/40\n",
      "14s - loss: 0.5887 - acc: 0.7387\n",
      "Epoch 12/40\n",
      "12s - loss: 0.5889 - acc: 0.7387\n",
      "Epoch 13/40\n",
      "13s - loss: 0.5866 - acc: 0.7398\n",
      "Epoch 14/40\n",
      "12s - loss: 0.5838 - acc: 0.7417\n",
      "Epoch 15/40\n",
      "13s - loss: 0.5840 - acc: 0.7418\n",
      "Epoch 16/40\n",
      "14s - loss: 0.5836 - acc: 0.7419\n",
      "Epoch 17/40\n",
      "13s - loss: 0.5834 - acc: 0.7398\n",
      "Epoch 18/40\n",
      "12s - loss: 0.5809 - acc: 0.7418\n",
      "Epoch 19/40\n",
      "15s - loss: 0.5797 - acc: 0.7429\n",
      "Epoch 20/40\n",
      "13s - loss: 0.5797 - acc: 0.7431\n",
      "Epoch 21/40\n",
      "12s - loss: 0.5782 - acc: 0.7423\n",
      "Epoch 22/40\n",
      "13s - loss: 0.5772 - acc: 0.7445\n",
      "Epoch 23/40\n",
      "13s - loss: 0.5761 - acc: 0.7442\n",
      "Epoch 24/40\n",
      "15s - loss: 0.5760 - acc: 0.7439\n",
      "Epoch 25/40\n",
      "13s - loss: 0.5765 - acc: 0.7469\n",
      "Epoch 26/40\n",
      "12s - loss: 0.5750 - acc: 0.7461\n",
      "Epoch 27/40\n",
      "14s - loss: 0.5730 - acc: 0.7471\n",
      "Epoch 28/40\n",
      "14s - loss: 0.5735 - acc: 0.7476\n",
      "Epoch 29/40\n",
      "13s - loss: 0.5750 - acc: 0.7460\n",
      "Epoch 30/40\n",
      "16s - loss: 0.5703 - acc: 0.7473\n",
      "Epoch 31/40\n",
      "15s - loss: 0.5723 - acc: 0.7466\n",
      "Epoch 32/40\n",
      "14s - loss: 0.5703 - acc: 0.7495\n",
      "Epoch 33/40\n",
      "12s - loss: 0.5716 - acc: 0.7484\n",
      "Epoch 34/40\n",
      "15s - loss: 0.5702 - acc: 0.7475\n",
      "Epoch 35/40\n",
      "11s - loss: 0.5701 - acc: 0.7471\n",
      "Epoch 36/40\n",
      "13s - loss: 0.5698 - acc: 0.7470\n",
      "Epoch 37/40\n",
      "11s - loss: 0.5689 - acc: 0.7498\n",
      "Epoch 38/40\n",
      "12s - loss: 0.5669 - acc: 0.7497\n",
      "Epoch 39/40\n",
      "13s - loss: 0.5684 - acc: 0.7496\n",
      "Epoch 40/40\n",
      "11s - loss: 0.5692 - acc: 0.7504\n",
      "9344/9871 [===========================>..] - ETA: 0s \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bthe cv_score for the 2 turn is:\n",
      "0.561057228677\n",
      "Epoch 1/40\n",
      "15s - loss: 0.7088 - acc: 0.7025\n",
      "Epoch 2/40\n",
      "12s - loss: 0.6274 - acc: 0.7263\n",
      "Epoch 3/40\n",
      "14s - loss: 0.6143 - acc: 0.7312\n",
      "Epoch 4/40\n",
      "12s - loss: 0.6087 - acc: 0.7317\n",
      "Epoch 5/40\n",
      "13s - loss: 0.6012 - acc: 0.7336\n",
      "Epoch 6/40\n",
      "12s - loss: 0.5972 - acc: 0.7355\n",
      "Epoch 7/40\n",
      "13s - loss: 0.5944 - acc: 0.7387\n",
      "Epoch 8/40\n",
      "14s - loss: 0.5945 - acc: 0.7376\n",
      "Epoch 9/40\n",
      "13s - loss: 0.5914 - acc: 0.7373\n",
      "Epoch 10/40\n",
      "11s - loss: 0.5887 - acc: 0.7391\n",
      "Epoch 11/40\n",
      "12s - loss: 0.5900 - acc: 0.7383\n",
      "Epoch 12/40\n",
      "13s - loss: 0.5881 - acc: 0.7414\n",
      "Epoch 13/40\n",
      "13s - loss: 0.5867 - acc: 0.7415\n",
      "Epoch 14/40\n",
      "10s - loss: 0.5840 - acc: 0.7421\n",
      "Epoch 15/40\n",
      "13s - loss: 0.5837 - acc: 0.7412\n",
      "Epoch 16/40\n",
      "14s - loss: 0.5842 - acc: 0.7408\n",
      "Epoch 17/40\n",
      "12s - loss: 0.5807 - acc: 0.7435\n",
      "Epoch 18/40\n",
      "14s - loss: 0.5805 - acc: 0.7426\n",
      "Epoch 19/40\n",
      "14s - loss: 0.5801 - acc: 0.7443\n",
      "Epoch 20/40\n",
      "17s - loss: 0.5812 - acc: 0.7444\n",
      "Epoch 21/40\n",
      "12s - loss: 0.5776 - acc: 0.7434\n",
      "Epoch 22/40\n",
      "17s - loss: 0.5765 - acc: 0.7433\n",
      "Epoch 23/40\n",
      "16s - loss: 0.5770 - acc: 0.7470\n",
      "Epoch 24/40\n",
      "15s - loss: 0.5757 - acc: 0.7442\n",
      "Epoch 25/40\n",
      "12s - loss: 0.5755 - acc: 0.7446\n",
      "Epoch 26/40\n",
      "14s - loss: 0.5744 - acc: 0.7449\n",
      "Epoch 27/40\n",
      "15s - loss: 0.5746 - acc: 0.7467\n",
      "Epoch 28/40\n",
      "15s - loss: 0.5733 - acc: 0.7459\n",
      "Epoch 29/40\n",
      "16s - loss: 0.5713 - acc: 0.7467\n",
      "Epoch 30/40\n",
      "12s - loss: 0.5732 - acc: 0.7467\n",
      "Epoch 31/40\n",
      "13s - loss: 0.5712 - acc: 0.7476\n",
      "Epoch 32/40\n",
      "13s - loss: 0.5717 - acc: 0.7480\n",
      "Epoch 33/40\n",
      "8s - loss: 0.5703 - acc: 0.7471\n",
      "Epoch 34/40\n",
      "7s - loss: 0.5696 - acc: 0.7482\n",
      "Epoch 35/40\n",
      "5s - loss: 0.5691 - acc: 0.7486\n",
      "Epoch 36/40\n",
      "6s - loss: 0.5690 - acc: 0.7484\n",
      "Epoch 37/40\n",
      "8s - loss: 0.5679 - acc: 0.7494\n",
      "Epoch 38/40\n",
      "6s - loss: 0.5679 - acc: 0.7490\n",
      "Epoch 39/40\n",
      "5s - loss: 0.5691 - acc: 0.7473\n",
      "Epoch 40/40\n",
      "6s - loss: 0.5661 - acc: 0.7513\n",
      "8928/9871 [==========================>...] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bthe cv_score for the 3 turn is:\n",
      "0.568970155629\n",
      "Epoch 1/40\n",
      "8s - loss: 0.7055 - acc: 0.7051\n",
      "Epoch 2/40\n",
      "8s - loss: 0.6266 - acc: 0.7238\n",
      "Epoch 3/40\n",
      "7s - loss: 0.6124 - acc: 0.7299\n",
      "Epoch 4/40\n",
      "7s - loss: 0.6042 - acc: 0.7340\n",
      "Epoch 5/40\n",
      "7s - loss: 0.6016 - acc: 0.7347\n",
      "Epoch 6/40\n",
      "8s - loss: 0.5968 - acc: 0.7353\n",
      "Epoch 7/40\n",
      "9s - loss: 0.5943 - acc: 0.7371\n",
      "Epoch 8/40\n",
      "7s - loss: 0.5919 - acc: 0.7364\n",
      "Epoch 9/40\n",
      "7s - loss: 0.5909 - acc: 0.7382\n",
      "Epoch 10/40\n",
      "6s - loss: 0.5899 - acc: 0.7378\n",
      "Epoch 11/40\n",
      "8s - loss: 0.5868 - acc: 0.7386\n",
      "Epoch 12/40\n",
      "7s - loss: 0.5847 - acc: 0.7380\n",
      "Epoch 13/40\n",
      "8s - loss: 0.5839 - acc: 0.7404\n",
      "Epoch 14/40\n",
      "6s - loss: 0.5844 - acc: 0.7419\n",
      "Epoch 15/40\n",
      "7s - loss: 0.5823 - acc: 0.7425\n",
      "Epoch 16/40\n",
      "8s - loss: 0.5798 - acc: 0.7409\n",
      "Epoch 17/40\n",
      "7s - loss: 0.5808 - acc: 0.7422\n",
      "Epoch 18/40\n",
      "7s - loss: 0.5802 - acc: 0.7423\n",
      "Epoch 19/40\n",
      "6s - loss: 0.5785 - acc: 0.7414\n",
      "Epoch 20/40\n",
      "7s - loss: 0.5777 - acc: 0.7442\n",
      "Epoch 21/40\n",
      "7s - loss: 0.5781 - acc: 0.7445\n",
      "Epoch 22/40\n",
      "8s - loss: 0.5751 - acc: 0.7444\n",
      "Epoch 23/40\n",
      "9s - loss: 0.5756 - acc: 0.7444\n",
      "Epoch 24/40\n",
      "9s - loss: 0.5732 - acc: 0.7457\n",
      "Epoch 25/40\n",
      "7s - loss: 0.5750 - acc: 0.7462\n",
      "Epoch 26/40\n",
      "7s - loss: 0.5728 - acc: 0.7448\n",
      "Epoch 27/40\n",
      "8s - loss: 0.5743 - acc: 0.7447\n",
      "Epoch 28/40\n",
      "8s - loss: 0.5720 - acc: 0.7449\n",
      "Epoch 29/40\n",
      "7s - loss: 0.5717 - acc: 0.7455\n",
      "Epoch 30/40\n",
      "8s - loss: 0.5728 - acc: 0.7471\n",
      "Epoch 31/40\n",
      "7s - loss: 0.5699 - acc: 0.7475\n",
      "Epoch 32/40\n",
      "6s - loss: 0.5687 - acc: 0.7487\n",
      "Epoch 33/40\n",
      "6s - loss: 0.5689 - acc: 0.7465\n",
      "Epoch 34/40\n",
      "7s - loss: 0.5697 - acc: 0.7473\n",
      "Epoch 35/40\n",
      "7s - loss: 0.5678 - acc: 0.7453\n",
      "Epoch 36/40\n",
      "8s - loss: 0.5689 - acc: 0.7455\n",
      "Epoch 37/40\n",
      "8s - loss: 0.5678 - acc: 0.7473\n",
      "Epoch 38/40\n",
      "8s - loss: 0.5696 - acc: 0.7476\n",
      "Epoch 39/40\n",
      "7s - loss: 0.5678 - acc: 0.7498\n",
      "Epoch 40/40\n",
      "8s - loss: 0.5658 - acc: 0.7493\n",
      "9312/9871 [===========================>..] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bthe cv_score for the 4 turn is:\n",
      "0.568841445137\n",
      "Epoch 1/40\n",
      "8s - loss: 0.7086 - acc: 0.7019\n",
      "Epoch 2/40\n",
      "8s - loss: 0.6296 - acc: 0.7217\n",
      "Epoch 3/40\n",
      "5s - loss: 0.6153 - acc: 0.7281\n",
      "Epoch 4/40\n",
      "7s - loss: 0.6085 - acc: 0.7293\n",
      "Epoch 5/40\n",
      "7s - loss: 0.6015 - acc: 0.7324\n",
      "Epoch 6/40\n",
      "7s - loss: 0.6003 - acc: 0.7338\n",
      "Epoch 7/40\n",
      "6s - loss: 0.5968 - acc: 0.7325\n",
      "Epoch 8/40\n",
      "6s - loss: 0.5954 - acc: 0.7351\n",
      "Epoch 9/40\n",
      "6s - loss: 0.5925 - acc: 0.7361\n",
      "Epoch 10/40\n",
      "6s - loss: 0.5916 - acc: 0.7385\n",
      "Epoch 11/40\n",
      "6s - loss: 0.5903 - acc: 0.7372\n",
      "Epoch 12/40\n",
      "7s - loss: 0.5883 - acc: 0.7382\n",
      "Epoch 13/40\n",
      "8s - loss: 0.5861 - acc: 0.7384\n",
      "Epoch 14/40\n",
      "7s - loss: 0.5856 - acc: 0.7392\n",
      "Epoch 15/40\n",
      "7s - loss: 0.5843 - acc: 0.7402\n",
      "Epoch 16/40\n",
      "7s - loss: 0.5848 - acc: 0.7394\n",
      "Epoch 17/40\n",
      "6s - loss: 0.5820 - acc: 0.7419\n",
      "Epoch 18/40\n",
      "7s - loss: 0.5800 - acc: 0.7404\n",
      "Epoch 19/40\n",
      "7s - loss: 0.5798 - acc: 0.7413\n",
      "Epoch 20/40\n",
      "6s - loss: 0.5806 - acc: 0.7421\n",
      "Epoch 21/40\n",
      "7s - loss: 0.5803 - acc: 0.7424\n",
      "Epoch 22/40\n",
      "6s - loss: 0.5793 - acc: 0.7417\n",
      "Epoch 23/40\n",
      "7s - loss: 0.5773 - acc: 0.7448\n",
      "Epoch 24/40\n",
      "6s - loss: 0.5762 - acc: 0.7428\n",
      "Epoch 25/40\n",
      "7s - loss: 0.5748 - acc: 0.7452\n",
      "Epoch 26/40\n",
      "7s - loss: 0.5749 - acc: 0.7431\n",
      "Epoch 27/40\n",
      "6s - loss: 0.5769 - acc: 0.7437\n",
      "Epoch 28/40\n",
      "7s - loss: 0.5760 - acc: 0.7423\n",
      "Epoch 29/40\n",
      "6s - loss: 0.5749 - acc: 0.7461\n",
      "Epoch 30/40\n",
      "7s - loss: 0.5735 - acc: 0.7457\n",
      "Epoch 31/40\n",
      "6s - loss: 0.5730 - acc: 0.7435\n",
      "Epoch 32/40\n",
      "6s - loss: 0.5728 - acc: 0.7436\n",
      "Epoch 33/40\n",
      "6s - loss: 0.5727 - acc: 0.7468\n",
      "Epoch 34/40\n",
      "5s - loss: 0.5703 - acc: 0.7454\n",
      "Epoch 35/40\n",
      "6s - loss: 0.5715 - acc: 0.7463\n",
      "Epoch 36/40\n",
      "7s - loss: 0.5693 - acc: 0.7466\n",
      "Epoch 37/40\n",
      "7s - loss: 0.5714 - acc: 0.7475\n",
      "Epoch 38/40\n",
      "6s - loss: 0.5720 - acc: 0.7472\n",
      "Epoch 39/40\n",
      "7s - loss: 0.5677 - acc: 0.7486\n",
      "Epoch 40/40\n",
      "6s - loss: 0.5687 - acc: 0.7484\n",
      "9760/9868 [============================>.] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bthe cv_score for the 5 turn is:\n",
      "0.559321642877\n",
      "0.567395737516\n"
     ]
    }
   ],
   "source": [
    "for batch_size in [64]:\n",
    "\n",
    "    i=0\n",
    "    cv_scores=[]\n",
    "    cv_result=[]\n",
    "    for dev_index, val_index in KF:\n",
    "        dev_set, val_set = train_df.iloc[dev_index,:] , train_df.iloc[val_index,:] \n",
    "        dev_X, val_X = dev_set[features].as_matrix(), val_set[features].as_matrix()\n",
    "        dev_y, val_y = train_y[dev_index], train_y[val_index]\n",
    "    \n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=20)\n",
    "\n",
    "        seed = 0\n",
    "        np.random.seed(seed)\n",
    "        model = nn_model(features,lr=0.1)\n",
    "        history=model.fit(dev_X, dev_y, epochs = 40, batch_size=batch_size, verbose = 2 \n",
    "          #,validation_data=[val_X, val_y], callbacks=[early_stopping]\n",
    "                         )\n",
    "        preds =  model.predict_proba(val_X)\n",
    "    \n",
    "            #save the pickles for futures use\n",
    "        pickl_file = store+'nn-5fold-out-'+str(i)+'.pickle'\n",
    "        fileObject = open(pickl_file,'wb') \n",
    "        pickle.dump(preds,fileObject)   \n",
    "        fileObject.close()    \n",
    "        \n",
    "        lls=log_loss(val_y, preds)\n",
    "        cv_scores.append(lls)\n",
    "        cv_result.append(history)\n",
    "        i+=1\n",
    "        print 'the cv_score for the '+str(i)+' turn is:'\n",
    "        print(lls)\n",
    "    \n",
    "    print np.mean(cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "8s - loss: 0.6997 - acc: 0.7037\n",
      "Epoch 2/40\n",
      "8s - loss: 0.6215 - acc: 0.7276\n",
      "Epoch 3/40\n",
      "7s - loss: 0.6106 - acc: 0.7302\n",
      "Epoch 4/40\n",
      "8s - loss: 0.6039 - acc: 0.7332\n",
      "Epoch 5/40\n",
      "7s - loss: 0.5993 - acc: 0.7337\n",
      "Epoch 6/40\n",
      "9s - loss: 0.5948 - acc: 0.7370\n",
      "Epoch 7/40\n",
      "8s - loss: 0.5931 - acc: 0.7375\n",
      "Epoch 8/40\n",
      "8s - loss: 0.5910 - acc: 0.7387\n",
      "Epoch 9/40\n",
      "9s - loss: 0.5896 - acc: 0.7372\n",
      "Epoch 10/40\n",
      "9s - loss: 0.5878 - acc: 0.7412\n",
      "Epoch 11/40\n",
      "9s - loss: 0.5865 - acc: 0.7403\n",
      "Epoch 12/40\n",
      "8s - loss: 0.5853 - acc: 0.7403\n",
      "Epoch 13/40\n",
      "7s - loss: 0.5840 - acc: 0.7419\n",
      "Epoch 14/40\n",
      "8s - loss: 0.5835 - acc: 0.7410\n",
      "Epoch 15/40\n",
      "7s - loss: 0.5812 - acc: 0.7416\n",
      "Epoch 16/40\n",
      "10s - loss: 0.5816 - acc: 0.7425\n",
      "Epoch 17/40\n",
      "8s - loss: 0.5801 - acc: 0.7420\n",
      "Epoch 18/40\n",
      "8s - loss: 0.5801 - acc: 0.7436\n",
      "Epoch 19/40\n",
      "8s - loss: 0.5788 - acc: 0.7415\n",
      "Epoch 20/40\n",
      "9s - loss: 0.5781 - acc: 0.7448\n",
      "Epoch 21/40\n",
      "8s - loss: 0.5757 - acc: 0.7459\n",
      "Epoch 22/40\n",
      "8s - loss: 0.5769 - acc: 0.7430\n",
      "Epoch 23/40\n",
      "8s - loss: 0.5744 - acc: 0.7463\n",
      "Epoch 24/40\n",
      "8s - loss: 0.5738 - acc: 0.7458\n",
      "Epoch 25/40\n",
      "9s - loss: 0.5748 - acc: 0.7457\n",
      "Epoch 26/40\n",
      "8s - loss: 0.5737 - acc: 0.7454\n",
      "Epoch 27/40\n",
      "9s - loss: 0.5731 - acc: 0.7452\n",
      "Epoch 28/40\n",
      "9s - loss: 0.5733 - acc: 0.7462\n",
      "Epoch 29/40\n",
      "8s - loss: 0.5713 - acc: 0.7472\n",
      "Epoch 30/40\n",
      "9s - loss: 0.5704 - acc: 0.7454\n",
      "Epoch 31/40\n",
      "8s - loss: 0.5722 - acc: 0.7455\n",
      "Epoch 32/40\n",
      "11s - loss: 0.5697 - acc: 0.7475\n",
      "Epoch 33/40\n",
      "8s - loss: 0.5697 - acc: 0.7471\n",
      "Epoch 34/40\n",
      "8s - loss: 0.5693 - acc: 0.7476\n",
      "Epoch 35/40\n",
      "9s - loss: 0.5702 - acc: 0.7472\n",
      "Epoch 36/40\n",
      "9s - loss: 0.5665 - acc: 0.7481\n",
      "Epoch 37/40\n",
      "7s - loss: 0.5669 - acc: 0.7492\n",
      "Epoch 38/40\n",
      "9s - loss: 0.5677 - acc: 0.7495\n",
      "Epoch 39/40\n",
      "8s - loss: 0.5678 - acc: 0.7501\n",
      "Epoch 40/40\n",
      "9s - loss: 0.5683 - acc: 0.7497\n",
      "73888/74659 [============================>.] - ETA: 0s \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b"
     ]
    }
   ],
   "source": [
    "\"\"\"trainX testX for et and rf \"\"\"\n",
    "train_X, test_X = train_df[features].as_matrix(), test_df[features].as_matrix()\n",
    "\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "model = nn_model(features,lr=0.1)\n",
    "history=model.fit(train_X, train_y, epochs = 40, batch_size=64, verbose = 2) \n",
    "  #,validation_data=[val_X, val_y])#, callbacks=[early_stopping])\n",
    "\n",
    "preds =  model.predict_proba(test_X)\n",
    "\n",
    "out_df = pd.DataFrame(preds)\n",
    "out_df.columns = [\"high\", \"medium\", \"low\"]\n",
    "out_df[\"listing_id\"] = test_df.listing_id.values\n",
    "out_df.to_json(store+'nn-bulk-out.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out_df.to_json(store+'nn-bulk-out.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
