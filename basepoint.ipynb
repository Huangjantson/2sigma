{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import operator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "import xgboost as xgb\n",
    "from sklearn import  preprocessing, ensemble\n",
    "#from sklearn import model_selection,\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**XGB runner**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def runXGB(train_X, train_y, test_X, test_y=None, feature_names=None, seed_val=0, num_rounds=1000):\n",
    "    param = {}\n",
    "    param['objective'] = 'multi:softprob'\n",
    "    param['eta'] = 0.1\n",
    "    param['max_depth'] = 6\n",
    "    param['silent'] = 1\n",
    "    param['num_class'] = 3\n",
    "    param['eval_metric'] = \"mlogloss\"\n",
    "    param['min_child_weight'] = 1\n",
    "    param['subsample'] = 0.7\n",
    "    param['colsample_bytree'] = 0.7\n",
    "    param['seed'] = seed_val\n",
    "    num_rounds = num_rounds\n",
    "\n",
    "    plst = list(param.items())\n",
    "    xgtrain = xgb.DMatrix(train_X, label=train_y)\n",
    "\n",
    "    if test_y is not None:\n",
    "        xgtest = xgb.DMatrix(test_X, label=test_y)\n",
    "        watchlist = [ (xgtrain,'train'), (xgtest, 'test') ]\n",
    "        model = xgb.train(plst, xgtrain, num_rounds, watchlist, early_stopping_rounds=20)\n",
    "    else:\n",
    "        xgtest = xgb.DMatrix(test_X)\n",
    "        model = xgb.train(plst, xgtrain, num_rounds)\n",
    "\n",
    "    pred_test_y = model.predict(xgtest)\n",
    "    return pred_test_y, model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The form of the list(param.items()) is **\n",
    "[('num_class', 3),\n",
    " ('silent', 1),\n",
    " ('eval_metric', 'mlogloss'),\n",
    " ('min_child_weight', 1),\n",
    " ('subsample', 0.7),\n",
    " ('eta', 0.1),\n",
    " ('objective', 'multi:softprob'),\n",
    " ('colsample_bytree', 0.7),\n",
    " ('max_depth', 6)]\n",
    " **should check the input for xgb.train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49352, 15)\n",
      "(74659, 14)\n"
     ]
    }
   ],
   "source": [
    "data_path = \"../\"\n",
    "train_file = data_path + \"train.json\"\n",
    "test_file = data_path + \"test.json\"\n",
    "train_df = pd.read_json(train_file)\n",
    "test_df = pd.read_json(test_file)\n",
    "print(train_df.shape)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10        53a5b119ba8f7b61d4e010512e0dfc85\n",
       "10000     c5c8a357cba207596b04d1afd1e4f130\n",
       "100004    c3ba40552e2120b0acfc3cb5730bb2aa\n",
       "100007    28d9ad350afeaab8027513a3e52ac8d5\n",
       "100013                                   0\n",
       "100014    38a913e46c94a7f46ddf19b756a9640c\n",
       "100016    3ba49a93260ca5df92fde024cb4ca61f\n",
       "100020    0372927bcb6a0949613ef5bf893bbac7\n",
       "100026    a7efbeb58190aa267b4a9121cd0c88c0\n",
       "100027                                   0\n",
       "100030                                   0\n",
       "10004                                    0\n",
       "100044    67c9b420da4a365bc26a6cd0ef4a5320\n",
       "100048                                   0\n",
       "10005                                    0\n",
       "100051    bfb9405149bfff42a92980b594c28234\n",
       "100052    642cc2c920512ffe2a74c28122f8b47f\n",
       "100053                                   0\n",
       "100055    cc4c6ae9225df6d2395c4e16c235f7ab\n",
       "100058    dc3cae15729b48fec3394f9295671991\n",
       "Name: building_id, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"building_id\"].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_to_use  = [\"bathrooms\", \"bedrooms\", \"latitude\", \"longitude\", \"price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# count of photos #\n",
    "train_df[\"num_photos\"] = train_df[\"photos\"].apply(len)\n",
    "test_df[\"num_photos\"] = test_df[\"photos\"].apply(len)\n",
    "\n",
    "# count of \"features\" #\n",
    "train_df[\"num_features\"] = train_df[\"features\"].apply(len)\n",
    "test_df[\"num_features\"] = test_df[\"features\"].apply(len)\n",
    "\n",
    "# count of words present in description column #\n",
    "train_df[\"num_description_words\"] = train_df[\"description\"].apply(lambda x: len(x.split(\" \")))\n",
    "test_df[\"num_description_words\"] = test_df[\"description\"].apply(lambda x: len(x.split(\" \")))\n",
    "\n",
    "# convert the created column to datetime object so as to extract more features \n",
    "train_df[\"created\"] = pd.to_datetime(train_df[\"created\"])\n",
    "test_df[\"created\"] = pd.to_datetime(test_df[\"created\"])\n",
    "\n",
    "# Let us extract some features like year, month, day, hour from date columns #\n",
    "train_df[\"created_year\"] = train_df[\"created\"].dt.year\n",
    "test_df[\"created_year\"] = test_df[\"created\"].dt.year\n",
    "train_df[\"created_month\"] = train_df[\"created\"].dt.month\n",
    "test_df[\"created_month\"] = test_df[\"created\"].dt.month\n",
    "train_df[\"created_day\"] = train_df[\"created\"].dt.day\n",
    "test_df[\"created_day\"] = test_df[\"created\"].dt.day\n",
    "train_df[\"created_hour\"] = train_df[\"created\"].dt.hour\n",
    "test_df[\"created_hour\"] = test_df[\"created\"].dt.hour\n",
    "\n",
    "# adding all these new features to use list #\n",
    "features_to_use.extend([\"num_photos\", \"num_features\", \"num_description_words\",\"created_year\", \"created_month\", \"created_day\", \"listing_id\", \"created_hour\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Used preprocessing.LabelEncoder() for one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categorical = [\"display_address\", \"manager_id\", \"building_id\", \"street_address\"]\n",
    "for f in categorical:\n",
    "        if train_df[f].dtype=='object':\n",
    "            #print(f)\n",
    "            lbl = preprocessing.LabelEncoder()\n",
    "            lbl.fit(list(train_df[f].values) + list(test_df[f].values))\n",
    "            train_df[f] = lbl.transform(list(train_df[f].values))\n",
    "            test_df[f] = lbl.transform(list(test_df[f].values))\n",
    "            features_to_use.append(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dealing with the 'feature' feature by using tf/idf **\n",
    "The tr_sparse is a sparse matrix for the training data and the te_sparse is a transform for the testing data based on the idf dict from the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10                                                         \n",
      "10000     Doorman Elevator Fitness_Center Cats_Allowed D...\n",
      "100004    Laundry_In_Building Dishwasher Hardwood_Floors...\n",
      "100007                               Hardwood_Floors No_Fee\n",
      "100013                                              Pre-War\n",
      "Name: features, dtype: object\n"
     ]
    }
   ],
   "source": [
    "train_df['features'] = train_df[\"features\"].apply(lambda x: \" \".join([\"_\".join(i.split(\" \")) for i in x]))\n",
    "test_df['features'] = test_df[\"features\"].apply(lambda x: \" \".join([\"_\".join(i.split(\" \")) for i in x]))\n",
    "print(train_df[\"features\"].head())\n",
    "tfidf = CountVectorizer(stop_words='english', max_features=200)\n",
    "tr_sparse = tfidf.fit_transform(train_df[\"features\"])\n",
    "te_sparse = tfidf.transform(test_df[\"features\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10        12282\n",
       "10000      9080\n",
       "100004    13719\n",
       "100007    10866\n",
       "100013    15072\n",
       "100014    15194\n",
       "100016    14964\n",
       "100020    15223\n",
       "100026    11646\n",
       "100027     6459\n",
       "100030    15694\n",
       "10004     14685\n",
       "100044     9660\n",
       "100048    15380\n",
       "10005     10903\n",
       "100051    10791\n",
       "100052     2750\n",
       "100053    13340\n",
       "100055    14962\n",
       "100058     2752\n",
       "100062    12188\n",
       "100063     9584\n",
       "100065    10797\n",
       "100066    12060\n",
       "10007     13956\n",
       "100071    10901\n",
       "100075    10107\n",
       "100076    15369\n",
       "100079     1446\n",
       "100081    10066\n",
       "          ...  \n",
       "99915     12579\n",
       "99917     14366\n",
       "99919     11023\n",
       "99921     12888\n",
       "99923     15464\n",
       "99924      8048\n",
       "99931     13391\n",
       "99933     14899\n",
       "99935     10635\n",
       "99937     15694\n",
       "9994      15523\n",
       "99953     15371\n",
       "99956     12499\n",
       "99960      8636\n",
       "99961     10839\n",
       "99964     10028\n",
       "99965     11088\n",
       "99966     10989\n",
       "99979     11228\n",
       "99980     11841\n",
       "99982     14310\n",
       "99984     10020\n",
       "99986      8953\n",
       "99987     11106\n",
       "99988     10579\n",
       "9999       9577\n",
       "99991     12864\n",
       "99992     15306\n",
       "99993     14850\n",
       "99994     12707\n",
       "Name: display_address, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
