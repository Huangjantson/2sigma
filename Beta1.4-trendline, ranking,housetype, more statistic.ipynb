{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn import  preprocessing, ensemble\n",
    "from sklearn.metrics import log_loss,accuracy_score\n",
    "from sklearn.cross_validation import KFold,StratifiedKFold\n",
    "import re\n",
    "import string\n",
    "from collections import defaultdict, Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#try xgboost\n",
    "#original fucntion from SRK\n",
    "def runXGB(train_X, train_y, test_X, test_y=None, feature_names=None, \\\n",
    "     seed_val=0, early_stop = 20,num_rounds=10000, eta = 0.1,\\\n",
    "     max_depth = 6,cv_dict = None,verbose_eval=True):\n",
    "    param = {}\n",
    "    param['objective'] = 'multi:softprob'\n",
    "    param['eta'] = eta\n",
    "    param['max_depth'] = max_depth\n",
    "    param['silent'] = 1\n",
    "    param['num_class'] = 3\n",
    "    param['eval_metric'] = \"mlogloss\"\n",
    "    param['min_child_weight'] = 1\n",
    "    param['subsample'] = 0.7\n",
    "    param['colsample_bytree'] = 0.7\n",
    "    param['seed'] = seed_val\n",
    "    num_rounds = num_rounds\n",
    "\n",
    "    plst = list(param.items())\n",
    "    xgtrain = xgb.DMatrix(train_X, label=train_y,feature_names=feature_names)\n",
    "\n",
    "    if test_y is not None:\n",
    "        xgtest = xgb.DMatrix(test_X, label=test_y,feature_names=feature_names)\n",
    "        watchlist = [ (xgtrain,'train'), (xgtest, 'test') ]\n",
    "        model = xgb.train(plst, xgtrain, num_rounds, watchlist,\\\n",
    "        early_stopping_rounds=early_stop,evals_result = cv_dict,verbose_eval = verbose_eval)\n",
    "    else:\n",
    "        xgtest = xgb.DMatrix(test_X,feature_names=feature_names)\n",
    "        model = xgb.train(plst, xgtrain, num_rounds)\n",
    "\n",
    "    pred_test_y = model.predict(xgtest)\n",
    "    return pred_test_y, model\n",
    "\n",
    "class CVstatistics(object):\n",
    "    \n",
    "    \"\"\"\n",
    "    self.result : the result dataframe storing the cv results\n",
    "    self.endpoint : the first ending point for the validations\n",
    "    self.turns: the turns for each validation\n",
    "    \n",
    "    validCurve : plot the validation curve,stop at the first endpoint\n",
    "    errorsAt: return the average errors at a certain turn\n",
    "    \"\"\"\n",
    "    def __init__(self,result_dict,metric,k=5):\n",
    "        self.metric = metric\n",
    "        if type(result_dict) == pd.DataFrame:\n",
    "            self.result = result_dict\n",
    "        else:\n",
    "            temp_dict = {}\n",
    "            for phase in ['train','test']:\n",
    "                for turn in range(k):\n",
    "                    temp_dict[phase+str(turn)]=cv_result[turn][phase][metric]\n",
    "                    self.result=pd.DataFrame(dict([ (key,pd.Series(v)) for key,v in temp_dict.iteritems()]))    \n",
    "        \n",
    "        self.endpoint =len(self.result.filter(like = 'train').dropna())\n",
    "        \n",
    "        self.turns = self.result.filter(like = 'test').\\\n",
    "            apply(lambda x : ~np.isnan(x)).cumsum(axis=0).iloc[len(self.result)-1,:]\n",
    "\n",
    "    def validCurve(self,start = 0, stop_at_first = True):\n",
    "        if stop_at_first:\n",
    "            eout = self.result.iloc[start:,:].filter(like = 'test').dropna().mean(axis=1)\n",
    "            ein =  self.result.iloc[start:,:].filter(like = 'train').dropna().mean(axis=1)\n",
    "        else:\n",
    "            eout = self.result.iloc[start:,:].filter(like = 'test').mean(axis=1)\n",
    "            ein =  self.result.iloc[start:,:].filter(like = 'train').mean(axis=1)\n",
    "        plt.plot(map(lambda x :x+start,range(len(eout))), eout,\n",
    "        map(lambda x :x+start,range(len(ein))), ein)\n",
    "        plt.xlabel(\"turn\")\n",
    "        plt.ylabel(self.metric)\n",
    "        plt.title('Validation Curve')\n",
    "        \n",
    "        plt.show()\n",
    "    \n",
    "    def eoutCurve(self,stop_at_first = True):\n",
    "        if stop_at_first:\n",
    "            eout = self.result.iloc[start:,:].filter(like = 'test').dropna().mean(axis=1)\n",
    "        else:\n",
    "            eout = self.result.iloc[start:,:].filter(like = 'test').mean(axis=1)\n",
    "        plt.plot(map(lambda x :x+start,range(len(eout))), eout)\n",
    "        plt.xlabel(\"turn\")\n",
    "        plt.ylabel(self.metric)\n",
    "        plt.title('Eout Curve')\n",
    "        \n",
    "        plt.show()\n",
    "        \n",
    "    def minAvgEout(self):\n",
    "        meanTestError = cvResult.result.filter(like='test').mean(axis=1)\n",
    "        return meanTestError[meanTestError==np.min(meanTestError)]\n",
    "    \n",
    "    def errorsAt(self,turn):\n",
    "        eout = self.result.filter(like = 'test').loc[turn].mean()\n",
    "        ein = self.result.filter(like = 'train').loc[turn].mean()\n",
    "        return eout,ein\n",
    "    \n",
    "def xgbImportance(model,factor_name):\n",
    "    factors = model.get_score(importance_type=factor_name)\n",
    "    factor_list = []\n",
    "    total = sum(factors.values())\n",
    "    for key in factors:\n",
    "        factors[key] = factors[key]*1.0/total\n",
    "        factor_list.append((key,factors[key]))\n",
    "    return sorted(factor_list,key=lambda x : x[1],reverse=True)\n",
    "    \n",
    "def showFscore(model,normalize = True):\n",
    "    factors = model.get_fscore()\n",
    "    factor_list = []\n",
    "    total = sum(factors.values())\n",
    "    for key in factors:\n",
    "        if normalize:\n",
    "            factors[key] = factors[key]*1.0/total\n",
    "        else:\n",
    "            factors[key] = factors[key]\n",
    "        factor_list.append((key,factors[key]))\n",
    "    return sorted(factor_list,key=lambda x : x[1],reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#feature processing functions\n",
    "#define punctutaion filter\n",
    "def removePunctuation(x):\n",
    "    #filter the head or tail blanks\n",
    "    x = re.sub(r'^\\s+',r' ',x)\n",
    "    x = re.sub(r'\\s+$',r' ',x)\n",
    "    \n",
    "    # Lowercasing all words\n",
    "    x = x.lower()\n",
    "    # Removing non ASCII chars, warning if you are dealing with other languages!!!!!!!!!!!!!!!\n",
    "    x = re.sub(r'[^\\x00-\\x7f]',r' ',x)\n",
    "    #change all the blank to space\n",
    "    x = re.sub(r'\\s',r' ',x)\n",
    "    # Removing (replacing with empty spaces actually) all the punctuations\n",
    "    removing = string.punctuation#.replace('-','')# except '-'\n",
    "    removed = re.sub(\"[\"+removing+\"]\", \"\", x)\n",
    "    #removing the line-changing\n",
    "    #removed = re.sub('\\\\n',\" \",removed)    \n",
    "    return removed\n",
    "\n",
    "#feature processing functions\n",
    "def proecessStreet(address):\n",
    "    #remove the building number\n",
    "    pattern = re.compile('^[\\d-]*[\\s]+')\n",
    "    street = removePunctuation(pattern.sub('',address))\n",
    "    \n",
    "    #sub the st to street\n",
    "    pattern = re.compile('( st)$')\n",
    "    street = pattern.sub(' street',street)\n",
    "    \n",
    "    #sub the ave to avenue\n",
    "    pattern = re.compile('( ave)$')\n",
    "    street = pattern.sub(' avenue',street)\n",
    "    \n",
    "    pattern = re.compile('(\\d+)((th)|(st)|(rd)|(nd))')\n",
    "    street = pattern.sub('\\g<1>',street)\n",
    "    \n",
    "    #deal with the w 14 street => west 14 street\n",
    "    pattern = re.compile('(w)(\\s+)(\\d+)')    \n",
    "    street = pattern.sub('west \\g<3>',street)\n",
    "    \n",
    "    #deal with the e....\n",
    "    pattern = re.compile('(e)(\\s+)(\\d+)')    \n",
    "    street = pattern.sub('east \\g<3>',street)\n",
    "    \n",
    "    return street\n",
    "    \n",
    "#from \"this is a lit\"s python version by rakhlin\n",
    "def singleValueConvert(df1,df2,column,minimum_size=5):\n",
    "    ps = df1[column].append(df2[column])\n",
    "    grouped = ps.groupby(ps).size().to_frame().rename(columns={0: \"size\"})\n",
    "    df1.loc[df1.join(grouped, on=column, how=\"left\")[\"size\"] <= minimum_size, column] = -1\n",
    "    df2.loc[df2.join(grouped, on=column, how=\"left\")[\"size\"] <= minimum_size, column] = -1\n",
    "    return df1, df2\n",
    "\n",
    "#add ranking for this function\n",
    "def performance_eval(train_df,test_df,feature,k,smoothing=True,g=1,f=1,update_df =None,random = None):\n",
    "    target_num_map = {'High':2, 'Medium':1, 'Low':0}\n",
    "    temp=pd.concat([train_df[feature],pd.get_dummies(train_df.interest_level)], axis = 1)\\\n",
    "         .groupby(feature).mean()\n",
    "     \n",
    "    new_feature = feature+'_perf'\n",
    "    new_rank = feature+'_rank'\n",
    "    new_nrank = feature+'_nrank'\n",
    "    \n",
    "    temp.columns = ['tempHigh','tempLow', 'tempMed']\n",
    "    \n",
    "    temp[feature+'_origin'] = temp['tempHigh']*2 + temp['tempMed']\n",
    "    mean_values = temp.loc[:, feature+'_origin'].mean()\n",
    "\n",
    "    temp['count'] = train_df.groupby(feature).count().iloc[:,1]\n",
    "    if smoothing:\n",
    "        temp[\"lambda\"] = g / (g + np.exp((k - temp[\"count\"] )/f))\n",
    "        temp[new_feature] = temp[\"lambda\"]*temp[feature+'_origin']+(1-temp[\"lambda\"])*mean_values\n",
    "    else:\n",
    "        temp[new_feature] = temp[feature+'_origin']\n",
    "        \n",
    "    temp[new_rank]=temp[new_feature].rank()\n",
    "    temp[new_nrank]=temp[new_rank]/temp['count']\n",
    "    \n",
    "    # Add uniform noise. Not mentioned in original paper.adding to each manager\n",
    "    if random:\n",
    "        temp[new_feature] *= np.random.uniform(1 - random, 1 + random, len(temp))     \n",
    "\n",
    "    value = test_df[[feature]].join(temp, on=feature, how=\"left\")[[new_feature,new_rank,new_nrank]].fillna(mean_values)\n",
    "    \n",
    "    if update_df is None: update_df = test_df\n",
    "    if new_feature not in update_df.columns: update_df[new_feature] = np.nan\n",
    "    if new_rank not in update_df.columns: update_df[new_rank] = np.nan\n",
    "    if new_nrank not in update_df.columns: update_df[new_nrank] = np.nan\n",
    "\n",
    "    update_df.update(value)\n",
    "    \n",
    "#functions for features\n",
    "def featureList(train_df,test_df,limit = 0.001):\n",
    "    #acquiring the feature lists\n",
    "    features_in_train = train_df[\"features\"].apply(pd.Series).unstack().reset_index(drop = True).dropna().value_counts()\n",
    "    features_in_test = test_df[\"features\"].apply(pd.Series).unstack().reset_index(drop = True).dropna().value_counts()\n",
    "    \n",
    "    filtered_features_in_train = features_in_train[features_in_train > limit*len(train_df)]\n",
    "    filtered_features_in_test = features_in_test[features_in_test > limit*len(test_df)]\n",
    "    accept_list = set(filtered_features_in_train.index).union(set(filtered_features_in_test.index))\n",
    "    return accept_list\n",
    "\n",
    "def featureMapping(train_df,test_df,feature_list):\n",
    "    for feature in feature_list:\n",
    "        #add the feature column for both\n",
    "        #if feature in the row, then set the value for (row,feature) to 1\n",
    "        train_df['with_'+feature]=train_df['features'].apply(lambda x : 1 if feature in x else 0)\n",
    "        test_df['with_'+feature]=test_df['features'].apply(lambda x : 1 if feature in x else 0)\n",
    "    return\n",
    "\n",
    "#new function for clustering\n",
    "def getCluster(train_df,test_df,k):\n",
    "    cluster = KMeans(k,random_state = 2333)\n",
    "    cluster.fit(train_df[['latitude', 'longitude']].dropna())\n",
    "    train_df['cluster_id_'+str(k)]=map(lambda x,y: cluster.predict(np.array([x,y]).reshape(1,-1))[0] \\\n",
    "                           if ~(np.isnan(x)|np.isnan(y)) else -1,\\\n",
    "                           train_df['latitude'],train_df['longitude'])\n",
    "    test_df['cluster_id_'+str(k)]=map(lambda x,y: cluster.predict(np.array([x,y]).reshape(1,-1))[0] \\\n",
    "                           if ~(np.isnan(x)|np.isnan(y)) else -1,\\\n",
    "                           test_df['latitude'],test_df['longitude'])\n",
    "    \n",
    "#setting the outliers to be nan. to be test\n",
    "def processMap(df):\n",
    "    for i in ['latitude', 'longitude']:\n",
    "        Q1 = df[i].quantile(0.005)\n",
    "        Q3 = df[i].quantile(0.995)\n",
    "        IQR = Q3 - Q1\n",
    "        upper = Q3\n",
    "        lower = Q1\n",
    "        df.ix[(df[i]>upper)|(df[i]<lower),i] = np.nan\n",
    "        #df.ix[:,i] =  df[i].round(3) \n",
    "    return \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def manager_lon_lat(train_df,test_df):\n",
    "    \n",
    "    #adding the features about distance and location\n",
    "    temp=train_df[['manager_id',\"latitude\", \"longitude\"]].dropna()\n",
    "    mean_value = temp.groupby('manager_id')[[\"latitude\", \"longitude\"]].mean().round(4)\n",
    "    mean_value.columns = ['mlat','mlon']\n",
    "    std_value = train_df.groupby('manager_id')[[\"latitude\", \"longitude\"]].std()\n",
    "    mstd = std_value[[\"latitude\", \"longitude\"]].mean()\n",
    "    std_value['latitude']=std_value['latitude'].fillna(mstd['latitude'])\n",
    "    std_value['longitude']=std_value['longitude'].fillna(mstd['longitude'])\n",
    "    #manager mean distance\n",
    "    std_value['m_m_distance'] = map(lambda x,y:np.sqrt(x**2+y**2).round(4),\\\n",
    "                                    std_value['latitude'],std_value['longitude'])\n",
    "    \n",
    "    value = pd.concat([mean_value,std_value])\n",
    "\n",
    "    updateMTest = test_df[['manager_id']].join(mean_value, on = 'manager_id', how=\"left\")[['mlat','mlon']].fillna(-1)\n",
    "    updateDTest = test_df[['manager_id']].join(std_value, on='manager_id', how=\"left\")['m_m_distance'].fillna(-1)\n",
    "    updateMTrain = train_df[['manager_id']].join(mean_value, on = 'manager_id', how=\"left\")[['mlat','mlon']].fillna(-1)\n",
    "    updateDTrain = train_df[['manager_id']].join(std_value, on='manager_id', how=\"left\")['m_m_distance'].fillna(-1)\n",
    "    \n",
    "    for f in ['mlat','mlon','m_m_distance']:\n",
    "        if f not in test_df.columns: \n",
    "            test_df[f] = np.nan\n",
    "        if f not in train_df.columns: \n",
    "            train_df[f] = np.nan\n",
    "    \n",
    "    test_df.update(updateDTest)\n",
    "    test_df.update(updateMTest)\n",
    "    \n",
    "    train_df.update(updateDTrain)\n",
    "    train_df.update(updateMTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def categorical_size(train_df,test_df,cf):\n",
    "    values =train_df.groupby(cf)['interest_level'].agg({'size':'size'})\n",
    "    values = values.add_prefix(cf+'_')\n",
    "    new_feature = list(values.columns)\n",
    "    updateTest = test_df[[cf]].join(values, on = cf, how=\"left\")[new_feature].fillna(-1)\n",
    "    updateTrain = train_df[[cf]].join(values, on = cf, how=\"left\")[new_feature]#.fillna(-1)\n",
    "    \n",
    "    for f in new_feature:\n",
    "        if f not in test_df.columns: \n",
    "            test_df[f] = np.nan\n",
    "        if f not in train_df.columns:\n",
    "            train_df[f] = np.nan\n",
    "    #update the statistics excluding the normalized value\n",
    "    test_df.update(updateTest)\n",
    "    train_df.update(updateTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#the new one not using cv-manner for the statistics\n",
    "def categorical_statistics(train_df,test_df,cf,nf,\\\n",
    "                           get_median=True,get_min = True,get_max = True,\\\n",
    "                           get_normalized_in_group = True,mini_size = 20):\n",
    "    statistics ={}\n",
    "    statistics['mean']='mean'\n",
    "    statistics['std']='std'\n",
    "    statistics['size']='size'\n",
    "\n",
    "    if get_max:\n",
    "        statistics['max']='max'\n",
    "    if get_min:\n",
    "        statistics['min']='min'\n",
    "    if get_median:\n",
    "        statistics['median']='median'\n",
    "        \n",
    "    values = train_df.groupby(cf)[nf].agg(statistics)\n",
    "    values = values.add_prefix(cf+'_'+nf+'_')\n",
    "    \n",
    "    new_feature = list(values.columns)\n",
    "    \n",
    "    #consider using -1 for others\n",
    "    updateTest = test_df[[cf]].join(values, on = cf, how=\"left\")[new_feature]#.fillna(-1)\n",
    "    updateTrain = train_df[[cf]].join(values, on = cf, how=\"left\")[new_feature]#.fillna(-1)\n",
    "        \n",
    "    for f in new_feature:\n",
    "        if f not in test_df.columns: \n",
    "            test_df[f] = np.nan\n",
    "        if f not in train_df.columns:\n",
    "            train_df[f] = np.nan\n",
    "    #update the statistics excluding the normalized value\n",
    "    test_df.update(updateTest)\n",
    "    train_df.update(updateTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#the old one for using cv-manner\n",
    "def categorical_statistics(train_df,test_df,cf,nf,\\\n",
    "                           get_median=True,get_min = True,get_max = True,\\\n",
    "                           get_normalized_in_group = True,update_df = None):\n",
    "    statistics ={}\n",
    "    statistics['mean']='mean'\n",
    "    statistics['std']='std'\n",
    "    statistics['size']='size'\n",
    "\n",
    "    if get_max:\n",
    "        statistics['max']='max'\n",
    "    if get_min:\n",
    "        statistics['min']='min'\n",
    "    if get_median:\n",
    "        statistics['median']='median'\n",
    "        \n",
    "    values = train_df.groupby(cf)[nf].agg(statistics)\n",
    "    values = values.add_prefix(cf+'_'+nf+'_')\n",
    "    \n",
    "    new_feature = list(values.columns)\n",
    "    \n",
    "    \n",
    "    #consider using -1 for others\n",
    "    updateTest = test_df[[cf]].join(values, on = cf, how=\"left\")[new_feature]#.fillna(-1)\n",
    "    \n",
    "    if update_df is None: update_df = test_df\n",
    "\n",
    "    \n",
    "    for f in new_feature:\n",
    "        if f not in update_df.columns: \n",
    "            update_df[f] = np.nan\n",
    "\n",
    "    #update the statistics excluding the normalized value\n",
    "    update_df.update(updateTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rank_on_categorical(train_df,test_df,cf,nf,mini_size=20,random=None):\n",
    "    base = train_df.groupby(cf)[nf].agg({'rank':'rank','size':'size'})\n",
    "    base['nrank'] = base['rank']/base['size']\n",
    "    \n",
    "    if mini_size:\n",
    "        base.ix[base['size']<mini_size,:] = -1\n",
    "    \n",
    "    updateTrain = train_df[[cf]].join(base, on = cf, how=\"left\").fillna(-1)\n",
    "    updateTest = test_df[[cf]].join(base,on=cf,how = 'left').fillna(-1)\n",
    "\n",
    "    n_feature = cf+'_'+nf+'_nrank'\n",
    "    r_feature = cf+'_'+nf+'_rank'\n",
    "    \n",
    "    train_df[n_feature] =  updateTrain['rank']\n",
    "    train_df[r_feature] =  updateTrain['nrank']\n",
    "    \n",
    "    test_df[n_feature] =  updateTest['rank']\n",
    "    test_df[r_feature] =  updateTest['nrank']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#try performance instead of high&medium\n",
    "def temporalManagerPerf(train_df,test_df,update_df =None):\n",
    "    temp=pd.concat([train_df,pd.get_dummies(train_df.interest_level)], axis = 1)\n",
    "    tempTrain = temp[['manager_id','dayofyear','high','low','medium']].set_index('manager_id')\n",
    "    tempTest = test_df[['manager_id','dayofyear']]\n",
    "    tempJoin = tempTest.join(tempTrain,on='manager_id',how='left', rsuffix='_toSum')\n",
    "    \n",
    "    #3 day performance\n",
    "    performance_3 = tempJoin[tempJoin['dayofyear'] - tempJoin['dayofyear_toSum']<4]\n",
    "    performance_3 = performance_3.groupby(performance_3.index).sum()[['high','low','medium']]\n",
    "    performance_3['total'] = performance_3['high']+performance_3['low']+performance_3['medium']\n",
    "    performance_3['m3perf'] = (2*performance_3['high']+performance_3['medium'])*1.0/performance_3['total']\n",
    "\n",
    "    \n",
    "    performance_7 = tempJoin[tempJoin['dayofyear'] - tempJoin['dayofyear_toSum']<8]\n",
    "    performance_7 = performance_7.groupby(performance_7.index).sum()[['high','low','medium']]\n",
    "    performance_7['total'] = performance_7['high']+performance_7['low']+performance_7['medium']\n",
    "    performance_7['m7perf'] = (2*performance_7['high']+performance_7['medium'])*1.0/performance_7['total']\n",
    "    \n",
    "    performance_14 = tempJoin[tempJoin['dayofyear'] - tempJoin['dayofyear_toSum']<15]\n",
    "    performance_14 = performance_14.groupby(performance_14.index).sum()[['high','low','medium']]\n",
    "    performance_14['total'] = performance_14['high']+performance_14['low']+performance_14['medium']\n",
    "    performance_14['m14perf'] = (2*performance_14['high']+performance_14['medium'])*1.0/performance_14['total']\n",
    "\n",
    "    \n",
    "    performance_30 = tempJoin[tempJoin['dayofyear'] - tempJoin['dayofyear_toSum']<31]\n",
    "    performance_30 = performance_30.groupby(performance_30.index).sum()[['high','low','medium']]\n",
    "    performance_30['total'] = performance_30['high']+performance_30['low']+performance_30['medium']\n",
    "    performance_30['m30perf'] = (2*performance_30['high']+performance_30['medium'])*1.0/performance_30['total']\n",
    "\n",
    "    update = pd.concat([performance_3[['m3perf']],performance_7[['m7perf']],\\\n",
    "                        performance_14[['m14perf']],performance_30[['m30perf']]],axis=1).fillna(-1)\n",
    "\n",
    "    if update_df is None: update_df = test_df\n",
    "    \n",
    "    new_features = ['m3perf','m7perf','m14perf','m30perf']\n",
    "    \n",
    "    for f in new_features:\n",
    "        if f not in update_df.columns: \n",
    "             update_df[f] = np.nan\n",
    "    \n",
    "    update_df.update(update)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49352, 15)\n",
      "(74659, 14)\n"
     ]
    }
   ],
   "source": [
    "#lodaing data\n",
    "data_path = \"../../kaggleData/2sigma/\"\n",
    "train_file = data_path + \"train.json\"\n",
    "test_file = data_path + \"test.json\"\n",
    "train_df = pd.read_json(train_file)\n",
    "test_df = pd.read_json(test_file)\n",
    "print(train_df.shape)\n",
    "print(test_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#basic numerical features\n",
    "features_to_use  = [\"bathrooms\", \"bedrooms\", \"latitude\", \"longitude\", \"price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#some transfromed features\n",
    "# count of photos #\n",
    "train_df[\"num_photos\"] = train_df[\"photos\"].apply(len)\n",
    "#test_df[\"num_photos\"] = test_df[\"photos\"].apply(len)\n",
    "\n",
    "# count of \"features\" #\n",
    "train_df[\"num_features\"] = train_df[\"features\"].apply(len)\n",
    "#test_df[\"num_features\"] = test_df[\"features\"].apply(len)\n",
    "\n",
    "# count of words present in description column #\n",
    "train_df[\"num_description_words\"] = train_df[\"description\"].apply(lambda x: len(x.split(\" \")))\n",
    "#test_df[\"num_description_words\"] = test_df[\"description\"].apply(lambda x: len(x.split(\" \")))\n",
    "\n",
    "# convert the created column to datetime object so as to extract more features \n",
    "train_df[\"created\"] = pd.to_datetime(train_df[\"created\"])\n",
    "#test_df[\"created\"] = pd.to_datetime(test_df[\"created\"])\n",
    "\n",
    "# Let us extract some features like year, month, day, hour from date columns #\n",
    "train_df[\"created_year\"] = train_df[\"created\"].dt.year\n",
    "#test_df[\"created_year\"] = test_df[\"created\"].dt.year\n",
    "train_df[\"created_month\"] = train_df[\"created\"].dt.month\n",
    "#test_df[\"created_month\"] = test_df[\"created\"].dt.month\n",
    "train_df[\"created_day\"] = train_df[\"created\"].dt.day\n",
    "#test_df[\"created_day\"] = test_df[\"created\"].dt.day\n",
    "train_df[\"created_hour\"] = train_df[\"created\"].dt.hour\n",
    "#test_df[\"created_hour\"] = test_df[\"created\"].dt.hour\n",
    "\n",
    "#some new numerical features related to the price\n",
    "train_df[\"price_per_bath\"] =  (train_df[\"price\"]*1.0/train_df[\"bathrooms\"]).replace(np.Inf,-1)\n",
    "train_df[\"price_per_bed\"] = (train_df[\"price\"]*1.0/train_df[\"bedrooms\"]).replace(np.Inf,-1)\n",
    "train_df[\"bath_per_bed\"] = (train_df[\"bathrooms\"]*1.0/train_df[\"bedrooms\"]).replace(np.Inf,-1)\n",
    "train_df[\"price_per_room\"] = (train_df[\"price\"]*1.0/(train_df[\"bedrooms\"]+train_df[\"bathrooms\"])).replace(np.Inf,-1)\n",
    "\n",
    "#test_df[\"price_per_bath\"] =  (test_df[\"price\"]*1.0/test_df[\"bathrooms\"]).replace(np.Inf,-1)\n",
    "#test_df[\"price_per_bed\"] = (test_df[\"price\"]*1.0/test_df[\"bedrooms\"]).replace(np.Inf,-1)\n",
    "#test_df[\"bath_per_bed\"] = (test_df[\"bathrooms\"]*1.0/test_df[\"bedrooms\"]).replace(np.Inf,-1)\n",
    "#test_df[\"price_per_room\"] = (test_df[\"price\"]*1.0/(test_df[\"bedrooms\"]+test_df[\"bathrooms\"])).replace(np.Inf,-1)\n",
    "\n",
    "\n",
    "# adding all these new features to use list # \"listing_id\",\n",
    "features_to_use.extend([\"num_photos\", \"num_features\", \"num_description_words\",\\\n",
    "                        \"created_year\",\"listing_id\", \"created_month\", \"created_day\", \"created_hour\"])\n",
    "#price new features\n",
    "features_to_use.extend([\"price_per_bed\",\"bath_per_bed\",\"price_per_room\"])\n",
    "\n",
    "#for latter use\n",
    "train_df[\"dayofyear\"] = train_df[\"created\"].dt.dayofyear\n",
    "#test_df[\"dayofyear\"] = test_df[\"created\"].dt.dayofyear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#adding the house type\n",
    "train_df['house_type']=map(lambda x,y:(x,y),train_df['bedrooms'],train_df['bathrooms'])\n",
    "train_df['house_type'] = train_df['house_type'].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#filling outliers with nan\n",
    "processMap(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "new categorical data generated from the old ones\n",
    "\"\"\"\n",
    "#new feature for the street_address, use them instead of the original one\n",
    "train_df[\"street_name\"] = train_df[\"street_address\"].apply(proecessStreet)\n",
    "#test_df[\"street_name\"] = test_df[\"street_address\"].apply(proecessStreet)\n",
    "\n",
    "train_df['building0']=map(lambda x:1 if x== '0' else 0,train_df['building_id'])\n",
    "test_df['building0']=map(lambda x:1 if x== '0' else 0,test_df['building_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#dealing with features\n",
    "\n",
    "#preprocessing for features\n",
    "train_df[\"features\"] = train_df[\"features\"].apply(lambda x:[\"_\".join(i.split(\" \")).lower().strip().replace('-','_') \\\n",
    "                                                            for i in x])\n",
    "#test_df[\"features\"] = test_df[\"features\"].apply(lambda x:[\"_\".join(i.split(\" \")).lower().strip().replace('-','_')\\\n",
    "#                                                          for i in x])\n",
    "#create the accept list\n",
    "accept_list = list(featureList(train_df,test_df,limit = 0.001))\n",
    "\n",
    "#map the feature to dummy slots\n",
    "featureMapping(train_df,test_df,accept_list)\n",
    "features_to_use.extend(map(lambda x : 'with_'+x,accept_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bathrooms', 'bedrooms', 'latitude', 'longitude', 'price', 'num_photos', 'num_features', 'num_description_words', 'created_year', 'listing_id', 'created_month', 'created_day', 'created_hour', 'price_per_bed', 'bath_per_bed', 'price_per_room', u'with_exclusive', u'with_furnished', u'with_lowrise', u'with_common_parking/garage', u'with_pets_on_approval', u'with_terrace', u'with_live_in_superintendent', u'with_newly_renovated', u'with_full_time_doorman', u'with_duplex', u'with_dryer_in_unit', u'with_multi_level', u'with_garden', u'with_hardwood_floors', u'with_on_site_garage', u'with_fireplace', u'with_eat_in_kitchen', u'with_wifi_access', u'with_garage', u'with_subway', u'with_dining_room', u'with_view', u'with_publicoutdoor', u'with_hardwood', u'with_fitness_center', u'with_high_speed_internet', u'with_laundry_in_building', u'with_parking', u'with_garden/patio', u'with_prewar', u'with_on_site_laundry', u'with_valet', u'with_green_building', u'with_short_term_allowed', u'with_new_construction', u'with_reduced_fee', u'with_roofdeck', u'with_stainless_steel_appliances', u'with_simplex', u'with_dishwasher', u'with_washer_in_unit', u'with_cats_allowed', u'with_exposed_brick', u'with_roof_deck', u'with_common_outdoor_space', u'with_outdoor_areas', u'with_common_roof_deck', u'with_no_pets', u'with_childrens_playroom', u'with_central_a/c', u'with_wheelchair_access', u'with_post_war', u'with_renovated', u'with_elevator', u'with_highrise', u'with_loft', u'with_gym', u'with_luxury_building', u'with_outdoor_space', u'with_pre_war', u'with_residents_lounge', u'with_laundry_room', u'with_marble_bath', u'with_laundry_in_unit', u'with_parking_space', u'with_private_outdoor_space', u'with_high_ceiling', u'with_concierge', u'with_walk_in_closet(s)', u'with_doorman', u'with_balcony', u'with_dogs_allowed', u'with_gym/fitness', u'with_storage', u'with_live_in_super', u'with_lounge', u'with_granite_kitchen', u'with_private_balcony', u'with_laundry', u'with_actual_apt._photos', u'with_residents_garden', u'with_pool', u'with_washer/dryer', u'with_light', u'with_swimming_pool', u'with_high_ceilings', u'with_patio', u'with_no_fee', u'with_bike_room']\n"
     ]
    }
   ],
   "source": [
    "#shorten reprocessing time: save the preprocessed train_df and test_df with some basic features\n",
    "#train_df.to_json('train1.3std.json')\n",
    "#test_df.to_json('test1.3std.json')\n",
    "#print features_to_use\n",
    "#shorten reprocessing time: load the preprocessed train_df and test_df with some basic features\n",
    "#train_df=pd.read_json('train1.3std.json')\n",
    "#test_df=pd.read_json('test1.3std.json')\n",
    "#features_to_use = ['bathrooms', 'bedrooms', 'latitude', 'longitude', 'price', 'num_photos', 'num_features', 'num_description_words', 'created_year', 'listing_id', 'created_month', 'created_day', 'created_hour', 'price_per_bed', 'bath_per_bed', 'price_per_room', u'with_exclusive', u'with_furnished', u'with_lowrise', u'with_common_parking/garage', u'with_pets_on_approval', u'with_terrace', u'with_live_in_superintendent', u'with_newly_renovated', u'with_full_time_doorman', u'with_duplex', u'with_dryer_in_unit', u'with_multi_level', u'with_garden', u'with_hardwood_floors', u'with_on_site_garage', u'with_fireplace', u'with_eat_in_kitchen', u'with_wifi_access', u'with_garage', u'with_subway', u'with_dining_room', u'with_view', u'with_publicoutdoor', u'with_hardwood', u'with_fitness_center', u'with_high_speed_internet', u'with_laundry_in_building', u'with_parking', u'with_garden/patio', u'with_prewar', u'with_on_site_laundry', u'with_valet', u'with_green_building', u'with_short_term_allowed', u'with_new_construction', u'with_reduced_fee', u'with_roofdeck', u'with_stainless_steel_appliances', u'with_simplex', u'with_dishwasher', u'with_washer_in_unit', u'with_cats_allowed', u'with_exposed_brick', u'with_roof_deck', u'with_common_outdoor_space', u'with_outdoor_areas', u'with_common_roof_deck', u'with_no_pets', u'with_childrens_playroom', u'with_central_a/c', u'with_wheelchair_access', u'with_post_war', u'with_renovated', u'with_elevator', u'with_highrise', u'with_loft', u'with_gym', u'with_luxury_building', u'with_outdoor_space', u'with_pre_war', u'with_residents_lounge', u'with_laundry_room', u'with_marble_bath', u'with_laundry_in_unit', u'with_parking_space', u'with_private_outdoor_space', u'with_high_ceiling', u'with_concierge', u'with_walk_in_closet(s)', u'with_doorman', u'with_balcony', u'with_dogs_allowed', u'with_gym/fitness', u'with_storage', u'with_live_in_super', u'with_lounge', u'with_granite_kitchen', u'with_private_balcony', u'with_laundry', u'with_actual_apt._photos', u'with_residents_garden', u'with_pool', u'with_washer/dryer', u'with_light', u'with_swimming_pool', u'with_high_ceilings', u'with_patio', u'with_no_fee', u'with_bike_room']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#prepare for validation\n",
    "target_num_map = {'high':0, 'medium':1, 'low':2}\n",
    "\n",
    "train_y = np.array(train_df['interest_level'].apply(lambda x: target_num_map[x]))\n",
    "\n",
    "KF=StratifiedKFold(train_y,5,shuffle=True,random_state = 42)\n",
    "\n",
    "train_df = train_df.fillna(-1)\n",
    "#test_df = test_df.fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#the basic features from preprocessing \n",
    "features = list(features_to_use)\n",
    "\n",
    "#features to be added during cv by cv-manner statistics\n",
    "features.extend(['manager_id_perf'])\n",
    "features.extend(['m3perf','m7perf','m14perf','m30perf'])\n",
    "features.extend(['manager_id_nrank'])\n",
    "\n",
    "\n",
    "#categorical features to be added\n",
    "categorical = [\"display_address\", \"street_address\",\"street_name\",'building_id','manager_id','building0','house_type']\n",
    "features.extend(categorical)\n",
    "features.extend(['cluster_id_10','cluster_id_30'])\n",
    "\n",
    "#statistical features\n",
    "features.extend(['m_m_distance','mlon','mlat'])\n",
    "\n",
    "main_st_nf = [\"bathrooms\", \"bedrooms\",\"price_per_bed\",\"bath_per_bed\",\"price_per_room\",\\\n",
    "                  \"num_photos\", \"num_features\", \"num_description_words\",'price']\n",
    "main_statistics =['mean','max','min','median']\n",
    "\n",
    "for st in main_statistics:\n",
    "    features.extend(map(lambda x : 'manager_id_'+x+'_'+st,main_st_nf))\n",
    "    features.extend(map(lambda x : 'house_type_'+x+'_'+st,main_st_nf)) \n",
    "\n",
    "features.extend(map(lambda x : 'cluster_id_10_'+x+'_'+'mean',main_st_nf))\n",
    "features.extend(map(lambda x : 'cluster_id_30_'+x+'_'+'mean',main_st_nf))\n",
    "\n",
    "price_related = ['price_per_bed','price_per_room','price']\n",
    "features.extend(map(lambda x : 'house_type_30_'+x+'_nrank',price_related))\n",
    "\n",
    "features.extend(['manager_id_size','house_type_size'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features=list(set(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:116: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/opt/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:117: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/opt/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/opt/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/opt/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/opt/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/opt/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:87: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/opt/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:88: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/opt/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:89: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/opt/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/opt/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/opt/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/opt/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/opt/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/opt/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/opt/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/opt/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/opt/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/opt/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:74: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/opt/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:75: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:1.03553\ttest-mlogloss:1.03576\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 64 rounds.\n",
      "[100]\ttrain-mlogloss:0.5243\ttest-mlogloss:0.551061\n",
      "[200]\ttrain-mlogloss:0.481529\ttest-mlogloss:0.533631\n",
      "[300]\ttrain-mlogloss:0.450678\ttest-mlogloss:0.52639\n",
      "[400]\ttrain-mlogloss:0.42604\ttest-mlogloss:0.522931\n",
      "[500]\ttrain-mlogloss:0.403726\ttest-mlogloss:0.522051\n",
      "Stopping. Best iteration:\n",
      "[511]\ttrain-mlogloss:0.401662\ttest-mlogloss:0.521869\n",
      "\n",
      "loss for the turn 0 is 0.522026661125\n"
     ]
    }
   ],
   "source": [
    "#running and getting the cv from xgboost\n",
    "cv_scores = []\n",
    "cv_result = []\n",
    "models = []\n",
    "\n",
    "i=0\n",
    "for dev_index, val_index in KF: \n",
    "    result_dict = {}\n",
    "    \n",
    "    dev_set, val_set = train_df.iloc[dev_index,:] , train_df.iloc[val_index,:] \n",
    "    \n",
    "    #=============================================================        \n",
    "    \"\"\"feature engineerings for the categorical features\"\"\"\n",
    "    #fill substitute the small size values by their mean\n",
    "    for f in ['display_address','manager_id','building_id','street_name']:\n",
    "        dev_set,val_set  = singleValueConvert(dev_set,val_set,f,1)\n",
    "    \n",
    "    #kmeans grouping\n",
    "    getCluster(dev_set,val_set,30)\n",
    "    getCluster(dev_set,val_set,10)\n",
    "    \n",
    "    \n",
    "    dev_set['house_type_30']=map(lambda x,y:(x,y),dev_set['house_type'],dev_set['cluster_id_30'])\n",
    "    val_set['house_type_30']=map(lambda x,y:(x,y),val_set['house_type'],val_set['cluster_id_30'])\n",
    "        \n",
    "    dev_set['house_type_30'] = dev_set['house_type_30'].apply(str)\n",
    "    val_set['house_type_30'] = val_set['house_type_30'].apply(str)\n",
    "\n",
    "    #K-FOLD evaluation for the statistic features\n",
    "    skf=KFold(len(dev_set['interest_level']),5,shuffle=True,random_state = 42)\n",
    "    #dev set adding manager skill\n",
    "    for train,test in skf:\n",
    "            performance_eval(dev_set.iloc[train,:],dev_set.iloc[test,:],feature='manager_id',k=5,g=10,\n",
    "                           update_df = dev_set,smoothing=False)\n",
    "            temporalManagerPerf(dev_set.iloc[train,:],dev_set.iloc[test,:],\\\n",
    "                           update_df = dev_set)\n",
    "            \"\"\"\n",
    "            #cv-manner statitstic\n",
    "            for f in main_st_nf:\n",
    "                #print f\n",
    "                categorical_statistics(dev_set.iloc[train,:],dev_set.iloc[test,:],'manager_id',f,update_df=dev_set)\n",
    "                categorical_statistics(dev_set.iloc[train,:],dev_set.iloc[test,:],'cluster_id_10',f,update_df=dev_set)\n",
    "                categorical_statistics(dev_set.iloc[train,:],dev_set.iloc[test,:],'cluster_id_30',f,update_df=dev_set)\n",
    "                #categorical_size(dev_set,val_set,'manager_id')\n",
    "            \"\"\"\n",
    "            \n",
    "            \n",
    "    performance_eval(dev_set,val_set,feature='manager_id',k=5,g=10,smoothing=False)\n",
    "    temporalManagerPerf(dev_set,val_set)\n",
    "        \n",
    "        \n",
    "    #statitstic\n",
    "    for f in main_st_nf:\n",
    "        #print f\n",
    "        categorical_statistics(dev_set,val_set,'manager_id',f)\n",
    "        categorical_statistics(dev_set,val_set,'cluster_id_10',f)\n",
    "        categorical_statistics(dev_set,val_set,'cluster_id_30',f)\n",
    "        categorical_statistics(dev_set,val_set,'house_type',f)\n",
    "        categorical_size(dev_set,val_set,'manager_id')\n",
    "        categorical_size(dev_set,val_set,'house_type')\n",
    "    \n",
    "    for f in price_related:\n",
    "        rank_on_categorical(dev_set,val_set,'house_type_30',f,random =None)\n",
    "\n",
    "    \n",
    "    #manager main location\n",
    "    manager_lon_lat(dev_set,val_set)\n",
    "    \n",
    "    for f in categorical:\n",
    "    \n",
    "        if dev_set[f].dtype=='object':\n",
    "            #print(f)\n",
    "            lbl = preprocessing.LabelEncoder()\n",
    "            lbl.fit(list(dev_set[f])+list(val_set[f]))\n",
    "            dev_set[f] = lbl.transform(list(dev_set[f].values))\n",
    "            val_set[f] = lbl.transform(list(val_set[f].values))\n",
    "    \n",
    "    #============================================================\n",
    "    #dev_set.to_csv('having_view.csv',index=False,encoding  = 'utf-8')\n",
    "        \n",
    "    #filter the features\n",
    "    dev_X, val_X = dev_set[features].as_matrix(), val_set[features].as_matrix()\n",
    "    dev_y, val_y = train_y[dev_index], train_y[val_index]\n",
    "\n",
    "    \"\"\"\n",
    "    runXGB(dev_X, train_y, val_X, test_y=None, feature_names=None, \\\n",
    "    seed_val=0, early_stop = 20,num_rounds=10000, eta = 0.1, max_depth = 6)\n",
    "    \"\"\"        \n",
    "    \n",
    "    preds,model = runXGB(dev_X, dev_y, val_X, val_y,feature_names=features,\\\n",
    "           early_stop = 64,num_rounds=10000,eta = 0.1,max_depth=4,cv_dict = result_dict,verbose_eval=100)\n",
    "\n",
    "    loss = log_loss(val_y, preds)\n",
    "    cv_scores.append(loss)\n",
    "    cv_result.append(result_dict)\n",
    "    models.append(model)\n",
    "    print 'loss for the turn '+str(i)+' is '+str(loss)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "test0    800\n",
       "test1    800\n",
       "test2    800\n",
       "test3    800\n",
       "test4    800\n",
       "Name: 799, dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#plot the validation curv\n",
    "cvResult = CVstatistics(cv_result,'mlogloss')\n",
    "cvResult.turns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5b40ebf3d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cvResult.validCurve(start =500,stop_at_first = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([       u'bathrooms',         u'bedrooms',      u'building_id',\n",
       "                u'created',      u'description',  u'display_address',\n",
       "               u'features',   u'interest_level',         u'latitude',\n",
       "             u'listing_id',\n",
       "       ...\n",
       "       u'manager_id_nrank',           u'm3perf',           u'm7perf',\n",
       "                u'm14perf',          u'm30perf',    u'cluster_id_30',\n",
       "          u'cluster_id_10',             u'mlat',             u'mlon',\n",
       "           u'm_m_distance'],\n",
       "      dtype='object', length=220)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_set.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "meanTestError = cvResult.result.filter(like='test').mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "595    0.528103\n",
       "dtype: float64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meanTestError[meanTestError==np.min(meanTestError)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cvResult.result.filter(like='test').mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.52939496933607533"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5282528, 0.40200579999999997)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvResult.errorsAt(550)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('m30perf', 0.046787673038181356),\n",
       " ('m14perf', 0.03493217941756987),\n",
       " ('with_no_fee', 0.025413847226228373),\n",
       " ('with_furnished', 0.022452628438520698),\n",
       " ('price', 0.021225085027586372),\n",
       " ('with_simplex', 0.018795723748467403),\n",
       " ('m7perf', 0.017161803753475532),\n",
       " ('bathrooms', 0.016336954315079158),\n",
       " ('price_per_room', 0.015738347477346645),\n",
       " ('with_hardwood_floors', 0.014448657775336483),\n",
       " ('with_reduced_fee', 0.01441663576808782),\n",
       " ('price_per_bed', 0.01432317506827848),\n",
       " ('with_short_term_allowed', 0.01271395988156673),\n",
       " ('building_id', 0.012354934134110977),\n",
       " ('num_photos', 0.012257453246156251),\n",
       " ('with_hardwood', 0.011807529584957089),\n",
       " ('longitude', 0.011698068005277071),\n",
       " ('bedrooms', 0.011325605803883863),\n",
       " ('with_laundry_in_building', 0.01125500700406142),\n",
       " ('cluster_id_10', 0.011180471914944033),\n",
       " ('created_hour', 0.011147468387016015),\n",
       " ('with_parking_space', 0.01061449893456022),\n",
       " ('latitude', 0.010029675506773314),\n",
       " ('display_address', 0.009880302729647843),\n",
       " ('with_laundry_in_unit', 0.009848444304857236),\n",
       " ('with_private_outdoor_space', 0.009635004608542202),\n",
       " ('mlon', 0.009566018486498615),\n",
       " ('cluster_id_30', 0.009447987589377533),\n",
       " ('with_exclusive', 0.009442961778077665),\n",
       " ('with_parking', 0.009278395924595584),\n",
       " ('with_high_ceiling', 0.009273061642798421),\n",
       " ('with_common_outdoor_space', 0.009206946349615516),\n",
       " ('manager_id_nrank', 0.009170122221178863),\n",
       " ('with_actual_apt._photos', 0.009134505818321743),\n",
       " ('with_on_site_laundry', 0.009046516515148978),\n",
       " ('with_wheelchair_access', 0.008858588033811557),\n",
       " ('with_concierge', 0.008815878286841468),\n",
       " ('with_prewar', 0.008791029131118568),\n",
       " ('with_cats_allowed', 0.008670351413601049),\n",
       " ('num_features', 0.008572937217223449),\n",
       " ('with_central_a/c', 0.00845821903778632),\n",
       " ('with_swimming_pool', 0.008323319061185658),\n",
       " ('listing_id', 0.008313561414846299),\n",
       " ('with_dogs_allowed', 0.008238167675296998),\n",
       " ('with_newly_renovated', 0.008209892855826089),\n",
       " ('with_storage', 0.0080488010056113),\n",
       " ('with_washer_in_unit', 0.008021717665177733),\n",
       " ('with_on_site_garage', 0.007986062864083243),\n",
       " ('bath_per_bed', 0.007979013660758627),\n",
       " ('street_name', 0.007911663693642722),\n",
       " ('mlat', 0.007908147205128332),\n",
       " ('with_doorman', 0.00781752972976882),\n",
       " ('with_balcony', 0.007805844759534776),\n",
       " ('street_address', 0.007795022548145752),\n",
       " ('with_fitness_center', 0.007679701680525737),\n",
       " ('m_m_distance', 0.007664515005202098),\n",
       " ('m3perf', 0.007628554143241963),\n",
       " ('manager_id', 0.007537003498973417),\n",
       " ('with_terrace', 0.007472511407602487),\n",
       " ('num_description_words', 0.007391353308414193),\n",
       " ('with_dishwasher', 0.0073268678551928045),\n",
       " ('with_garden/patio', 0.00722436667640834),\n",
       " ('with_renovated', 0.007212354835483046),\n",
       " ('with_bike_room', 0.007140736585590361),\n",
       " ('with_elevator', 0.007104979137800429),\n",
       " ('with_high_speed_internet', 0.007054509997424322),\n",
       " ('with_dryer_in_unit', 0.006836685348797502),\n",
       " ('with_roof_deck', 0.006794073990564795),\n",
       " ('with_roofdeck', 0.006755468048942704),\n",
       " ('with_multi_level', 0.006740966430717019),\n",
       " ('with_new_construction', 0.0067262220801470735),\n",
       " ('created_day', 0.006680250253878689),\n",
       " ('with_live_in_super', 0.006643006442748539),\n",
       " ('with_laundry', 0.006623584595147144),\n",
       " ('created_month', 0.0065866100457143625),\n",
       " ('with_pre_war', 0.0065211817183923205),\n",
       " ('with_common_parking/garage', 0.006518316809963177),\n",
       " ('with_dining_room', 0.006489783263951252),\n",
       " ('with_fireplace', 0.006436297176439075),\n",
       " ('with_high_ceilings', 0.006400899963718166),\n",
       " ('with_live_in_superintendent', 0.006346321315395294),\n",
       " ('with_loft', 0.006218320831952259),\n",
       " ('with_walk_in_closet(s)', 0.006110469203675902),\n",
       " ('with_granite_kitchen', 0.006025714362547771),\n",
       " ('with_light', 0.006011542971443623),\n",
       " ('with_publicoutdoor', 0.0059859074548233105),\n",
       " ('with_outdoor_space', 0.005978554568427526),\n",
       " ('with_exposed_brick', 0.0058904025025637375),\n",
       " ('with_stainless_steel_appliances', 0.005883007900980755),\n",
       " ('with_garage', 0.005872959078167325),\n",
       " ('with_outdoor_areas', 0.005851588740806097),\n",
       " ('with_pool', 0.005733837729577297),\n",
       " ('with_green_building', 0.0057115347623745835),\n",
       " ('with_common_roof_deck', 0.005660396113723001),\n",
       " ('with_private_balcony', 0.005614334112074305),\n",
       " ('with_lowrise', 0.005350851235537366),\n",
       " ('with_pets_on_approval', 0.005261096442998812),\n",
       " ('with_washer/dryer', 0.005136112005567561),\n",
       " ('with_eat_in_kitchen', 0.005092167504398653),\n",
       " ('with_duplex', 0.004991497104622704),\n",
       " ('with_luxury_building', 0.0049729206341786285),\n",
       " ('with_marble_bath', 0.004971794653928126),\n",
       " ('with_view', 0.004738824408032852),\n",
       " ('with_laundry_room', 0.004703472475878402),\n",
       " ('with_no_pets', 0.004561269390350513),\n",
       " ('with_lounge', 0.0040840237630196926),\n",
       " ('with_highrise', 0.003959558416825391),\n",
       " ('with_garden', 0.0037768882517074517),\n",
       " ('with_gym/fitness', 0.0036424338271628417),\n",
       " ('with_subway', 0.003481623279625112),\n",
       " ('with_valet', 0.003316375971137592)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show the importance of the features\n",
    "xgbImportance(models[0],'gain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('listing_id', 0.06107592215757645),\n",
       " ('price', 0.05881172795276719),\n",
       " ('price_per_room', 0.0558596772806741),\n",
       " ('latitude', 0.05044280760081396),\n",
       " ('street_address', 0.04981227250580379),\n",
       " ('longitude', 0.04602906193574274),\n",
       " ('building_id', 0.04233183342409217),\n",
       " ('manager_id_nrank', 0.04164397695680835),\n",
       " ('num_description_words', 0.04161531627067152),\n",
       " ('m30perf', 0.038835229715399384),\n",
       " ('manager_id', 0.03860594422630478),\n",
       " ('price_per_bed', 0.03619844659081138),\n",
       " ('display_address', 0.03241523602075034),\n",
       " ('street_name', 0.0314980940643719),\n",
       " ('mlon', 0.02946318534865725),\n",
       " ('m14perf', 0.02934854260410994),\n",
       " ('mlat', 0.02914791780115216),\n",
       " ('m_m_distance', 0.02854604339227881),\n",
       " ('m3perf', 0.02811613310022642),\n",
       " ('m7perf', 0.027399615946805768),\n",
       " ('created_day', 0.024361583216302198),\n",
       " ('num_photos', 0.021896764208535154),\n",
       " ('created_hour', 0.021868103522398326),\n",
       " ('num_features', 0.017769625404832193),\n",
       " ('cluster_id_30', 0.01719641168209567),\n",
       " ('cluster_id_10', 0.008225616921269096),\n",
       " ('with_no_fee', 0.007394457023301138),\n",
       " ('bedrooms', 0.006849903986701442),\n",
       " ('bathrooms', 0.006706600556017311),\n",
       " ('bath_per_bed', 0.005216244876902353),\n",
       " ('with_furnished', 0.0033819609641454816),\n",
       " ('with_laundry_in_unit', 0.0031526754750508725),\n",
       " ('with_laundry_in_building', 0.003038032730503568),\n",
       " ('with_hardwood_floors', 0.002808747241408959),\n",
       " ('with_pre_war', 0.0023215155770829154),\n",
       " ('with_cats_allowed', 0.0022928548909460895),\n",
       " ('with_dishwasher', 0.0021495514602619587),\n",
       " ('with_dogs_allowed', 0.0020349087157146544),\n",
       " ('created_month', 0.001977587343441002),\n",
       " ('with_swimming_pool', 0.0018629445988936975),\n",
       " ('with_doorman', 0.0018342839127568713),\n",
       " ('with_balcony', 0.0018342839127568713),\n",
       " ('with_reduced_fee', 0.0018342839127568713),\n",
       " ('with_exclusive', 0.0016623197959359146),\n",
       " ('with_elevator', 0.0016336591097990886),\n",
       " ('with_actual_apt._photos', 0.0016336591097990886),\n",
       " ('with_dining_room', 0.0015763377375254363),\n",
       " ('with_fitness_center', 0.001519016365251784),\n",
       " ('with_common_outdoor_space', 0.001490355679114958),\n",
       " ('with_outdoor_space', 0.0014043736207044796),\n",
       " ('with_garden/patio', 0.0013183915622940012),\n",
       " ('with_terrace', 0.0013183915622940012),\n",
       " ('with_loft', 0.0012037488177466969),\n",
       " ('with_private_outdoor_space', 0.0012037488177466969),\n",
       " ('with_high_speed_internet', 0.0011464274454730447),\n",
       " ('with_simplex', 0.0010604453870625664),\n",
       " ('with_wheelchair_access', 0.0010604453870625664),\n",
       " ('with_roof_deck', 0.0010317847009257402),\n",
       " ('with_multi_level', 0.001003124014788914),\n",
       " ('with_parking_space', 0.0008884812702416096),\n",
       " ('with_storage', 0.0006878564672838268),\n",
       " ('with_new_construction', 0.0006878564672838268),\n",
       " ('with_fireplace', 0.0006018744088733484),\n",
       " ('with_renovated', 0.0005445530365996962),\n",
       " ('with_short_term_allowed', 0.00048723166432604396),\n",
       " ('with_on_site_laundry', 0.00048723166432604396),\n",
       " ('with_high_ceiling', 0.00048723166432604396),\n",
       " ('with_outdoor_areas', 0.0004585709781892178),\n",
       " ('with_publicoutdoor', 0.00042991029205239175),\n",
       " ('with_garage', 0.00042991029205239175),\n",
       " ('with_hardwood', 0.00042991029205239175),\n",
       " ('with_view', 0.0004012496059155656),\n",
       " ('with_live_in_super', 0.0003439282336419134),\n",
       " ('with_concierge', 0.0003439282336419134),\n",
       " ('with_parking', 0.0003439282336419134),\n",
       " ('with_dryer_in_unit', 0.00031526754750508726),\n",
       " ('with_prewar', 0.00031526754750508726),\n",
       " ('with_on_site_garage', 0.00031526754750508726),\n",
       " ('with_granite_kitchen', 0.00031526754750508726),\n",
       " ('with_pets_on_approval', 0.00025794617523143505),\n",
       " ('with_eat_in_kitchen', 0.00025794617523143505),\n",
       " ('with_green_building', 0.00025794617523143505),\n",
       " ('with_duplex', 0.00025794617523143505),\n",
       " ('with_light', 0.0002292854890946089),\n",
       " ('with_high_ceilings', 0.0002292854890946089),\n",
       " ('with_walk_in_closet(s)', 0.0002006248029577828),\n",
       " ('with_newly_renovated', 0.0002006248029577828),\n",
       " ('with_luxury_building', 0.0002006248029577828),\n",
       " ('with_central_a/c', 0.0001719641168209567),\n",
       " ('with_laundry_room', 0.0001719641168209567),\n",
       " ('with_common_parking/garage', 0.0001719641168209567),\n",
       " ('with_washer_in_unit', 0.0001719641168209567),\n",
       " ('with_pool', 0.0001719641168209567),\n",
       " ('with_washer/dryer', 0.0001433034306841306),\n",
       " ('with_marble_bath', 0.00011464274454730446),\n",
       " ('with_no_pets', 0.00011464274454730446),\n",
       " ('with_private_balcony', 8.598205841047835e-05),\n",
       " ('with_stainless_steel_appliances', 8.598205841047835e-05),\n",
       " ('with_laundry', 8.598205841047835e-05),\n",
       " ('with_bike_room', 8.598205841047835e-05),\n",
       " ('with_live_in_superintendent', 8.598205841047835e-05),\n",
       " ('with_highrise', 8.598205841047835e-05),\n",
       " ('with_exposed_brick', 5.732137227365223e-05),\n",
       " ('with_roofdeck', 5.732137227365223e-05),\n",
       " ('with_valet', 5.732137227365223e-05),\n",
       " ('with_lowrise', 5.732137227365223e-05),\n",
       " ('with_garden', 2.8660686136826114e-05),\n",
       " ('with_gym/fitness', 2.8660686136826114e-05),\n",
       " ('with_common_roof_deck', 2.8660686136826114e-05),\n",
       " ('with_subway', 2.8660686136826114e-05),\n",
       " ('with_lounge', 2.8660686136826114e-05)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showFscore(model,normalize = True)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
