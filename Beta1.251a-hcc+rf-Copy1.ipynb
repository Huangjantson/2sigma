{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn import  preprocessing, ensemble\n",
    "from sklearn.metrics import log_loss,accuracy_score\n",
    "from sklearn.cross_validation import KFold,StratifiedKFold\n",
    "import re\n",
    "import string\n",
    "from collections import defaultdict, Counter\n",
    "from itertools import product\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#try xgboost\n",
    "#fucntion from SRK\n",
    "def runXGB(train_X, train_y, test_X, test_y=None, feature_names=None, \\\n",
    "     seed_val=0, early_stop = 20,num_rounds=10000, eta = 0.1, max_depth = 6):\n",
    "    param = {}\n",
    "    param['objective'] = 'multi:softprob'\n",
    "    param['eta'] = eta\n",
    "    param['max_depth'] = max_depth\n",
    "    param['silent'] = 1\n",
    "    param['num_class'] = 3\n",
    "    param['eval_metric'] = \"mlogloss\"\n",
    "    param['min_child_weight'] = 1\n",
    "    param['subsample'] = 0.5\n",
    "    param['colsample_bytree'] = 0.5\n",
    "    param['seed'] = seed_val\n",
    "    num_rounds = num_rounds\n",
    "\n",
    "    plst = list(param.items())\n",
    "    xgtrain = xgb.DMatrix(train_X, label=train_y,feature_names=feature_names)\n",
    "\n",
    "    if test_y is not None:\n",
    "        xgtest = xgb.DMatrix(test_X, label=test_y,feature_names=feature_names)\n",
    "        watchlist = [ (xgtrain,'train'), (xgtest, 'test') ]\n",
    "        model = xgb.train(plst, xgtrain, num_rounds, watchlist,\\\n",
    "        early_stopping_rounds=early_stop)\n",
    "    else:\n",
    "        xgtest = xgb.DMatrix(test_X,feature_names=feature_names)\n",
    "        model = xgb.train(plst, xgtrain, num_rounds)\n",
    "\n",
    "    pred_test_y = model.predict(xgtest)\n",
    "    return pred_test_y, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#feature processing functions\n",
    "#define punctutaion filter\n",
    "def removePunctuation(x):\n",
    "    #filter the head or tail blanks\n",
    "    x = re.sub(r'^\\s+',r' ',x)\n",
    "    x = re.sub(r'\\s+$',r' ',x)\n",
    "    \n",
    "    # Lowercasing all words\n",
    "    x = x.lower()\n",
    "    # Removing non ASCII chars, warning if you are dealing with other languages!!!!!!!!!!!!!!!\n",
    "    x = re.sub(r'[^\\x00-\\x7f]',r' ',x)\n",
    "    #change all the blank to space\n",
    "    x = re.sub(r'\\s',r' ',x)\n",
    "    # Removing (replacing with empty spaces actually) all the punctuations\n",
    "    removing = string.punctuation#.replace('-','')# except '-'\n",
    "    removed = re.sub(\"[\"+removing+\"]\", \"\", x)\n",
    "    #removing the line-changing\n",
    "    #removed = re.sub('\\\\n',\" \",removed)    \n",
    "    return removed\n",
    "\n",
    "#feature processing functions\n",
    "def proecessStreet(address):\n",
    "    #remove the building number\n",
    "    pattern = re.compile('^[\\d-]*[\\s]+')\n",
    "    street = removePunctuation(pattern.sub('',address))\n",
    "    \n",
    "    #sub the st to street\n",
    "    pattern = re.compile('( st)$')\n",
    "    street = pattern.sub(' street',street)\n",
    "    \n",
    "    #sub the ave to avenue\n",
    "    pattern = re.compile('( ave)$')\n",
    "    street = pattern.sub(' avenue',street)\n",
    "    \n",
    "    pattern = re.compile('(\\d+)((th)|(st)|(rd)|(nd))')\n",
    "    street = pattern.sub('\\g<1>',street)\n",
    "    \n",
    "    #deal with the w 14 street => west 14 street\n",
    "    pattern = re.compile('(w)(\\s+)(\\d+)')    \n",
    "    street = pattern.sub('west \\g<3>',street)\n",
    "    \n",
    "    #deal with the e....\n",
    "    pattern = re.compile('(e)(\\s+)(\\d+)')    \n",
    "    street = pattern.sub('east \\g<3>',street)\n",
    "    \n",
    "    return street\n",
    "    \n",
    "#from \"this is a lit\"s python version by rakhlin\n",
    "def singleValueConvert(df1,df2,column,minimum_size=5):\n",
    "    ps = df1[column].append(df2[column])\n",
    "    grouped = ps.groupby(ps).size().to_frame().rename(columns={0: \"size\"})\n",
    "    df1.loc[df1.join(grouped, on=column, how=\"left\")[\"size\"] <= minimum_size, column] = -1\n",
    "    df2.loc[df2.join(grouped, on=column, how=\"left\")[\"size\"] <= minimum_size, column] = -1\n",
    "    return df1, df2\n",
    "\n",
    "def manager_skill_eval(train_df,test_df,unrank_threshold = 10):\n",
    "\n",
    "    target_num_map = {'High':2, 'Medium':1, 'Low':0}\n",
    "    temp=pd.concat([train_df.manager_id,pd.get_dummies(train_df.interest_level)], axis = 1).groupby('manager_id').mean()\n",
    "     \n",
    "    temp.columns = ['ManHigh','ManLow', 'ManMedium']\n",
    "    \n",
    "    print temp.columns\n",
    "    temp['count'] = train_df.groupby('manager_id').count().iloc[:,1]\n",
    "    \n",
    "    temp['manager_skill'] = temp['ManHigh']*2 + temp['ManMedium']\n",
    "    \n",
    "    #ixes of the managers with to few sample\n",
    "    unranked_managers_ixes = temp['count']<unrank_threshold\n",
    "    ranked_managers_ixes = ~unranked_managers_ixes\n",
    "    \n",
    "    #test for using rank or unrank part for the filling values\n",
    "    mean_values = temp.loc[unranked_managers_ixes, ['ManHigh','ManLow', 'ManMedium','manager_skill']].mean()\n",
    "    mean_values_total = temp.loc[:, ['ManHigh','ManLow', 'ManMedium','manager_skill']].mean()\n",
    "    \n",
    "    #reset their values to their average\n",
    "    temp.loc[unranked_managers_ixes,['ManHigh','ManLow', 'ManMedium','manager_skill']] = mean_values.values\n",
    "    \n",
    "    #assign the features for the train set\n",
    "    new_train_df = train_df.merge(temp.reset_index(),how='left', left_on='manager_id', right_on='manager_id')\n",
    "    \n",
    "    #assign the features for the test/val set\n",
    "    new_test_df = test_df.merge(temp.reset_index(),how='left', left_on='manager_id', right_on='manager_id')\n",
    "    new_manager_ixes = new_test_df['ManHigh'].isnull()\n",
    "    new_test_df.loc[new_manager_ixes,['ManHigh','ManLow', 'ManMedium','manager_skill']] = mean_values_total.values           \n",
    "    \n",
    "    return new_train_df,new_test_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#functions for features\n",
    "def featureList(train_df,test_df,limit = 0.001):\n",
    "    #acquiring the feature lists\n",
    "    features_in_train = train_df[\"features\"].apply(pd.Series).unstack().reset_index(drop = True).dropna().value_counts()\n",
    "    features_in_test = test_df[\"features\"].apply(pd.Series).unstack().reset_index(drop = True).dropna().value_counts()\n",
    "    \n",
    "    filtered_features_in_train = features_in_train[features_in_train > limit*len(train_df)]\n",
    "    filtered_features_in_test = features_in_test[features_in_test > limit*len(test_df)]\n",
    "    accept_list = set(filtered_features_in_train.index).union(set(filtered_features_in_test.index))\n",
    "    return accept_list\n",
    "\n",
    "def featureMapping(train_df,test_df,feature_list):\n",
    "    for feature in feature_list:\n",
    "        #add the feature column for both\n",
    "        #if feature in the row, then set the value for (row,feature) to 1\n",
    "        train_df['with_'+feature]=train_df['features'].apply(lambda x : 1 if feature in x else 0)\n",
    "        test_df['with_'+feature]=test_df['features'].apply(lambda x : 1 if feature in x else 0)\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def hcc_encode(train_df, test_df, variable, target, prior_prob, k, f=1, g=1, r_k=None, update_df=None):\n",
    "    \"\"\"\n",
    "    See \"A Preprocessing Scheme for High-Cardinality Categorical Attributes in\n",
    "    Classification and Prediction Problems\" by Daniele Micci-Barreca\n",
    "    \"\"\"\n",
    "    hcc_name = \"_\".join([\"hcc\", variable, target])\n",
    "\n",
    "    grouped = train_df.groupby(variable)[target].agg({\"size\": \"size\", \"mean\": \"mean\"})\n",
    "    grouped[\"lambda\"] = 1 / (g + np.exp((k - grouped[\"size\"]) / f))\n",
    "    grouped[hcc_name] = grouped[\"lambda\"] * grouped[\"mean\"] + (1 - grouped[\"lambda\"]) * prior_prob\n",
    "\n",
    "    df = test_df[[variable]].join(grouped, on=variable, how=\"left\")[hcc_name].fillna(prior_prob)\n",
    "    if r_k: df *= np.random.uniform(1 - r_k, 1 + r_k, len(test_df))     # Add uniform noise. Not mentioned in original paper\n",
    "\n",
    "    if update_df is None: update_df = test_df\n",
    "    if hcc_name not in update_df.columns: update_df[hcc_name] = np.nan\n",
    "    update_df.update(df)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49352, 15)\n",
      "(74659, 14)\n"
     ]
    }
   ],
   "source": [
    "#lodaing data\n",
    "data_path = \"../../kaggleData/2sigma/\"\n",
    "train_file = data_path + \"train.json\"\n",
    "test_file = data_path + \"test.json\"\n",
    "train_df = pd.read_json(train_file)\n",
    "test_df = pd.read_json(test_file)\n",
    "print(train_df.shape)\n",
    "print(test_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#basic numerical features\n",
    "features_to_use  = [\"bathrooms\", \"bedrooms\", \"latitude\", \"longitude\", \"price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#some new numerical features related to the price\n",
    "train_df[\"price_per_bath\"] =  (train_df[\"price\"]*1.0/train_df[\"bathrooms\"]).replace(np.Inf,-1)\n",
    "train_df[\"price_per_bed\"] = (train_df[\"price\"]*1.0/train_df[\"bedrooms\"]).replace(np.Inf,-1)\n",
    "train_df[\"bath_per_bed\"] = (train_df[\"bathrooms\"]*1.0/train_df[\"bedrooms\"]).replace(np.Inf,-1)\n",
    "train_df[\"price_per_room\"] = (train_df[\"price\"]*1.0/(train_df[\"bedrooms\"]+train_df[\"bathrooms\"])).replace(np.Inf,-1)\n",
    "\n",
    "test_df[\"price_per_bath\"] =  (test_df[\"price\"]*1.0/test_df[\"bathrooms\"]).replace(np.Inf,-1)\n",
    "test_df[\"price_per_bed\"] = (test_df[\"price\"]*1.0/test_df[\"bedrooms\"]).replace(np.Inf,-1)\n",
    "test_df[\"bath_per_bed\"] = (test_df[\"bathrooms\"]*1.0/test_df[\"bedrooms\"]).replace(np.Inf,-1)\n",
    "test_df[\"price_per_room\"] = (test_df[\"price\"]*1.0/(test_df[\"bedrooms\"]+test_df[\"bathrooms\"])).replace(np.Inf,-1)\n",
    "\n",
    "features_to_use.extend([\"price_per_bed\",\"bath_per_bed\",\"price_per_room\"])\n",
    "#features_to_use.append('price_per_bed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#some transfromed features\n",
    "# count of photos #\n",
    "train_df[\"num_photos\"] = train_df[\"photos\"].apply(len)\n",
    "test_df[\"num_photos\"] = test_df[\"photos\"].apply(len)\n",
    "\n",
    "# count of \"features\" #\n",
    "train_df[\"num_features\"] = train_df[\"features\"].apply(len)\n",
    "test_df[\"num_features\"] = test_df[\"features\"].apply(len)\n",
    "\n",
    "# count of words present in description column #\n",
    "train_df[\"num_description_words\"] = train_df[\"description\"].apply(lambda x: len(x.split(\" \")))\n",
    "test_df[\"num_description_words\"] = test_df[\"description\"].apply(lambda x: len(x.split(\" \")))\n",
    "\n",
    "# convert the created column to datetime object so as to extract more features \n",
    "train_df[\"created\"] = pd.to_datetime(train_df[\"created\"])\n",
    "test_df[\"created\"] = pd.to_datetime(test_df[\"created\"])\n",
    "\n",
    "# Let us extract some features like year, month, day, hour from date columns #\n",
    "train_df[\"created_year\"] = train_df[\"created\"].dt.year\n",
    "test_df[\"created_year\"] = test_df[\"created\"].dt.year\n",
    "train_df[\"created_month\"] = train_df[\"created\"].dt.month\n",
    "test_df[\"created_month\"] = test_df[\"created\"].dt.month\n",
    "train_df[\"created_day\"] = train_df[\"created\"].dt.day\n",
    "test_df[\"created_day\"] = test_df[\"created\"].dt.day\n",
    "train_df[\"created_hour\"] = train_df[\"created\"].dt.hour\n",
    "test_df[\"created_hour\"] = test_df[\"created\"].dt.hour\n",
    "\n",
    "# adding all these new features to use list # \"listing_id\",\n",
    "features_to_use.extend([\"num_photos\", \"num_features\", \"num_description_words\",\"created_year\",\"listing_id\", \"created_month\", \"created_day\", \"created_hour\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features_to_use=list(set(features_to_use))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "new categorical data append and converting label dummies for future use\n",
    "\"\"\"\n",
    "#new feature for the street_address, use them instead of the original one\n",
    "train_df[\"street_name\"] = train_df[\"street_address\"].apply(proecessStreet)\n",
    "test_df[\"street_name\"] = test_df[\"street_address\"].apply(proecessStreet)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#dealing with features\n",
    "\n",
    "#preprocessing for features\n",
    "train_df[\"features\"] = train_df[\"features\"].apply(lambda x:[\"_\".join(i.split(\" \")).lower().strip().replace('-','_') \\\n",
    "                                                            for i in x])\n",
    "test_df[\"features\"] = test_df[\"features\"].apply(lambda x:[\"_\".join(i.split(\" \")).lower().strip().replace('-','_')\\\n",
    "                                                          for i in x])\n",
    "#create the accept list\n",
    "accept_list = list(featureList(train_df,test_df,limit = 0.001))\n",
    "\n",
    "#map the feature to dummy slots\n",
    "featureMapping(train_df,test_df,accept_list)\n",
    "features_to_use.extend(map(lambda x : 'with_'+x,accept_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#hcc encoding  using cross validation type\n",
    "KF=KFold(len(train_df),5,shuffle=True,random_state = 2017)\n",
    "\n",
    "#i = 0\n",
    "for f , s in KF:\n",
    "    #print i\n",
    "    \n",
    "    hcc_scoring(train_df.iloc[f],train_df.iloc[s],'manager_id','high',update_df =train_df)\n",
    "    hcc_scoring(train_df.iloc[f],train_df.iloc[s],'manager_id','medium',update_df =train_df)\n",
    "    hcc_scoring(train_df.iloc[f],train_df.iloc[s],'building_id','high',update_df =train_df)\n",
    "    hcc_scoring(train_df.iloc[f],train_df.iloc[s],'building_id','medium',update_df =train_df)\n",
    "\n",
    "#get hcc for the tesing\n",
    "hcc_scoring(train_df,test_df,'manager_id','high')\n",
    "hcc_scoring(train_df,test_df,'manager_id','medium')\n",
    "hcc_scoring(train_df,test_df,'building_id','high')\n",
    "hcc_scoring(train_df,test_df,'building_id','medium')\n",
    "\n",
    "\n",
    "features_to_use.append('hcc_building_id_high')\n",
    "features_to_use.append('hcc_building_id_medium')\n",
    "features_to_use.append('hcc_manager_id_high')\n",
    "features_to_use.append('hcc_manager_id_medium')\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#prepare for training\n",
    "target_num_map = {'high':0, 'medium':1, 'low':2}\n",
    "\n",
    "train_y = np.array(train_df['interest_level'].apply(lambda x: target_num_map[x]))\n",
    "\n",
    "KF=KFold(len(train_df),3,shuffle=True,random_state = 42)\n",
    "\n",
    "train_df = train_df.fillna(-1)\n",
    "test_df = test_df.fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_to_use.append('manager_skill')\n",
    "categorical = [\"display_address\", \"manager_id\", \"building_id\", \"street_address\",\"street_name\"]\n",
    "\n",
    "features_to_use.extend(categorical)\n",
    "\n",
    "features_to_use.append('hcc_building_id_pred_1')\n",
    "features_to_use.append('hcc_building_id_pred_2')\n",
    "features_to_use.append('hcc_manager_id_pred_1')\n",
    "features_to_use.append('hcc_manager_id_pred_2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'ManHigh', u'ManLow', u'ManMedium'], dtype='object')\n",
      "[0]\ttrain-mlogloss:1.03653\ttest-mlogloss:1.03774\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 200 rounds.\n",
      "[1]\ttrain-mlogloss:0.985252\ttest-mlogloss:0.987255\n",
      "[2]\ttrain-mlogloss:0.940461\ttest-mlogloss:0.943382\n",
      "[3]\ttrain-mlogloss:0.901768\ttest-mlogloss:0.905743\n",
      "[4]\ttrain-mlogloss:0.86939\ttest-mlogloss:0.873816\n",
      "[5]\ttrain-mlogloss:0.84008\ttest-mlogloss:0.844909\n",
      "[6]\ttrain-mlogloss:0.814402\ttest-mlogloss:0.820033\n",
      "[7]\ttrain-mlogloss:0.79055\ttest-mlogloss:0.79705\n",
      "[8]\ttrain-mlogloss:0.769737\ttest-mlogloss:0.77714\n",
      "[9]\ttrain-mlogloss:0.752196\ttest-mlogloss:0.760196\n",
      "[10]\ttrain-mlogloss:0.736181\ttest-mlogloss:0.745108\n",
      "[11]\ttrain-mlogloss:0.721592\ttest-mlogloss:0.731095\n",
      "[12]\ttrain-mlogloss:0.709697\ttest-mlogloss:0.7196\n",
      "[13]\ttrain-mlogloss:0.697879\ttest-mlogloss:0.708544\n",
      "[14]\ttrain-mlogloss:0.68694\ttest-mlogloss:0.698079\n",
      "[15]\ttrain-mlogloss:0.677909\ttest-mlogloss:0.689477\n",
      "[16]\ttrain-mlogloss:0.669199\ttest-mlogloss:0.681224\n",
      "[17]\ttrain-mlogloss:0.66115\ttest-mlogloss:0.673486\n",
      "[18]\ttrain-mlogloss:0.654279\ttest-mlogloss:0.667167\n",
      "[19]\ttrain-mlogloss:0.648134\ttest-mlogloss:0.66125\n",
      "[20]\ttrain-mlogloss:0.642216\ttest-mlogloss:0.655657\n",
      "[21]\ttrain-mlogloss:0.636971\ttest-mlogloss:0.650892\n",
      "[22]\ttrain-mlogloss:0.632424\ttest-mlogloss:0.646824\n",
      "[23]\ttrain-mlogloss:0.628043\ttest-mlogloss:0.642763\n",
      "[24]\ttrain-mlogloss:0.624243\ttest-mlogloss:0.639463\n",
      "[25]\ttrain-mlogloss:0.620471\ttest-mlogloss:0.635991\n",
      "[26]\ttrain-mlogloss:0.617145\ttest-mlogloss:0.633171\n",
      "[27]\ttrain-mlogloss:0.613474\ttest-mlogloss:0.629663\n",
      "[28]\ttrain-mlogloss:0.610362\ttest-mlogloss:0.626773\n",
      "[29]\ttrain-mlogloss:0.606966\ttest-mlogloss:0.623804\n",
      "[30]\ttrain-mlogloss:0.604486\ttest-mlogloss:0.621754\n",
      "[31]\ttrain-mlogloss:0.601867\ttest-mlogloss:0.619403\n",
      "[32]\ttrain-mlogloss:0.59901\ttest-mlogloss:0.616891\n",
      "[33]\ttrain-mlogloss:0.596756\ttest-mlogloss:0.614942\n",
      "[34]\ttrain-mlogloss:0.594796\ttest-mlogloss:0.61306\n",
      "[35]\ttrain-mlogloss:0.592828\ttest-mlogloss:0.611408\n",
      "[36]\ttrain-mlogloss:0.590291\ttest-mlogloss:0.609281\n",
      "[37]\ttrain-mlogloss:0.588578\ttest-mlogloss:0.607864\n",
      "[38]\ttrain-mlogloss:0.586892\ttest-mlogloss:0.606559\n",
      "[39]\ttrain-mlogloss:0.584865\ttest-mlogloss:0.604985\n",
      "[40]\ttrain-mlogloss:0.583017\ttest-mlogloss:0.603335\n",
      "[41]\ttrain-mlogloss:0.581486\ttest-mlogloss:0.601893\n",
      "[42]\ttrain-mlogloss:0.579977\ttest-mlogloss:0.600792\n",
      "[43]\ttrain-mlogloss:0.578455\ttest-mlogloss:0.599397\n",
      "[44]\ttrain-mlogloss:0.577062\ttest-mlogloss:0.598322\n",
      "[45]\ttrain-mlogloss:0.575717\ttest-mlogloss:0.59726\n",
      "[46]\ttrain-mlogloss:0.57452\ttest-mlogloss:0.596546\n",
      "[47]\ttrain-mlogloss:0.573386\ttest-mlogloss:0.595558\n",
      "[48]\ttrain-mlogloss:0.571989\ttest-mlogloss:0.594531\n",
      "[49]\ttrain-mlogloss:0.570985\ttest-mlogloss:0.593695\n",
      "[50]\ttrain-mlogloss:0.569765\ttest-mlogloss:0.592798\n",
      "[51]\ttrain-mlogloss:0.568635\ttest-mlogloss:0.592062\n",
      "[52]\ttrain-mlogloss:0.567628\ttest-mlogloss:0.591238\n",
      "[53]\ttrain-mlogloss:0.566198\ttest-mlogloss:0.590016\n",
      "[54]\ttrain-mlogloss:0.564947\ttest-mlogloss:0.589147\n",
      "[55]\ttrain-mlogloss:0.563933\ttest-mlogloss:0.588416\n",
      "[56]\ttrain-mlogloss:0.562934\ttest-mlogloss:0.58783\n",
      "[57]\ttrain-mlogloss:0.562011\ttest-mlogloss:0.587236\n",
      "[58]\ttrain-mlogloss:0.560983\ttest-mlogloss:0.586563\n",
      "[59]\ttrain-mlogloss:0.560122\ttest-mlogloss:0.586077\n",
      "[60]\ttrain-mlogloss:0.55904\ttest-mlogloss:0.585312\n",
      "[61]\ttrain-mlogloss:0.557957\ttest-mlogloss:0.584534\n",
      "[62]\ttrain-mlogloss:0.557044\ttest-mlogloss:0.584047\n",
      "[63]\ttrain-mlogloss:0.55587\ttest-mlogloss:0.5832\n",
      "[64]\ttrain-mlogloss:0.555063\ttest-mlogloss:0.582612\n",
      "[65]\ttrain-mlogloss:0.55435\ttest-mlogloss:0.582111\n",
      "[66]\ttrain-mlogloss:0.553429\ttest-mlogloss:0.581453\n",
      "[67]\ttrain-mlogloss:0.55253\ttest-mlogloss:0.581031\n",
      "[68]\ttrain-mlogloss:0.551626\ttest-mlogloss:0.580374\n",
      "[69]\ttrain-mlogloss:0.550721\ttest-mlogloss:0.579896\n",
      "[70]\ttrain-mlogloss:0.550074\ttest-mlogloss:0.579563\n",
      "[71]\ttrain-mlogloss:0.549251\ttest-mlogloss:0.579204\n",
      "[72]\ttrain-mlogloss:0.548519\ttest-mlogloss:0.578678\n",
      "[73]\ttrain-mlogloss:0.547632\ttest-mlogloss:0.578149\n",
      "[74]\ttrain-mlogloss:0.547057\ttest-mlogloss:0.577651\n",
      "[75]\ttrain-mlogloss:0.546349\ttest-mlogloss:0.57724\n",
      "[76]\ttrain-mlogloss:0.545683\ttest-mlogloss:0.57681\n",
      "[77]\ttrain-mlogloss:0.544914\ttest-mlogloss:0.576286\n",
      "[78]\ttrain-mlogloss:0.544082\ttest-mlogloss:0.575688\n",
      "[79]\ttrain-mlogloss:0.543428\ttest-mlogloss:0.575259\n",
      "[80]\ttrain-mlogloss:0.542629\ttest-mlogloss:0.574943\n",
      "[81]\ttrain-mlogloss:0.541958\ttest-mlogloss:0.574535\n",
      "[82]\ttrain-mlogloss:0.541129\ttest-mlogloss:0.573921\n",
      "[83]\ttrain-mlogloss:0.540392\ttest-mlogloss:0.573523\n",
      "[84]\ttrain-mlogloss:0.539762\ttest-mlogloss:0.573217\n",
      "[85]\ttrain-mlogloss:0.539195\ttest-mlogloss:0.572974\n",
      "[86]\ttrain-mlogloss:0.538271\ttest-mlogloss:0.572332\n",
      "[87]\ttrain-mlogloss:0.537591\ttest-mlogloss:0.572106\n",
      "[88]\ttrain-mlogloss:0.53694\ttest-mlogloss:0.571697\n",
      "[89]\ttrain-mlogloss:0.536111\ttest-mlogloss:0.571303\n",
      "[90]\ttrain-mlogloss:0.535505\ttest-mlogloss:0.571049\n",
      "[91]\ttrain-mlogloss:0.534947\ttest-mlogloss:0.570696\n",
      "[92]\ttrain-mlogloss:0.53437\ttest-mlogloss:0.570348\n",
      "[93]\ttrain-mlogloss:0.533765\ttest-mlogloss:0.570009\n",
      "[94]\ttrain-mlogloss:0.533275\ttest-mlogloss:0.569827\n",
      "[95]\ttrain-mlogloss:0.532802\ttest-mlogloss:0.569597\n",
      "[96]\ttrain-mlogloss:0.532256\ttest-mlogloss:0.569344\n",
      "[97]\ttrain-mlogloss:0.53173\ttest-mlogloss:0.569059\n",
      "[98]\ttrain-mlogloss:0.531025\ttest-mlogloss:0.568578\n",
      "[99]\ttrain-mlogloss:0.530412\ttest-mlogloss:0.568241\n",
      "[100]\ttrain-mlogloss:0.529666\ttest-mlogloss:0.568001\n",
      "[101]\ttrain-mlogloss:0.529151\ttest-mlogloss:0.567771\n",
      "[102]\ttrain-mlogloss:0.528639\ttest-mlogloss:0.567626\n",
      "[103]\ttrain-mlogloss:0.527997\ttest-mlogloss:0.567354\n",
      "[104]\ttrain-mlogloss:0.527318\ttest-mlogloss:0.567015\n",
      "[105]\ttrain-mlogloss:0.526724\ttest-mlogloss:0.566664\n",
      "[106]\ttrain-mlogloss:0.526308\ttest-mlogloss:0.566427\n",
      "[107]\ttrain-mlogloss:0.525613\ttest-mlogloss:0.566011\n",
      "[108]\ttrain-mlogloss:0.525047\ttest-mlogloss:0.565702\n",
      "[109]\ttrain-mlogloss:0.524627\ttest-mlogloss:0.565497\n",
      "[110]\ttrain-mlogloss:0.524217\ttest-mlogloss:0.565318\n",
      "[111]\ttrain-mlogloss:0.523751\ttest-mlogloss:0.565105\n",
      "[112]\ttrain-mlogloss:0.523213\ttest-mlogloss:0.564847\n",
      "[113]\ttrain-mlogloss:0.522693\ttest-mlogloss:0.56455\n",
      "[114]\ttrain-mlogloss:0.522365\ttest-mlogloss:0.564336\n",
      "[115]\ttrain-mlogloss:0.521872\ttest-mlogloss:0.564117\n",
      "[116]\ttrain-mlogloss:0.521479\ttest-mlogloss:0.563794\n",
      "[117]\ttrain-mlogloss:0.520998\ttest-mlogloss:0.56362\n",
      "[118]\ttrain-mlogloss:0.520516\ttest-mlogloss:0.56343\n",
      "[119]\ttrain-mlogloss:0.519988\ttest-mlogloss:0.563329\n",
      "[120]\ttrain-mlogloss:0.519454\ttest-mlogloss:0.563209\n",
      "[121]\ttrain-mlogloss:0.51882\ttest-mlogloss:0.562886\n",
      "[122]\ttrain-mlogloss:0.518204\ttest-mlogloss:0.562552\n",
      "[123]\ttrain-mlogloss:0.517579\ttest-mlogloss:0.562295\n",
      "[124]\ttrain-mlogloss:0.517184\ttest-mlogloss:0.562076\n",
      "[125]\ttrain-mlogloss:0.516622\ttest-mlogloss:0.561758\n",
      "[126]\ttrain-mlogloss:0.516175\ttest-mlogloss:0.561598\n",
      "[127]\ttrain-mlogloss:0.515668\ttest-mlogloss:0.561407\n",
      "[128]\ttrain-mlogloss:0.515136\ttest-mlogloss:0.561091\n",
      "[129]\ttrain-mlogloss:0.514699\ttest-mlogloss:0.560942\n",
      "[130]\ttrain-mlogloss:0.514311\ttest-mlogloss:0.560722\n",
      "[131]\ttrain-mlogloss:0.513907\ttest-mlogloss:0.56053\n",
      "[132]\ttrain-mlogloss:0.513361\ttest-mlogloss:0.560369\n",
      "[133]\ttrain-mlogloss:0.512759\ttest-mlogloss:0.560087\n",
      "[134]\ttrain-mlogloss:0.512252\ttest-mlogloss:0.559868\n",
      "[135]\ttrain-mlogloss:0.511698\ttest-mlogloss:0.559584\n",
      "[136]\ttrain-mlogloss:0.511433\ttest-mlogloss:0.559475\n",
      "[137]\ttrain-mlogloss:0.51087\ttest-mlogloss:0.559258\n",
      "[138]\ttrain-mlogloss:0.510428\ttest-mlogloss:0.55913\n",
      "[139]\ttrain-mlogloss:0.509982\ttest-mlogloss:0.558948\n",
      "[140]\ttrain-mlogloss:0.509556\ttest-mlogloss:0.558795\n",
      "[141]\ttrain-mlogloss:0.509023\ttest-mlogloss:0.558509\n",
      "[142]\ttrain-mlogloss:0.508619\ttest-mlogloss:0.558358\n",
      "[143]\ttrain-mlogloss:0.508137\ttest-mlogloss:0.558203\n",
      "[144]\ttrain-mlogloss:0.507779\ttest-mlogloss:0.558056\n",
      "[145]\ttrain-mlogloss:0.507248\ttest-mlogloss:0.557877\n",
      "[146]\ttrain-mlogloss:0.506906\ttest-mlogloss:0.557781\n",
      "[147]\ttrain-mlogloss:0.506307\ttest-mlogloss:0.55753\n",
      "[148]\ttrain-mlogloss:0.505796\ttest-mlogloss:0.557199\n",
      "[149]\ttrain-mlogloss:0.505398\ttest-mlogloss:0.557027\n",
      "[150]\ttrain-mlogloss:0.504847\ttest-mlogloss:0.556751\n",
      "[151]\ttrain-mlogloss:0.504375\ttest-mlogloss:0.556518\n",
      "[152]\ttrain-mlogloss:0.504056\ttest-mlogloss:0.556286\n",
      "[153]\ttrain-mlogloss:0.503655\ttest-mlogloss:0.556145\n",
      "[154]\ttrain-mlogloss:0.503262\ttest-mlogloss:0.556062\n",
      "[155]\ttrain-mlogloss:0.502803\ttest-mlogloss:0.555913\n",
      "[156]\ttrain-mlogloss:0.502527\ttest-mlogloss:0.555808\n",
      "[157]\ttrain-mlogloss:0.502221\ttest-mlogloss:0.555626\n",
      "[158]\ttrain-mlogloss:0.501854\ttest-mlogloss:0.555506\n",
      "[159]\ttrain-mlogloss:0.501437\ttest-mlogloss:0.555463\n",
      "[160]\ttrain-mlogloss:0.501054\ttest-mlogloss:0.555349\n",
      "[161]\ttrain-mlogloss:0.500723\ttest-mlogloss:0.555253\n",
      "[162]\ttrain-mlogloss:0.500306\ttest-mlogloss:0.555078\n",
      "[163]\ttrain-mlogloss:0.499864\ttest-mlogloss:0.554937\n",
      "[164]\ttrain-mlogloss:0.499324\ttest-mlogloss:0.554873\n",
      "[165]\ttrain-mlogloss:0.498989\ttest-mlogloss:0.554821\n",
      "[166]\ttrain-mlogloss:0.498624\ttest-mlogloss:0.554752\n",
      "[167]\ttrain-mlogloss:0.498182\ttest-mlogloss:0.55462\n",
      "[168]\ttrain-mlogloss:0.497809\ttest-mlogloss:0.554472\n",
      "[169]\ttrain-mlogloss:0.497436\ttest-mlogloss:0.554347\n",
      "[170]\ttrain-mlogloss:0.497047\ttest-mlogloss:0.554282\n",
      "[171]\ttrain-mlogloss:0.496679\ttest-mlogloss:0.554146\n",
      "[172]\ttrain-mlogloss:0.496409\ttest-mlogloss:0.554069\n",
      "[173]\ttrain-mlogloss:0.496039\ttest-mlogloss:0.55398\n",
      "[174]\ttrain-mlogloss:0.495536\ttest-mlogloss:0.553843\n",
      "[175]\ttrain-mlogloss:0.495144\ttest-mlogloss:0.553823\n",
      "[176]\ttrain-mlogloss:0.494753\ttest-mlogloss:0.553717\n",
      "[177]\ttrain-mlogloss:0.494367\ttest-mlogloss:0.553713\n",
      "[178]\ttrain-mlogloss:0.493945\ttest-mlogloss:0.553589\n",
      "[179]\ttrain-mlogloss:0.493584\ttest-mlogloss:0.553513\n",
      "[180]\ttrain-mlogloss:0.493167\ttest-mlogloss:0.553453\n",
      "[181]\ttrain-mlogloss:0.492801\ttest-mlogloss:0.553361\n",
      "[182]\ttrain-mlogloss:0.492479\ttest-mlogloss:0.553198\n",
      "[183]\ttrain-mlogloss:0.49214\ttest-mlogloss:0.553058\n",
      "[184]\ttrain-mlogloss:0.491811\ttest-mlogloss:0.552797\n",
      "[185]\ttrain-mlogloss:0.491426\ttest-mlogloss:0.552743\n",
      "[186]\ttrain-mlogloss:0.490997\ttest-mlogloss:0.552545\n",
      "[187]\ttrain-mlogloss:0.490692\ttest-mlogloss:0.552472\n",
      "[188]\ttrain-mlogloss:0.490397\ttest-mlogloss:0.552394\n",
      "[189]\ttrain-mlogloss:0.490132\ttest-mlogloss:0.552371\n",
      "[190]\ttrain-mlogloss:0.48981\ttest-mlogloss:0.552373\n",
      "[191]\ttrain-mlogloss:0.48939\ttest-mlogloss:0.552202\n",
      "[192]\ttrain-mlogloss:0.488944\ttest-mlogloss:0.552187\n",
      "[193]\ttrain-mlogloss:0.488657\ttest-mlogloss:0.552109\n",
      "[194]\ttrain-mlogloss:0.488288\ttest-mlogloss:0.552061\n",
      "[195]\ttrain-mlogloss:0.487955\ttest-mlogloss:0.551942\n",
      "[196]\ttrain-mlogloss:0.487501\ttest-mlogloss:0.551725\n",
      "[197]\ttrain-mlogloss:0.487208\ttest-mlogloss:0.551689\n",
      "[198]\ttrain-mlogloss:0.486805\ttest-mlogloss:0.551584\n",
      "[199]\ttrain-mlogloss:0.4865\ttest-mlogloss:0.551488\n",
      "[200]\ttrain-mlogloss:0.486181\ttest-mlogloss:0.551503\n",
      "[201]\ttrain-mlogloss:0.485812\ttest-mlogloss:0.551453\n",
      "[202]\ttrain-mlogloss:0.485446\ttest-mlogloss:0.551278\n",
      "[203]\ttrain-mlogloss:0.485036\ttest-mlogloss:0.551184\n",
      "[204]\ttrain-mlogloss:0.484662\ttest-mlogloss:0.551044\n",
      "[205]\ttrain-mlogloss:0.4844\ttest-mlogloss:0.551082\n",
      "[206]\ttrain-mlogloss:0.484109\ttest-mlogloss:0.550976\n",
      "[207]\ttrain-mlogloss:0.483785\ttest-mlogloss:0.550938\n",
      "[208]\ttrain-mlogloss:0.483508\ttest-mlogloss:0.550945\n",
      "[209]\ttrain-mlogloss:0.483175\ttest-mlogloss:0.550801\n",
      "[210]\ttrain-mlogloss:0.482882\ttest-mlogloss:0.550743\n",
      "[211]\ttrain-mlogloss:0.482508\ttest-mlogloss:0.550508\n",
      "[212]\ttrain-mlogloss:0.482234\ttest-mlogloss:0.550503\n",
      "[213]\ttrain-mlogloss:0.482001\ttest-mlogloss:0.550354\n",
      "[214]\ttrain-mlogloss:0.481602\ttest-mlogloss:0.55025\n",
      "[215]\ttrain-mlogloss:0.481276\ttest-mlogloss:0.550268\n",
      "[216]\ttrain-mlogloss:0.480941\ttest-mlogloss:0.550194\n",
      "[217]\ttrain-mlogloss:0.480622\ttest-mlogloss:0.550146\n",
      "[218]\ttrain-mlogloss:0.480358\ttest-mlogloss:0.550098\n",
      "[219]\ttrain-mlogloss:0.480013\ttest-mlogloss:0.550067\n",
      "[220]\ttrain-mlogloss:0.479707\ttest-mlogloss:0.54995\n",
      "[221]\ttrain-mlogloss:0.47931\ttest-mlogloss:0.549745\n",
      "[222]\ttrain-mlogloss:0.478974\ttest-mlogloss:0.54964\n",
      "[223]\ttrain-mlogloss:0.478694\ttest-mlogloss:0.549623\n",
      "[224]\ttrain-mlogloss:0.478293\ttest-mlogloss:0.549552\n",
      "[225]\ttrain-mlogloss:0.478006\ttest-mlogloss:0.549557\n",
      "[226]\ttrain-mlogloss:0.477697\ttest-mlogloss:0.549506\n",
      "[227]\ttrain-mlogloss:0.477364\ttest-mlogloss:0.549384\n",
      "[228]\ttrain-mlogloss:0.477008\ttest-mlogloss:0.54929\n",
      "[229]\ttrain-mlogloss:0.476596\ttest-mlogloss:0.549138\n",
      "[230]\ttrain-mlogloss:0.476185\ttest-mlogloss:0.548953\n",
      "[231]\ttrain-mlogloss:0.475758\ttest-mlogloss:0.548917\n",
      "[232]\ttrain-mlogloss:0.475505\ttest-mlogloss:0.54886\n",
      "[233]\ttrain-mlogloss:0.47533\ttest-mlogloss:0.548857\n",
      "[234]\ttrain-mlogloss:0.475022\ttest-mlogloss:0.548881\n",
      "[235]\ttrain-mlogloss:0.474643\ttest-mlogloss:0.54877\n",
      "[236]\ttrain-mlogloss:0.474322\ttest-mlogloss:0.548673\n",
      "[237]\ttrain-mlogloss:0.474017\ttest-mlogloss:0.548586\n",
      "[238]\ttrain-mlogloss:0.473654\ttest-mlogloss:0.548586\n",
      "[239]\ttrain-mlogloss:0.473332\ttest-mlogloss:0.548601\n",
      "[240]\ttrain-mlogloss:0.472976\ttest-mlogloss:0.548426\n",
      "[241]\ttrain-mlogloss:0.472767\ttest-mlogloss:0.548282\n",
      "[242]\ttrain-mlogloss:0.472484\ttest-mlogloss:0.548213\n",
      "[243]\ttrain-mlogloss:0.472161\ttest-mlogloss:0.548229\n",
      "[244]\ttrain-mlogloss:0.471895\ttest-mlogloss:0.548186\n",
      "[245]\ttrain-mlogloss:0.471622\ttest-mlogloss:0.548211\n",
      "[246]\ttrain-mlogloss:0.471382\ttest-mlogloss:0.548175\n",
      "[247]\ttrain-mlogloss:0.47101\ttest-mlogloss:0.548072\n",
      "[248]\ttrain-mlogloss:0.470759\ttest-mlogloss:0.548085\n",
      "[249]\ttrain-mlogloss:0.47042\ttest-mlogloss:0.548032\n",
      "[250]\ttrain-mlogloss:0.470067\ttest-mlogloss:0.547905\n",
      "[251]\ttrain-mlogloss:0.469753\ttest-mlogloss:0.547957\n",
      "[252]\ttrain-mlogloss:0.469469\ttest-mlogloss:0.547884\n",
      "[253]\ttrain-mlogloss:0.469123\ttest-mlogloss:0.547905\n",
      "[254]\ttrain-mlogloss:0.46884\ttest-mlogloss:0.547807\n",
      "[255]\ttrain-mlogloss:0.468591\ttest-mlogloss:0.547768\n",
      "[256]\ttrain-mlogloss:0.468374\ttest-mlogloss:0.547761\n",
      "[257]\ttrain-mlogloss:0.468124\ttest-mlogloss:0.547716\n",
      "[258]\ttrain-mlogloss:0.467817\ttest-mlogloss:0.547653\n",
      "[259]\ttrain-mlogloss:0.467502\ttest-mlogloss:0.547546\n",
      "[260]\ttrain-mlogloss:0.467241\ttest-mlogloss:0.54749\n",
      "[261]\ttrain-mlogloss:0.466989\ttest-mlogloss:0.547452\n",
      "[262]\ttrain-mlogloss:0.466777\ttest-mlogloss:0.54739\n",
      "[263]\ttrain-mlogloss:0.46638\ttest-mlogloss:0.547155\n",
      "[264]\ttrain-mlogloss:0.466138\ttest-mlogloss:0.547038\n",
      "[265]\ttrain-mlogloss:0.465955\ttest-mlogloss:0.546988\n",
      "[266]\ttrain-mlogloss:0.465635\ttest-mlogloss:0.546826\n",
      "[267]\ttrain-mlogloss:0.465316\ttest-mlogloss:0.546878\n",
      "[268]\ttrain-mlogloss:0.465018\ttest-mlogloss:0.546886\n",
      "[269]\ttrain-mlogloss:0.464659\ttest-mlogloss:0.546874\n",
      "[270]\ttrain-mlogloss:0.464457\ttest-mlogloss:0.546827\n",
      "[271]\ttrain-mlogloss:0.46414\ttest-mlogloss:0.546821\n",
      "[272]\ttrain-mlogloss:0.463813\ttest-mlogloss:0.546741\n",
      "[273]\ttrain-mlogloss:0.463555\ttest-mlogloss:0.546786\n",
      "[274]\ttrain-mlogloss:0.463275\ttest-mlogloss:0.546686\n",
      "[275]\ttrain-mlogloss:0.463027\ttest-mlogloss:0.5466\n",
      "[276]\ttrain-mlogloss:0.462813\ttest-mlogloss:0.546608\n",
      "[277]\ttrain-mlogloss:0.462571\ttest-mlogloss:0.546608\n",
      "[278]\ttrain-mlogloss:0.462297\ttest-mlogloss:0.546518\n",
      "[279]\ttrain-mlogloss:0.461996\ttest-mlogloss:0.546409\n",
      "[280]\ttrain-mlogloss:0.461673\ttest-mlogloss:0.546268\n",
      "[281]\ttrain-mlogloss:0.461447\ttest-mlogloss:0.546317\n",
      "[282]\ttrain-mlogloss:0.461012\ttest-mlogloss:0.54627\n",
      "[283]\ttrain-mlogloss:0.460714\ttest-mlogloss:0.546205\n",
      "[284]\ttrain-mlogloss:0.460453\ttest-mlogloss:0.54617\n",
      "[285]\ttrain-mlogloss:0.460224\ttest-mlogloss:0.546224\n",
      "[286]\ttrain-mlogloss:0.460038\ttest-mlogloss:0.546152\n",
      "[287]\ttrain-mlogloss:0.459803\ttest-mlogloss:0.546084\n",
      "[288]\ttrain-mlogloss:0.45963\ttest-mlogloss:0.546046\n",
      "[289]\ttrain-mlogloss:0.459317\ttest-mlogloss:0.545953\n",
      "[290]\ttrain-mlogloss:0.459053\ttest-mlogloss:0.545882\n",
      "[291]\ttrain-mlogloss:0.458761\ttest-mlogloss:0.54595\n",
      "[292]\ttrain-mlogloss:0.458479\ttest-mlogloss:0.545859\n",
      "[293]\ttrain-mlogloss:0.458255\ttest-mlogloss:0.545787\n",
      "[294]\ttrain-mlogloss:0.457987\ttest-mlogloss:0.54573\n",
      "[295]\ttrain-mlogloss:0.457757\ttest-mlogloss:0.545754\n",
      "[296]\ttrain-mlogloss:0.457584\ttest-mlogloss:0.545755\n",
      "[297]\ttrain-mlogloss:0.457296\ttest-mlogloss:0.545589\n",
      "[298]\ttrain-mlogloss:0.457047\ttest-mlogloss:0.545643\n",
      "[299]\ttrain-mlogloss:0.456691\ttest-mlogloss:0.545615\n",
      "[300]\ttrain-mlogloss:0.456368\ttest-mlogloss:0.545538\n",
      "[301]\ttrain-mlogloss:0.456037\ttest-mlogloss:0.545507\n",
      "[302]\ttrain-mlogloss:0.455808\ttest-mlogloss:0.545435\n",
      "[303]\ttrain-mlogloss:0.455626\ttest-mlogloss:0.545429\n",
      "[304]\ttrain-mlogloss:0.455495\ttest-mlogloss:0.545355\n",
      "[305]\ttrain-mlogloss:0.455157\ttest-mlogloss:0.545321\n",
      "[306]\ttrain-mlogloss:0.454949\ttest-mlogloss:0.545321\n",
      "[307]\ttrain-mlogloss:0.454654\ttest-mlogloss:0.545358\n",
      "[308]\ttrain-mlogloss:0.4544\ttest-mlogloss:0.545361\n",
      "[309]\ttrain-mlogloss:0.454095\ttest-mlogloss:0.545339\n",
      "[310]\ttrain-mlogloss:0.453809\ttest-mlogloss:0.545238\n",
      "[311]\ttrain-mlogloss:0.453528\ttest-mlogloss:0.545216\n",
      "[312]\ttrain-mlogloss:0.453238\ttest-mlogloss:0.545207\n",
      "[313]\ttrain-mlogloss:0.452994\ttest-mlogloss:0.545263\n",
      "[314]\ttrain-mlogloss:0.452697\ttest-mlogloss:0.545178\n",
      "[315]\ttrain-mlogloss:0.452434\ttest-mlogloss:0.545131\n",
      "[316]\ttrain-mlogloss:0.452102\ttest-mlogloss:0.545025\n",
      "[317]\ttrain-mlogloss:0.451829\ttest-mlogloss:0.544948\n",
      "[318]\ttrain-mlogloss:0.451573\ttest-mlogloss:0.545015\n",
      "[319]\ttrain-mlogloss:0.451324\ttest-mlogloss:0.545064\n",
      "[320]\ttrain-mlogloss:0.451111\ttest-mlogloss:0.544979\n",
      "[321]\ttrain-mlogloss:0.450844\ttest-mlogloss:0.545015\n",
      "[322]\ttrain-mlogloss:0.450607\ttest-mlogloss:0.544905\n",
      "[323]\ttrain-mlogloss:0.450338\ttest-mlogloss:0.544866\n",
      "[324]\ttrain-mlogloss:0.450003\ttest-mlogloss:0.544848\n",
      "[325]\ttrain-mlogloss:0.449794\ttest-mlogloss:0.5449\n",
      "[326]\ttrain-mlogloss:0.449539\ttest-mlogloss:0.54492\n",
      "[327]\ttrain-mlogloss:0.449218\ttest-mlogloss:0.544816\n",
      "[328]\ttrain-mlogloss:0.448948\ttest-mlogloss:0.544752\n",
      "[329]\ttrain-mlogloss:0.448759\ttest-mlogloss:0.544695\n",
      "[330]\ttrain-mlogloss:0.448474\ttest-mlogloss:0.544645\n",
      "[331]\ttrain-mlogloss:0.448216\ttest-mlogloss:0.544673\n",
      "[332]\ttrain-mlogloss:0.447964\ttest-mlogloss:0.544686\n",
      "[333]\ttrain-mlogloss:0.447616\ttest-mlogloss:0.544643\n",
      "[334]\ttrain-mlogloss:0.4473\ttest-mlogloss:0.544636\n",
      "[335]\ttrain-mlogloss:0.447118\ttest-mlogloss:0.544646\n",
      "[336]\ttrain-mlogloss:0.446908\ttest-mlogloss:0.544624\n",
      "[337]\ttrain-mlogloss:0.446762\ttest-mlogloss:0.544611\n",
      "[338]\ttrain-mlogloss:0.446528\ttest-mlogloss:0.544637\n",
      "[339]\ttrain-mlogloss:0.446313\ttest-mlogloss:0.544574\n",
      "[340]\ttrain-mlogloss:0.446103\ttest-mlogloss:0.544603\n",
      "[341]\ttrain-mlogloss:0.445851\ttest-mlogloss:0.544508\n",
      "[342]\ttrain-mlogloss:0.44552\ttest-mlogloss:0.544588\n",
      "[343]\ttrain-mlogloss:0.445306\ttest-mlogloss:0.544585\n",
      "[344]\ttrain-mlogloss:0.445108\ttest-mlogloss:0.544542\n",
      "[345]\ttrain-mlogloss:0.444891\ttest-mlogloss:0.544529\n",
      "[346]\ttrain-mlogloss:0.444608\ttest-mlogloss:0.544465\n",
      "[347]\ttrain-mlogloss:0.444354\ttest-mlogloss:0.544467\n",
      "[348]\ttrain-mlogloss:0.444156\ttest-mlogloss:0.544461\n",
      "[349]\ttrain-mlogloss:0.444024\ttest-mlogloss:0.544428\n",
      "[350]\ttrain-mlogloss:0.44376\ttest-mlogloss:0.544431\n",
      "[351]\ttrain-mlogloss:0.44357\ttest-mlogloss:0.54445\n",
      "[352]\ttrain-mlogloss:0.443305\ttest-mlogloss:0.544388\n",
      "[353]\ttrain-mlogloss:0.443117\ttest-mlogloss:0.544392\n",
      "[354]\ttrain-mlogloss:0.442877\ttest-mlogloss:0.544352\n",
      "[355]\ttrain-mlogloss:0.442619\ttest-mlogloss:0.544389\n",
      "[356]\ttrain-mlogloss:0.442446\ttest-mlogloss:0.544358\n",
      "[357]\ttrain-mlogloss:0.442182\ttest-mlogloss:0.544336\n",
      "[358]\ttrain-mlogloss:0.441874\ttest-mlogloss:0.544248\n",
      "[359]\ttrain-mlogloss:0.44165\ttest-mlogloss:0.544236\n",
      "[360]\ttrain-mlogloss:0.441371\ttest-mlogloss:0.544102\n",
      "[361]\ttrain-mlogloss:0.441106\ttest-mlogloss:0.544115\n",
      "[362]\ttrain-mlogloss:0.44087\ttest-mlogloss:0.544149\n",
      "[363]\ttrain-mlogloss:0.440569\ttest-mlogloss:0.544035\n",
      "[364]\ttrain-mlogloss:0.440315\ttest-mlogloss:0.544002\n",
      "[365]\ttrain-mlogloss:0.440141\ttest-mlogloss:0.543966\n",
      "[366]\ttrain-mlogloss:0.439833\ttest-mlogloss:0.543985\n",
      "[367]\ttrain-mlogloss:0.439599\ttest-mlogloss:0.5439\n",
      "[368]\ttrain-mlogloss:0.439348\ttest-mlogloss:0.543847\n",
      "[369]\ttrain-mlogloss:0.439115\ttest-mlogloss:0.543769\n",
      "[370]\ttrain-mlogloss:0.438871\ttest-mlogloss:0.543782\n",
      "[371]\ttrain-mlogloss:0.438612\ttest-mlogloss:0.543759\n",
      "[372]\ttrain-mlogloss:0.438326\ttest-mlogloss:0.543658\n",
      "[373]\ttrain-mlogloss:0.438034\ttest-mlogloss:0.543596\n",
      "[374]\ttrain-mlogloss:0.437799\ttest-mlogloss:0.543605\n",
      "[375]\ttrain-mlogloss:0.437597\ttest-mlogloss:0.543554\n",
      "[376]\ttrain-mlogloss:0.43731\ttest-mlogloss:0.543524\n",
      "[377]\ttrain-mlogloss:0.437068\ttest-mlogloss:0.543491\n",
      "[378]\ttrain-mlogloss:0.436836\ttest-mlogloss:0.543534\n",
      "[379]\ttrain-mlogloss:0.436624\ttest-mlogloss:0.543547\n",
      "[380]\ttrain-mlogloss:0.436441\ttest-mlogloss:0.543545\n",
      "[381]\ttrain-mlogloss:0.436221\ttest-mlogloss:0.543566\n",
      "[382]\ttrain-mlogloss:0.43604\ttest-mlogloss:0.543562\n",
      "[383]\ttrain-mlogloss:0.435834\ttest-mlogloss:0.543557\n",
      "[384]\ttrain-mlogloss:0.435542\ttest-mlogloss:0.543484\n",
      "[385]\ttrain-mlogloss:0.435324\ttest-mlogloss:0.543444\n",
      "[386]\ttrain-mlogloss:0.435109\ttest-mlogloss:0.543435\n",
      "[387]\ttrain-mlogloss:0.434852\ttest-mlogloss:0.543357\n",
      "[388]\ttrain-mlogloss:0.434614\ttest-mlogloss:0.543231\n",
      "[389]\ttrain-mlogloss:0.43433\ttest-mlogloss:0.543207\n",
      "[390]\ttrain-mlogloss:0.434064\ttest-mlogloss:0.543268\n",
      "[391]\ttrain-mlogloss:0.433876\ttest-mlogloss:0.543203\n",
      "[392]\ttrain-mlogloss:0.433553\ttest-mlogloss:0.543104\n",
      "[393]\ttrain-mlogloss:0.433262\ttest-mlogloss:0.543024\n",
      "[394]\ttrain-mlogloss:0.432931\ttest-mlogloss:0.54294\n",
      "[395]\ttrain-mlogloss:0.432679\ttest-mlogloss:0.54287\n",
      "[396]\ttrain-mlogloss:0.432443\ttest-mlogloss:0.542871\n",
      "[397]\ttrain-mlogloss:0.432268\ttest-mlogloss:0.542878\n",
      "[398]\ttrain-mlogloss:0.432033\ttest-mlogloss:0.542861\n",
      "[399]\ttrain-mlogloss:0.431802\ttest-mlogloss:0.542818\n",
      "[400]\ttrain-mlogloss:0.431518\ttest-mlogloss:0.542779\n",
      "[401]\ttrain-mlogloss:0.431292\ttest-mlogloss:0.542745\n",
      "[402]\ttrain-mlogloss:0.431102\ttest-mlogloss:0.542687\n",
      "[403]\ttrain-mlogloss:0.430898\ttest-mlogloss:0.542694\n",
      "[404]\ttrain-mlogloss:0.430692\ttest-mlogloss:0.542682\n",
      "[405]\ttrain-mlogloss:0.430496\ttest-mlogloss:0.542639\n",
      "[406]\ttrain-mlogloss:0.430289\ttest-mlogloss:0.542642\n",
      "[407]\ttrain-mlogloss:0.430111\ttest-mlogloss:0.542598\n",
      "[408]\ttrain-mlogloss:0.42977\ttest-mlogloss:0.542603\n",
      "[409]\ttrain-mlogloss:0.429523\ttest-mlogloss:0.542547\n",
      "[410]\ttrain-mlogloss:0.429227\ttest-mlogloss:0.542489\n",
      "[411]\ttrain-mlogloss:0.428989\ttest-mlogloss:0.542479\n",
      "[412]\ttrain-mlogloss:0.428737\ttest-mlogloss:0.542537\n",
      "[413]\ttrain-mlogloss:0.428512\ttest-mlogloss:0.542581\n",
      "[414]\ttrain-mlogloss:0.428314\ttest-mlogloss:0.542473\n",
      "[415]\ttrain-mlogloss:0.428046\ttest-mlogloss:0.5425\n",
      "[416]\ttrain-mlogloss:0.427851\ttest-mlogloss:0.542491\n",
      "[417]\ttrain-mlogloss:0.42762\ttest-mlogloss:0.542518\n",
      "[418]\ttrain-mlogloss:0.427337\ttest-mlogloss:0.542468\n",
      "[419]\ttrain-mlogloss:0.427103\ttest-mlogloss:0.542477\n",
      "[420]\ttrain-mlogloss:0.426915\ttest-mlogloss:0.542522\n",
      "[421]\ttrain-mlogloss:0.426628\ttest-mlogloss:0.542561\n",
      "[422]\ttrain-mlogloss:0.426369\ttest-mlogloss:0.542549\n",
      "[423]\ttrain-mlogloss:0.426179\ttest-mlogloss:0.542501\n",
      "[424]\ttrain-mlogloss:0.426009\ttest-mlogloss:0.542471\n",
      "[425]\ttrain-mlogloss:0.425808\ttest-mlogloss:0.542439\n",
      "[426]\ttrain-mlogloss:0.425572\ttest-mlogloss:0.542369\n",
      "[427]\ttrain-mlogloss:0.425408\ttest-mlogloss:0.54247\n",
      "[428]\ttrain-mlogloss:0.425122\ttest-mlogloss:0.542497\n",
      "[429]\ttrain-mlogloss:0.424932\ttest-mlogloss:0.542542\n",
      "[430]\ttrain-mlogloss:0.424685\ttest-mlogloss:0.542577\n",
      "[431]\ttrain-mlogloss:0.424423\ttest-mlogloss:0.542535\n",
      "[432]\ttrain-mlogloss:0.424241\ttest-mlogloss:0.542574\n",
      "[433]\ttrain-mlogloss:0.423922\ttest-mlogloss:0.542649\n",
      "[434]\ttrain-mlogloss:0.423665\ttest-mlogloss:0.542665\n",
      "[435]\ttrain-mlogloss:0.423385\ttest-mlogloss:0.542709\n",
      "[436]\ttrain-mlogloss:0.423094\ttest-mlogloss:0.542732\n",
      "[437]\ttrain-mlogloss:0.422914\ttest-mlogloss:0.542658\n",
      "[438]\ttrain-mlogloss:0.422701\ttest-mlogloss:0.542683\n",
      "[439]\ttrain-mlogloss:0.42254\ttest-mlogloss:0.542652\n",
      "[440]\ttrain-mlogloss:0.422251\ttest-mlogloss:0.542643\n",
      "[441]\ttrain-mlogloss:0.422058\ttest-mlogloss:0.542585\n",
      "[442]\ttrain-mlogloss:0.421826\ttest-mlogloss:0.542487\n",
      "[443]\ttrain-mlogloss:0.421638\ttest-mlogloss:0.542468\n",
      "[444]\ttrain-mlogloss:0.421415\ttest-mlogloss:0.542402\n",
      "[445]\ttrain-mlogloss:0.421208\ttest-mlogloss:0.54242\n",
      "[446]\ttrain-mlogloss:0.421023\ttest-mlogloss:0.542431\n",
      "[447]\ttrain-mlogloss:0.420788\ttest-mlogloss:0.542357\n",
      "[448]\ttrain-mlogloss:0.420617\ttest-mlogloss:0.542377\n",
      "[449]\ttrain-mlogloss:0.420424\ttest-mlogloss:0.542359\n",
      "[450]\ttrain-mlogloss:0.420191\ttest-mlogloss:0.542364\n",
      "[451]\ttrain-mlogloss:0.419935\ttest-mlogloss:0.542331\n",
      "[452]\ttrain-mlogloss:0.419641\ttest-mlogloss:0.542317\n",
      "[453]\ttrain-mlogloss:0.419398\ttest-mlogloss:0.542296\n",
      "[454]\ttrain-mlogloss:0.419181\ttest-mlogloss:0.542289\n",
      "[455]\ttrain-mlogloss:0.418923\ttest-mlogloss:0.542236\n",
      "[456]\ttrain-mlogloss:0.41867\ttest-mlogloss:0.542211\n",
      "[457]\ttrain-mlogloss:0.418462\ttest-mlogloss:0.542216\n",
      "[458]\ttrain-mlogloss:0.418179\ttest-mlogloss:0.542196\n",
      "[459]\ttrain-mlogloss:0.41794\ttest-mlogloss:0.542236\n",
      "[460]\ttrain-mlogloss:0.417761\ttest-mlogloss:0.542271\n",
      "[461]\ttrain-mlogloss:0.41753\ttest-mlogloss:0.542248\n",
      "[462]\ttrain-mlogloss:0.417288\ttest-mlogloss:0.542216\n",
      "[463]\ttrain-mlogloss:0.417089\ttest-mlogloss:0.542233\n",
      "[464]\ttrain-mlogloss:0.416893\ttest-mlogloss:0.542227\n",
      "[465]\ttrain-mlogloss:0.416728\ttest-mlogloss:0.542259\n",
      "[466]\ttrain-mlogloss:0.416528\ttest-mlogloss:0.542298\n",
      "[467]\ttrain-mlogloss:0.416373\ttest-mlogloss:0.542326\n",
      "[468]\ttrain-mlogloss:0.416116\ttest-mlogloss:0.542358\n",
      "[469]\ttrain-mlogloss:0.415918\ttest-mlogloss:0.542401\n",
      "[470]\ttrain-mlogloss:0.415736\ttest-mlogloss:0.542431\n",
      "[471]\ttrain-mlogloss:0.415562\ttest-mlogloss:0.542439\n",
      "[472]\ttrain-mlogloss:0.41531\ttest-mlogloss:0.542392\n",
      "[473]\ttrain-mlogloss:0.415099\ttest-mlogloss:0.542334\n",
      "[474]\ttrain-mlogloss:0.414903\ttest-mlogloss:0.542367\n",
      "[475]\ttrain-mlogloss:0.414607\ttest-mlogloss:0.542398\n",
      "[476]\ttrain-mlogloss:0.414431\ttest-mlogloss:0.542422\n",
      "[477]\ttrain-mlogloss:0.414138\ttest-mlogloss:0.542437\n",
      "[478]\ttrain-mlogloss:0.413931\ttest-mlogloss:0.542502\n",
      "[479]\ttrain-mlogloss:0.413726\ttest-mlogloss:0.542432\n",
      "[480]\ttrain-mlogloss:0.413513\ttest-mlogloss:0.542399\n",
      "[481]\ttrain-mlogloss:0.413299\ttest-mlogloss:0.542381\n",
      "[482]\ttrain-mlogloss:0.413065\ttest-mlogloss:0.542376\n",
      "[483]\ttrain-mlogloss:0.412835\ttest-mlogloss:0.542375\n",
      "[484]\ttrain-mlogloss:0.412639\ttest-mlogloss:0.542405\n",
      "[485]\ttrain-mlogloss:0.412444\ttest-mlogloss:0.542372\n",
      "[486]\ttrain-mlogloss:0.412247\ttest-mlogloss:0.54239\n",
      "[487]\ttrain-mlogloss:0.412015\ttest-mlogloss:0.542357\n",
      "[488]\ttrain-mlogloss:0.411783\ttest-mlogloss:0.542365\n",
      "[489]\ttrain-mlogloss:0.411561\ttest-mlogloss:0.542404\n",
      "[490]\ttrain-mlogloss:0.411387\ttest-mlogloss:0.542468\n",
      "[491]\ttrain-mlogloss:0.411206\ttest-mlogloss:0.542489\n",
      "[492]\ttrain-mlogloss:0.410906\ttest-mlogloss:0.542477\n",
      "[493]\ttrain-mlogloss:0.410679\ttest-mlogloss:0.542428\n",
      "[494]\ttrain-mlogloss:0.410466\ttest-mlogloss:0.542427\n",
      "[495]\ttrain-mlogloss:0.410293\ttest-mlogloss:0.542435\n",
      "[496]\ttrain-mlogloss:0.41013\ttest-mlogloss:0.542449\n",
      "[497]\ttrain-mlogloss:0.409863\ttest-mlogloss:0.542369\n",
      "[498]\ttrain-mlogloss:0.409689\ttest-mlogloss:0.54246\n",
      "[499]\ttrain-mlogloss:0.40943\ttest-mlogloss:0.542367\n",
      "[500]\ttrain-mlogloss:0.409239\ttest-mlogloss:0.542403\n",
      "[501]\ttrain-mlogloss:0.408972\ttest-mlogloss:0.542428\n",
      "[502]\ttrain-mlogloss:0.408794\ttest-mlogloss:0.542412\n",
      "[503]\ttrain-mlogloss:0.408534\ttest-mlogloss:0.542414\n",
      "[504]\ttrain-mlogloss:0.408341\ttest-mlogloss:0.542373\n",
      "[505]\ttrain-mlogloss:0.408192\ttest-mlogloss:0.542369\n",
      "[506]\ttrain-mlogloss:0.40799\ttest-mlogloss:0.542297\n",
      "[507]\ttrain-mlogloss:0.407757\ttest-mlogloss:0.542309\n",
      "[508]\ttrain-mlogloss:0.4075\ttest-mlogloss:0.54233\n",
      "[509]\ttrain-mlogloss:0.407286\ttest-mlogloss:0.542311\n",
      "[510]\ttrain-mlogloss:0.407145\ttest-mlogloss:0.542401\n",
      "[511]\ttrain-mlogloss:0.406916\ttest-mlogloss:0.542337\n",
      "[512]\ttrain-mlogloss:0.406688\ttest-mlogloss:0.542438\n",
      "[513]\ttrain-mlogloss:0.406555\ttest-mlogloss:0.542412\n",
      "[514]\ttrain-mlogloss:0.406319\ttest-mlogloss:0.542431\n",
      "[515]\ttrain-mlogloss:0.406164\ttest-mlogloss:0.542445\n",
      "[516]\ttrain-mlogloss:0.406013\ttest-mlogloss:0.542436\n",
      "[517]\ttrain-mlogloss:0.405888\ttest-mlogloss:0.542438\n",
      "[518]\ttrain-mlogloss:0.405666\ttest-mlogloss:0.542432\n",
      "[519]\ttrain-mlogloss:0.40547\ttest-mlogloss:0.542364\n",
      "[520]\ttrain-mlogloss:0.405273\ttest-mlogloss:0.542337\n",
      "[521]\ttrain-mlogloss:0.405124\ttest-mlogloss:0.54239\n",
      "[522]\ttrain-mlogloss:0.404902\ttest-mlogloss:0.542395\n",
      "[523]\ttrain-mlogloss:0.404734\ttest-mlogloss:0.542408\n",
      "[524]\ttrain-mlogloss:0.404534\ttest-mlogloss:0.542411\n",
      "[525]\ttrain-mlogloss:0.404291\ttest-mlogloss:0.542378\n",
      "[526]\ttrain-mlogloss:0.404052\ttest-mlogloss:0.542364\n",
      "[527]\ttrain-mlogloss:0.403875\ttest-mlogloss:0.542378\n",
      "[528]\ttrain-mlogloss:0.40369\ttest-mlogloss:0.542299\n",
      "[529]\ttrain-mlogloss:0.403504\ttest-mlogloss:0.542283\n",
      "[530]\ttrain-mlogloss:0.403353\ttest-mlogloss:0.542235\n",
      "[531]\ttrain-mlogloss:0.403135\ttest-mlogloss:0.542314\n",
      "[532]\ttrain-mlogloss:0.402978\ttest-mlogloss:0.542355\n",
      "[533]\ttrain-mlogloss:0.402794\ttest-mlogloss:0.542437\n",
      "[534]\ttrain-mlogloss:0.402616\ttest-mlogloss:0.542391\n",
      "[535]\ttrain-mlogloss:0.402398\ttest-mlogloss:0.542359\n",
      "[536]\ttrain-mlogloss:0.402225\ttest-mlogloss:0.542334\n",
      "[537]\ttrain-mlogloss:0.401989\ttest-mlogloss:0.542335\n",
      "[538]\ttrain-mlogloss:0.401765\ttest-mlogloss:0.542358\n",
      "[539]\ttrain-mlogloss:0.401591\ttest-mlogloss:0.542437\n",
      "[540]\ttrain-mlogloss:0.401391\ttest-mlogloss:0.542461\n",
      "[541]\ttrain-mlogloss:0.401189\ttest-mlogloss:0.542393\n",
      "[542]\ttrain-mlogloss:0.400917\ttest-mlogloss:0.542399\n",
      "[543]\ttrain-mlogloss:0.400683\ttest-mlogloss:0.542483\n",
      "[544]\ttrain-mlogloss:0.400461\ttest-mlogloss:0.542475\n",
      "[545]\ttrain-mlogloss:0.400283\ttest-mlogloss:0.542448\n",
      "[546]\ttrain-mlogloss:0.40006\ttest-mlogloss:0.542499\n",
      "[547]\ttrain-mlogloss:0.399851\ttest-mlogloss:0.542433\n",
      "[548]\ttrain-mlogloss:0.399655\ttest-mlogloss:0.54251\n",
      "[549]\ttrain-mlogloss:0.399508\ttest-mlogloss:0.54252\n",
      "[550]\ttrain-mlogloss:0.39936\ttest-mlogloss:0.542527\n",
      "[551]\ttrain-mlogloss:0.399171\ttest-mlogloss:0.542536\n",
      "[552]\ttrain-mlogloss:0.398947\ttest-mlogloss:0.542544\n",
      "[553]\ttrain-mlogloss:0.398719\ttest-mlogloss:0.542475\n",
      "[554]\ttrain-mlogloss:0.398473\ttest-mlogloss:0.542424\n",
      "[555]\ttrain-mlogloss:0.398251\ttest-mlogloss:0.542443\n",
      "[556]\ttrain-mlogloss:0.398056\ttest-mlogloss:0.542352\n",
      "[557]\ttrain-mlogloss:0.39785\ttest-mlogloss:0.542462\n",
      "[558]\ttrain-mlogloss:0.397681\ttest-mlogloss:0.542451\n",
      "[559]\ttrain-mlogloss:0.39741\ttest-mlogloss:0.542386\n",
      "[560]\ttrain-mlogloss:0.397153\ttest-mlogloss:0.542442\n",
      "[561]\ttrain-mlogloss:0.396886\ttest-mlogloss:0.542413\n",
      "[562]\ttrain-mlogloss:0.396669\ttest-mlogloss:0.542401\n",
      "[563]\ttrain-mlogloss:0.396497\ttest-mlogloss:0.542455\n",
      "[564]\ttrain-mlogloss:0.396265\ttest-mlogloss:0.542483\n",
      "[565]\ttrain-mlogloss:0.396046\ttest-mlogloss:0.542534\n",
      "[566]\ttrain-mlogloss:0.395804\ttest-mlogloss:0.542587\n",
      "[567]\ttrain-mlogloss:0.395619\ttest-mlogloss:0.542565\n",
      "[568]\ttrain-mlogloss:0.395435\ttest-mlogloss:0.542504\n",
      "[569]\ttrain-mlogloss:0.395238\ttest-mlogloss:0.542521\n",
      "[570]\ttrain-mlogloss:0.395077\ttest-mlogloss:0.542517\n",
      "[571]\ttrain-mlogloss:0.394884\ttest-mlogloss:0.542573\n",
      "[572]\ttrain-mlogloss:0.394648\ttest-mlogloss:0.54264\n",
      "[573]\ttrain-mlogloss:0.394406\ttest-mlogloss:0.542654\n",
      "[574]\ttrain-mlogloss:0.394234\ttest-mlogloss:0.542716\n",
      "[575]\ttrain-mlogloss:0.393986\ttest-mlogloss:0.542721\n",
      "[576]\ttrain-mlogloss:0.393724\ttest-mlogloss:0.54278\n",
      "[577]\ttrain-mlogloss:0.393443\ttest-mlogloss:0.542816\n",
      "[578]\ttrain-mlogloss:0.393216\ttest-mlogloss:0.542827\n",
      "[579]\ttrain-mlogloss:0.393041\ttest-mlogloss:0.542843\n",
      "[580]\ttrain-mlogloss:0.392773\ttest-mlogloss:0.542932\n",
      "[581]\ttrain-mlogloss:0.392552\ttest-mlogloss:0.542942\n",
      "[582]\ttrain-mlogloss:0.392349\ttest-mlogloss:0.542928\n",
      "[583]\ttrain-mlogloss:0.392105\ttest-mlogloss:0.54303\n",
      "[584]\ttrain-mlogloss:0.391907\ttest-mlogloss:0.543064\n",
      "[585]\ttrain-mlogloss:0.391699\ttest-mlogloss:0.543051\n",
      "[586]\ttrain-mlogloss:0.391535\ttest-mlogloss:0.543039\n",
      "[587]\ttrain-mlogloss:0.3912\ttest-mlogloss:0.543025\n",
      "[588]\ttrain-mlogloss:0.391028\ttest-mlogloss:0.543039\n",
      "[589]\ttrain-mlogloss:0.390867\ttest-mlogloss:0.543045\n",
      "[590]\ttrain-mlogloss:0.390687\ttest-mlogloss:0.543032\n",
      "[591]\ttrain-mlogloss:0.390583\ttest-mlogloss:0.543099\n",
      "[592]\ttrain-mlogloss:0.39037\ttest-mlogloss:0.543121\n",
      "[593]\ttrain-mlogloss:0.390172\ttest-mlogloss:0.543129\n",
      "[594]\ttrain-mlogloss:0.389944\ttest-mlogloss:0.543156\n",
      "[595]\ttrain-mlogloss:0.389735\ttest-mlogloss:0.543134\n",
      "[596]\ttrain-mlogloss:0.389547\ttest-mlogloss:0.543207\n",
      "[597]\ttrain-mlogloss:0.389342\ttest-mlogloss:0.543174\n",
      "[598]\ttrain-mlogloss:0.389126\ttest-mlogloss:0.543165\n",
      "[599]\ttrain-mlogloss:0.388915\ttest-mlogloss:0.543232\n",
      "[600]\ttrain-mlogloss:0.388683\ttest-mlogloss:0.543325\n",
      "[601]\ttrain-mlogloss:0.388472\ttest-mlogloss:0.543313\n",
      "[602]\ttrain-mlogloss:0.388283\ttest-mlogloss:0.543281\n",
      "[603]\ttrain-mlogloss:0.388087\ttest-mlogloss:0.543225\n",
      "[604]\ttrain-mlogloss:0.387886\ttest-mlogloss:0.543212\n",
      "[605]\ttrain-mlogloss:0.387659\ttest-mlogloss:0.543171\n",
      "[606]\ttrain-mlogloss:0.387414\ttest-mlogloss:0.543179\n",
      "[607]\ttrain-mlogloss:0.387203\ttest-mlogloss:0.543104\n",
      "[608]\ttrain-mlogloss:0.387018\ttest-mlogloss:0.543064\n",
      "[609]\ttrain-mlogloss:0.386818\ttest-mlogloss:0.542986\n",
      "[610]\ttrain-mlogloss:0.386648\ttest-mlogloss:0.542981\n",
      "[611]\ttrain-mlogloss:0.386461\ttest-mlogloss:0.543054\n",
      "[612]\ttrain-mlogloss:0.386258\ttest-mlogloss:0.543023\n",
      "[613]\ttrain-mlogloss:0.386081\ttest-mlogloss:0.542979\n",
      "[614]\ttrain-mlogloss:0.385924\ttest-mlogloss:0.543008\n",
      "[615]\ttrain-mlogloss:0.385719\ttest-mlogloss:0.542969\n",
      "[616]\ttrain-mlogloss:0.385458\ttest-mlogloss:0.543007\n",
      "[617]\ttrain-mlogloss:0.385293\ttest-mlogloss:0.542935\n",
      "[618]\ttrain-mlogloss:0.385048\ttest-mlogloss:0.542936\n",
      "[619]\ttrain-mlogloss:0.384851\ttest-mlogloss:0.542928\n",
      "[620]\ttrain-mlogloss:0.38471\ttest-mlogloss:0.542944\n",
      "[621]\ttrain-mlogloss:0.384539\ttest-mlogloss:0.542947\n",
      "[622]\ttrain-mlogloss:0.384317\ttest-mlogloss:0.543017\n",
      "[623]\ttrain-mlogloss:0.384059\ttest-mlogloss:0.54302\n",
      "[624]\ttrain-mlogloss:0.383851\ttest-mlogloss:0.543106\n",
      "[625]\ttrain-mlogloss:0.383709\ttest-mlogloss:0.543133\n",
      "[626]\ttrain-mlogloss:0.383562\ttest-mlogloss:0.543133\n",
      "[627]\ttrain-mlogloss:0.383378\ttest-mlogloss:0.543114\n",
      "[628]\ttrain-mlogloss:0.383244\ttest-mlogloss:0.543192\n",
      "[629]\ttrain-mlogloss:0.383034\ttest-mlogloss:0.54321\n",
      "[630]\ttrain-mlogloss:0.382813\ttest-mlogloss:0.54311\n",
      "[631]\ttrain-mlogloss:0.382596\ttest-mlogloss:0.543057\n",
      "[632]\ttrain-mlogloss:0.382406\ttest-mlogloss:0.543095\n",
      "[633]\ttrain-mlogloss:0.382163\ttest-mlogloss:0.54306\n",
      "[634]\ttrain-mlogloss:0.381998\ttest-mlogloss:0.542972\n",
      "[635]\ttrain-mlogloss:0.381877\ttest-mlogloss:0.543083\n",
      "[636]\ttrain-mlogloss:0.381676\ttest-mlogloss:0.54307\n",
      "[637]\ttrain-mlogloss:0.381507\ttest-mlogloss:0.54307\n",
      "[638]\ttrain-mlogloss:0.381315\ttest-mlogloss:0.543037\n",
      "[639]\ttrain-mlogloss:0.381128\ttest-mlogloss:0.543014\n",
      "[640]\ttrain-mlogloss:0.380919\ttest-mlogloss:0.542986\n",
      "[641]\ttrain-mlogloss:0.380767\ttest-mlogloss:0.542972\n",
      "[642]\ttrain-mlogloss:0.380596\ttest-mlogloss:0.543011\n",
      "[643]\ttrain-mlogloss:0.380441\ttest-mlogloss:0.542916\n",
      "[644]\ttrain-mlogloss:0.380349\ttest-mlogloss:0.542924\n",
      "[645]\ttrain-mlogloss:0.380202\ttest-mlogloss:0.542906\n",
      "[646]\ttrain-mlogloss:0.380058\ttest-mlogloss:0.542846\n",
      "[647]\ttrain-mlogloss:0.379876\ttest-mlogloss:0.542937\n",
      "[648]\ttrain-mlogloss:0.379655\ttest-mlogloss:0.542909\n",
      "[649]\ttrain-mlogloss:0.379426\ttest-mlogloss:0.543002\n",
      "[650]\ttrain-mlogloss:0.3793\ttest-mlogloss:0.542979\n",
      "[651]\ttrain-mlogloss:0.379152\ttest-mlogloss:0.542963\n",
      "[652]\ttrain-mlogloss:0.37893\ttest-mlogloss:0.542895\n",
      "[653]\ttrain-mlogloss:0.378776\ttest-mlogloss:0.543043\n",
      "[654]\ttrain-mlogloss:0.378584\ttest-mlogloss:0.543022\n",
      "[655]\ttrain-mlogloss:0.378395\ttest-mlogloss:0.542977\n",
      "[656]\ttrain-mlogloss:0.378183\ttest-mlogloss:0.542854\n",
      "[657]\ttrain-mlogloss:0.37799\ttest-mlogloss:0.542906\n",
      "[658]\ttrain-mlogloss:0.377823\ttest-mlogloss:0.542983\n",
      "Stopping. Best iteration:\n",
      "[458]\ttrain-mlogloss:0.418179\ttest-mlogloss:0.542196\n",
      "\n",
      "[0.54298306773379024]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cv_scores = []\n",
    "\n",
    "mini_ranking = 15\n",
    "\n",
    "for dev_index, val_index in KF:\n",
    "        #split the orginal train set into dev_set and val_set\n",
    "        dev_set, val_set = train_df.iloc[dev_index,:] , train_df.iloc[val_index,:] \n",
    "                \n",
    "        \n",
    "#====================================================================        \n",
    "        \"\"\"feature engineerings for the categorical features\"\"\"\n",
    "        \n",
    "        dev_set, val_set =manager_skill_eval(dev_set,val_set,\\\n",
    "        unrank_threshold = mini_ranking)\n",
    "        \n",
    "        #============================hcc-encoding================================\n",
    "        \n",
    "        for f in ['building_id', 'manager_id', 'display_address']:\n",
    "                singleValueConvert(dev_set,val_set,f,1)\n",
    "\n",
    "        dev_set = dev_set.replace({\"interest_level\": {\"low\": 0, \"medium\": 1, \"high\": 2}})\n",
    "        dev_set = dev_set.join(pd.get_dummies(dev_set[\"interest_level\"], prefix=\"pred\").astype(int))\n",
    "        prior_0, prior_1, prior_2 = dev_set[[\"pred_0\", \"pred_1\", \"pred_2\"]].mean()\n",
    "        \n",
    "        skf = StratifiedKFold(dev_set['interest_level'],random_state = 42)\n",
    "        attributes = product((\"building_id\", \"manager_id\"), zip((\"pred_1\", \"pred_2\"), (prior_1, prior_2)))\n",
    "        for variable, (target, prior) in attributes:\n",
    "            hcc_encode(dev_set, val_set, variable, target, prior, k=5, r_k=None)\n",
    "            for train, test in skf:\n",
    "                hcc_encode(dev_set.iloc[train], dev_set.iloc[test], variable, target, prior, \\\n",
    "                           k=5, r_k=0.01, update_df=dev_set)\n",
    "        \n",
    "        #==========================hcc-encoding=====================================\n",
    "        \n",
    "        \n",
    "        #fill substitute the small size values by their mean\n",
    "        for f in categorical:\n",
    "\n",
    "            \n",
    "            if dev_set[f].dtype=='object':\n",
    "                #print(f)\n",
    "                lbl = preprocessing.LabelEncoder()\n",
    "                lbl.fit(list(dev_set[f])+list(val_set[f]))\n",
    "                dev_set[f] = lbl.transform(list(dev_set[f].values))\n",
    "                val_set[f] = lbl.transform(list(val_set[f].values))\n",
    "        \n",
    "        \n",
    "#===================================================================\n",
    "                \n",
    "        #filter the features\n",
    "        dev_X, val_X = dev_set[features_to_use].as_matrix(), val_set[features_to_use].as_matrix()\n",
    "        dev_y, val_y = train_y[dev_index], train_y[val_index]\n",
    "        \n",
    "        \"\"\"\n",
    "        runXGB(train_X, train_y, test_X, test_y=None, feature_names=None, \\\n",
    "        seed_val=0, early_stop = 20,num_rounds=10000, eta = 0.1, max_depth = 6)\n",
    "        \"\"\"        \n",
    "        \n",
    "        preds, model = runXGB(dev_X, dev_y, val_X, val_y,\\\n",
    "        feature_names=features_to_use,early_stop=200,\n",
    "        num_rounds = 20000, eta = 0.1,max_depth = 4)\n",
    "        \n",
    "        #using rf for feature choosing\n",
    "        #model = ensemble.RandomForestClassifier(500,max_depth=35 ,random_state = 42,\\\n",
    "        #                                        class_weight='balanced',min_samples_split=10)\n",
    "        #model.fit(dev_X,dev_y)\n",
    "        #pred_prob = model.predict_proba(val_X)\n",
    "        #orig_prob = model.predict_proba(dev_X)\n",
    "        #pred = model.predict(val_X)\n",
    "            \n",
    "        cv_scores.append(log_loss(val_y, preds))\n",
    "        break\n",
    "#print 'in-sample error:'+str(log_loss(dev_y, orig_prob))\n",
    "#print 'out-of sample error'+str(log_loss(val_y, pred_prob))\n",
    "print cv_scores\n",
    "#print accuracy_score(val_y,pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_to_use=list(set(features_to_use))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'ManHigh', u'ManLow', u'ManMedium'], dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:123: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n"
     ]
    }
   ],
   "source": [
    "#features_to_use.append('manager_skill')\n",
    "#categorical = [\"display_address\", \"manager_id\", \"building_id\", \"street_address\",\"street_name\"]\n",
    "#features_to_use.extend(categorical)\n",
    "\n",
    "#====================================================================        \n",
    "\"\"\"feature engineerings for the categorical features\"\"\"\n",
    "\n",
    "train_set, test_set =manager_skill_eval(train_df,test_df,\\\n",
    "unrank_threshold = mini_ranking)\n",
    "\n",
    "\n",
    "#fill substitute the small size values by their mean\n",
    "for f in categorical:\n",
    "    train_set,test_set  = singleValueConvert(train_set,test_set,f,mini_ranking)\n",
    "\n",
    "    if train_set[f].dtype=='object':\n",
    "        #print(f)\n",
    "        lbl = preprocessing.LabelEncoder()\n",
    "        lbl.fit(list(train_df[f])+list(test_df[f]))\n",
    "        train_set[f] = lbl.transform(list(train_set[f].values))\n",
    "        test_set[f] = lbl.transform(list(test_set[f].values))\n",
    "\n",
    "#addAvgDiff(train_set,test_set,nn=15)\n",
    "\n",
    "#===================================================================\n",
    "\n",
    "train_X = train_set[features_to_use]\n",
    "test_X = test_set[features_to_use]\n",
    "\n",
    "train_X_m = train_X.as_matrix()\n",
    "test_X_m = test_X.as_matrix()\n",
    "\n",
    "        \"\"\"\n",
    "        runXGB(train_X, train_y, test_X, test_y=None, feature_names=None, \\\n",
    "        seed_val=0, early_stop = 20,num_rounds=10000, eta = 0.1, max_depth = 6)\n",
    "        \"\"\"        \n",
    "        \n",
    "preds, model = runXGB(dev_X, dev_y, val_X, val_y,\\\n",
    "feature_names=features_to_use,early_stop=200,\n",
    "num_rounds = 20000, eta = 0.1,max_depth = 4)\n",
    "\n",
    "out_df = pd.DataFrame(preds)\n",
    "out_df.columns = [\"high\", \"medium\", \"low\"]\n",
    "out_df[\"listing_id\"] = test_df.listing_id.values\n",
    "out_df.to_csv(\"xgb_beta1point251-nndiff.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([            u'bathrooms',              u'bedrooms',\n",
       "                 u'building_id',               u'created',\n",
       "                 u'description',       u'display_address',\n",
       "                    u'features',        u'interest_level',\n",
       "                    u'latitude',            u'listing_id',\n",
       "                   u'longitude',            u'manager_id',\n",
       "                      u'photos',                 u'price',\n",
       "              u'street_address',            u'num_photos',\n",
       "                u'num_features', u'num_description_words',\n",
       "                u'created_year',         u'created_month',\n",
       "                 u'created_day',          u'created_hour'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_set.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('latitude', 0.0836509332551549),\n",
       " ('price', 0.07954656503469168),\n",
       " ('listing_id', 0.07529561223492622),\n",
       " ('longitude', 0.07456268933841494),\n",
       " ('price_per_room', 0.07358545880973322),\n",
       " ('manager_skill', 0.058731554773771136),\n",
       " ('num_description_words', 0.05511580181764878),\n",
       " ('price_per_bed', 0.047982018958272254),\n",
       " ('manager_id', 0.039968728623082185),\n",
       " ('building_id', 0.035424606664712206),\n",
       " ('street_name', 0.03488712987393726),\n",
       " ('created_hour', 0.03263949965796931),\n",
       " ('created_day', 0.03073390012703997),\n",
       " ('num_photos', 0.030440730968435453),\n",
       " ('display_address', 0.029463500439753737),\n",
       " ('num_features', 0.026238639695104076),\n",
       " ('street_address', 0.018518518518518517),\n",
       " ('with_no_fee', 0.011482458712010164),\n",
       " ('bedrooms', 0.010212059024723932),\n",
       " ('bathrooms', 0.00952799765464673),\n",
       " ('hcc_building_id_high', 0.00943027460177856),\n",
       " ('hcc_manager_id_medium', 0.008550767125965015),\n",
       " ('bath_per_bed', 0.008355321020228672),\n",
       " ('hcc_manager_id_high', 0.008013290335190071),\n",
       " ('hcc_building_id_medium', 0.007671259650151471),\n",
       " ('with_furnished', 0.006058829277826639),\n",
       " ('with_hardwood_floors', 0.004446398905501808),\n",
       " ('with_laundry_in_building', 0.0042509527997654645),\n",
       " ('with_pre_war', 0.004202091273331379),\n",
       " ('with_cats_allowed', 0.003664614482556435),\n",
       " ('with_laundry_in_unit', 0.0035668914296882633),\n",
       " ('with_exclusive', 0.003420306850386006),\n",
       " ('with_dogs_allowed', 0.0030782761653474055),\n",
       " ('with_reduced_fee', 0.0030294146389133196),\n",
       " ('with_common_outdoor_space', 0.0030294146389133196),\n",
       " ('with_doorman', 0.002931691586045148),\n",
       " ('with_dishwasher', 0.002882830059611062),\n",
       " ('with_fitness_center', 0.002540799374572462),\n",
       " ('created_month', 0.002540799374572462),\n",
       " ('with_simplex', 0.0022476302159679467),\n",
       " ('with_roof_deck', 0.0021987686895338612),\n",
       " ('with_outdoor_space', 0.0021987686895338612),\n",
       " ('with_actual_apt._photos', 0.0021987686895338612),\n",
       " ('with_dining_room', 0.0021010456366656895),\n",
       " ('with_private_outdoor_space', 0.0021010456366656895),\n",
       " ('with_hardwood', 0.0021010456366656895),\n",
       " ('with_new_construction', 0.0020521841102316037),\n",
       " ('with_parking_space', 0.0020521841102316037),\n",
       " ('with_elevator', 0.001954461057363432),\n",
       " ('with_garden/patio', 0.0018078764780611746),\n",
       " ('with_terrace', 0.001759014951627089),\n",
       " ('with_swimming_pool', 0.0016612918987589172),\n",
       " ('with_high_speed_internet', 0.0015635688458907457),\n",
       " ('with_balcony', 0.0015147073194566598),\n",
       " ('with_wheelchair_access', 0.001465845793022574),\n",
       " ('with_loft', 0.001465845793022574),\n",
       " ('with_multi_level', 0.001465845793022574),\n",
       " ('with_garage', 0.000977230528681716),\n",
       " ('with_high_ceiling', 0.0008795074758135445),\n",
       " ('with_outdoor_areas', 0.0008306459493794586),\n",
       " ('with_prewar', 0.0007817844229453728),\n",
       " ('with_dryer_in_unit', 0.000732922896511287),\n",
       " ('with_short_term_allowed', 0.000732922896511287),\n",
       " ('with_storage', 0.0006840613700772012),\n",
       " ('with_renovated', 0.0006351998436431155),\n",
       " ('with_fireplace', 0.0005374767907749438),\n",
       " ('with_stainless_steel_appliances', 0.0005374767907749438),\n",
       " ('with_on_site_laundry', 0.0005374767907749438),\n",
       " ('with_duplex', 0.0005374767907749438),\n",
       " ('with_walk_in_closet(s)', 0.00043975373790677223),\n",
       " ('with_view', 0.0003908922114726864),\n",
       " ('with_newly_renovated', 0.0003908922114726864),\n",
       " ('with_common_parking/garage', 0.0003908922114726864),\n",
       " ('with_green_building', 0.0003908922114726864),\n",
       " ('with_residents_lounge', 0.0003908922114726864),\n",
       " ('with_granite_kitchen', 0.0003908922114726864),\n",
       " ('with_high_ceilings', 0.0003908922114726864),\n",
       " ('with_on_site_garage', 0.0003420306850386006),\n",
       " ('with_light', 0.0002931691586045148),\n",
       " ('with_concierge', 0.0002931691586045148),\n",
       " ('with_subway', 0.000244307632170429),\n",
       " ('with_publicoutdoor', 0.000244307632170429),\n",
       " ('with_central_a/c', 0.000244307632170429),\n",
       " ('with_roofdeck', 0.000244307632170429),\n",
       " ('with_laundry_room', 0.000244307632170429),\n",
       " ('with_pets_on_approval', 0.000244307632170429),\n",
       " ('with_no_pets', 0.0001954461057363432),\n",
       " ('with_lounge', 0.0001954461057363432),\n",
       " ('with_pool', 0.0001954461057363432),\n",
       " ('with_live_in_super', 0.0001465845793022574),\n",
       " ('with_laundry', 0.0001465845793022574),\n",
       " ('with_valet', 0.0001465845793022574),\n",
       " ('with_lowrise', 0.0001465845793022574),\n",
       " ('with_bike_room', 0.0001465845793022574),\n",
       " ('with_eat_in_kitchen', 0.0001465845793022574),\n",
       " ('with_parking', 0.0001465845793022574),\n",
       " ('with_washer/dryer', 0.0001465845793022574),\n",
       " ('with_private_balcony', 9.77230528681716e-05),\n",
       " ('with_washer_in_unit', 9.77230528681716e-05),\n",
       " ('with_live_in_superintendent', 9.77230528681716e-05),\n",
       " ('with_patio', 9.77230528681716e-05),\n",
       " ('with_marble_bath', 4.88615264340858e-05),\n",
       " ('with_exposed_brick', 4.88615264340858e-05),\n",
       " ('with_gym', 4.88615264340858e-05),\n",
       " ('with_childrens_playroom', 4.88615264340858e-05),\n",
       " ('with_common_roof_deck', 4.88615264340858e-05),\n",
       " ('with_highrise', 4.88615264340858e-05)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ananlysis by the feature importance by weight\n",
    "weight = model.get_score()\n",
    "weight_list = []\n",
    "total = sum(weight.values())\n",
    "for key in weight:\n",
    "    weight[key] = weight[key]*1.0/total\n",
    "    weight_list.append((key,weight[key]))\n",
    "sorted(weight_list,key = lambda x:x[1],reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('latitude', 0.0836509332551549),\n",
       " ('price', 0.07954656503469168),\n",
       " ('listing_id', 0.07529561223492622),\n",
       " ('longitude', 0.07456268933841494),\n",
       " ('price_per_room', 0.07358545880973322),\n",
       " ('manager_skill', 0.058731554773771136),\n",
       " ('num_description_words', 0.05511580181764878),\n",
       " ('price_per_bed', 0.047982018958272254),\n",
       " ('manager_id', 0.039968728623082185),\n",
       " ('building_id', 0.035424606664712206),\n",
       " ('street_name', 0.03488712987393726),\n",
       " ('created_hour', 0.03263949965796931),\n",
       " ('created_day', 0.03073390012703997),\n",
       " ('num_photos', 0.030440730968435453),\n",
       " ('display_address', 0.029463500439753737),\n",
       " ('num_features', 0.026238639695104076),\n",
       " ('street_address', 0.018518518518518517),\n",
       " ('with_no_fee', 0.011482458712010164),\n",
       " ('bedrooms', 0.010212059024723932),\n",
       " ('bathrooms', 0.00952799765464673),\n",
       " ('hcc_building_id_high', 0.00943027460177856),\n",
       " ('hcc_manager_id_medium', 0.008550767125965015),\n",
       " ('bath_per_bed', 0.008355321020228672),\n",
       " ('hcc_manager_id_high', 0.008013290335190071),\n",
       " ('hcc_building_id_medium', 0.007671259650151471),\n",
       " ('with_furnished', 0.006058829277826639),\n",
       " ('with_hardwood_floors', 0.004446398905501808),\n",
       " ('with_laundry_in_building', 0.0042509527997654645),\n",
       " ('with_pre_war', 0.004202091273331379),\n",
       " ('with_cats_allowed', 0.003664614482556435),\n",
       " ('with_laundry_in_unit', 0.0035668914296882633),\n",
       " ('with_exclusive', 0.003420306850386006),\n",
       " ('with_dogs_allowed', 0.0030782761653474055),\n",
       " ('with_reduced_fee', 0.0030294146389133196),\n",
       " ('with_common_outdoor_space', 0.0030294146389133196),\n",
       " ('with_doorman', 0.002931691586045148),\n",
       " ('with_dishwasher', 0.002882830059611062),\n",
       " ('with_fitness_center', 0.002540799374572462),\n",
       " ('created_month', 0.002540799374572462),\n",
       " ('with_simplex', 0.0022476302159679467),\n",
       " ('with_roof_deck', 0.0021987686895338612),\n",
       " ('with_outdoor_space', 0.0021987686895338612),\n",
       " ('with_actual_apt._photos', 0.0021987686895338612),\n",
       " ('with_dining_room', 0.0021010456366656895),\n",
       " ('with_private_outdoor_space', 0.0021010456366656895),\n",
       " ('with_hardwood', 0.0021010456366656895),\n",
       " ('with_new_construction', 0.0020521841102316037),\n",
       " ('with_parking_space', 0.0020521841102316037),\n",
       " ('with_elevator', 0.001954461057363432),\n",
       " ('with_garden/patio', 0.0018078764780611746),\n",
       " ('with_terrace', 0.001759014951627089),\n",
       " ('with_swimming_pool', 0.0016612918987589172),\n",
       " ('with_high_speed_internet', 0.0015635688458907457),\n",
       " ('with_balcony', 0.0015147073194566598),\n",
       " ('with_wheelchair_access', 0.001465845793022574),\n",
       " ('with_loft', 0.001465845793022574),\n",
       " ('with_multi_level', 0.001465845793022574),\n",
       " ('with_garage', 0.000977230528681716),\n",
       " ('with_high_ceiling', 0.0008795074758135445),\n",
       " ('with_outdoor_areas', 0.0008306459493794586),\n",
       " ('with_prewar', 0.0007817844229453728),\n",
       " ('with_dryer_in_unit', 0.000732922896511287),\n",
       " ('with_short_term_allowed', 0.000732922896511287),\n",
       " ('with_storage', 0.0006840613700772012),\n",
       " ('with_renovated', 0.0006351998436431155),\n",
       " ('with_fireplace', 0.0005374767907749438),\n",
       " ('with_stainless_steel_appliances', 0.0005374767907749438),\n",
       " ('with_on_site_laundry', 0.0005374767907749438),\n",
       " ('with_duplex', 0.0005374767907749438),\n",
       " ('with_walk_in_closet(s)', 0.00043975373790677223),\n",
       " ('with_view', 0.0003908922114726864),\n",
       " ('with_newly_renovated', 0.0003908922114726864),\n",
       " ('with_common_parking/garage', 0.0003908922114726864),\n",
       " ('with_green_building', 0.0003908922114726864),\n",
       " ('with_residents_lounge', 0.0003908922114726864),\n",
       " ('with_granite_kitchen', 0.0003908922114726864),\n",
       " ('with_high_ceilings', 0.0003908922114726864),\n",
       " ('with_on_site_garage', 0.0003420306850386006),\n",
       " ('with_light', 0.0002931691586045148),\n",
       " ('with_concierge', 0.0002931691586045148),\n",
       " ('with_subway', 0.000244307632170429),\n",
       " ('with_publicoutdoor', 0.000244307632170429),\n",
       " ('with_central_a/c', 0.000244307632170429),\n",
       " ('with_roofdeck', 0.000244307632170429),\n",
       " ('with_laundry_room', 0.000244307632170429),\n",
       " ('with_pets_on_approval', 0.000244307632170429),\n",
       " ('with_no_pets', 0.0001954461057363432),\n",
       " ('with_lounge', 0.0001954461057363432),\n",
       " ('with_pool', 0.0001954461057363432),\n",
       " ('with_live_in_super', 0.0001465845793022574),\n",
       " ('with_laundry', 0.0001465845793022574),\n",
       " ('with_valet', 0.0001465845793022574),\n",
       " ('with_lowrise', 0.0001465845793022574),\n",
       " ('with_bike_room', 0.0001465845793022574),\n",
       " ('with_eat_in_kitchen', 0.0001465845793022574),\n",
       " ('with_parking', 0.0001465845793022574),\n",
       " ('with_washer/dryer', 0.0001465845793022574),\n",
       " ('with_private_balcony', 9.77230528681716e-05),\n",
       " ('with_washer_in_unit', 9.77230528681716e-05),\n",
       " ('with_live_in_superintendent', 9.77230528681716e-05),\n",
       " ('with_patio', 9.77230528681716e-05),\n",
       " ('with_marble_bath', 4.88615264340858e-05),\n",
       " ('with_exposed_brick', 4.88615264340858e-05),\n",
       " ('with_gym', 4.88615264340858e-05),\n",
       " ('with_childrens_playroom', 4.88615264340858e-05),\n",
       " ('with_common_roof_deck', 4.88615264340858e-05),\n",
       " ('with_highrise', 4.88615264340858e-05)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ananlysis by the feature importance by gain\n",
    "gain = model.get_score(importance_type='gain')\n",
    "gain_list = []\n",
    "total = sum(gain.values())\n",
    "for key in gain:\n",
    "    gain[key] = gain[key]*1.0/total\n",
    "    gain_list.append((key,weight[key]))\n",
    "sorted(gain_list,key = lambda x:x[1],reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bathrooms': 0.15003324661763429,\n",
       " 'bedrooms': 0.11847222747849985,\n",
       " 'building_id': 0.05966144646752775,\n",
       " 'created_day': 0.027908091350767217,\n",
       " 'created_hour': 0.04913703475375256,\n",
       " 'created_month': 0.015463921187964249,\n",
       " 'display_address': 0.051917534421511584,\n",
       " 'latitude': 0.062329192852910546,\n",
       " 'listing_id': 0.05823796559748455,\n",
       " 'longitude': 0.05796867229011468,\n",
       " 'manager_id': 0.0658834209429622,\n",
       " 'num_description_words': 0.04385875263322271,\n",
       " 'num_features': 0.05493240649113651,\n",
       " 'num_photos': 0.053803480057786596,\n",
       " 'price': 0.07955324745771991,\n",
       " 'street_address': 0.050839359399004566}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ananlysis by the feature importance by coverage\n",
    "cover = model.get_score(importance_type='cover')\n",
    "total = sum(cover.values())\n",
    "for key in cover:\n",
    "    cover[key] = cover[key]*1.0/total\n",
    "cover"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
