{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn import  preprocessing, ensemble\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.cross_validation import KFold\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#try xgboost\n",
    "#fucntion from SRK\n",
    "def runXGB(train_X, train_y, test_X, test_y=None, feature_names=None, seed_val=0, num_rounds=10000):\n",
    "    param = {}\n",
    "    param['objective'] = 'multi:softprob'\n",
    "    param['eta'] = 0.1\n",
    "    param['max_depth'] = 6\n",
    "    param['silent'] = 1\n",
    "    param['num_class'] = 3\n",
    "    param['eval_metric'] = \"mlogloss\"\n",
    "    param['min_child_weight'] = 1\n",
    "    param['subsample'] = 0.7\n",
    "    param['colsample_bytree'] = 0.7\n",
    "    param['seed'] = seed_val\n",
    "    num_rounds = num_rounds\n",
    "\n",
    "    plst = list(param.items())\n",
    "    xgtrain = xgb.DMatrix(train_X, label=train_y,feature_names=feature_names)\n",
    "\n",
    "    if test_y is not None:\n",
    "        xgtest = xgb.DMatrix(test_X, label=test_y,feature_names=feature_names)\n",
    "        watchlist = [ (xgtrain,'train'), (xgtest, 'test') ]\n",
    "        model = xgb.train(plst, xgtrain, num_rounds, watchlist, early_stopping_rounds=100)\n",
    "    else:\n",
    "        xgtest = xgb.DMatrix(test_X,feature_names=feature_names)\n",
    "        model = xgb.train(plst, xgtrain, num_rounds)\n",
    "\n",
    "    pred_test_y = model.predict(xgtest)\n",
    "    return pred_test_y, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#feature processing functions\n",
    "#define punctutaion filter\n",
    "def removePunctuation(x):\n",
    "    #filter the head or tail blanks\n",
    "    x = re.sub(r'^\\s+',r' ',x)\n",
    "    x = re.sub(r'\\s+$',r' ',x)\n",
    "    \n",
    "    # Lowercasing all words\n",
    "    x = x.lower()\n",
    "    # Removing non ASCII chars, warning if you are dealing with other languages!!!!!!!!!!!!!!!\n",
    "    x = re.sub(r'[^\\x00-\\x7f]',r' ',x)\n",
    "    #change all the blank to space\n",
    "    x = re.sub(r'\\s',r' ',x)\n",
    "    # Removing (replacing with empty spaces actually) all the punctuations\n",
    "    removing = string.punctuation#.replace('-','')# except '-'\n",
    "    removed = re.sub(\"[\"+removing+\"]\", \"\", x)\n",
    "    #removing the line-changing\n",
    "    #removed = re.sub('\\\\n',\" \",removed)    \n",
    "    return removed\n",
    "\n",
    "#feature processing functions\n",
    "def proecessStreet(address):\n",
    "    #remove the building number\n",
    "    pattern = re.compile('^[\\d-]*[\\s]+')\n",
    "    street = removePunctuation(pattern.sub('',address))\n",
    "    #sub the st to street\n",
    "    pattern = re.compile('( st)$')\n",
    "    street = pattern.sub(' street',street)\n",
    "    #sub the ave to avenue\n",
    "    pattern = re.compile('( ave)$')\n",
    "    street = pattern.sub(' avenue',street)\n",
    "    #nth -> n\n",
    "    #nst -> n\n",
    "    #nrd -> n\n",
    "    #nnd -> n\n",
    "    pattern = re.compile('(\\d+)((th)|(st)|(rd)|(nd))')\n",
    "    street = pattern.sub('\\g<1>',street)\n",
    "    #deal with the w 14 street => west 14 street\n",
    "    pattern = re.compile('(w)(\\s+)(\\d+)')    \n",
    "    street = pattern.sub('west \\g<3>',street)\n",
    "    #deal with the e....\n",
    "    pattern = re.compile('(e)(\\s+)(\\d+)')    \n",
    "    street = pattern.sub('east \\g<3>',street)\n",
    "    \n",
    "\n",
    "    return street\n",
    "    \n",
    "def getStreetNumber(address):\n",
    "    #get building id in the front, return -1 if their isn't\n",
    "    pattern = re.compile('^([\\d-]*)([\\s]+)')\n",
    "    try:\n",
    "        number = pattern.search(address).group(1)\n",
    "        return int(number)\n",
    "    except:\n",
    "        return -1\n",
    "\n",
    "#from \"this is a lit\"s python version by rakhlin\n",
    "def singleValueConvert(df1,df2,column,minimum_size=5):\n",
    "    ps = df1[column].append(df2[column])\n",
    "    grouped = ps.groupby(ps).size().to_frame().rename(columns={0: \"size\"})\n",
    "    df1.loc[df1.join(grouped, on=column, how=\"left\")[\"size\"] <= minimum_size, column] = -1\n",
    "    df2.loc[df2.join(grouped, on=column, how=\"left\")[\"size\"] <= minimum_size, column] = -1\n",
    "    return df1, df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def manager_skill_eval(train_df,test_df,unrank_threshold = 10):\n",
    "\n",
    "    target_num_map = {'High':2, 'Medium':1, 'Low':0}\n",
    "    temp=pd.concat([train_df.manager_id,pd.get_dummies(train_df.interest_level)], axis = 1).groupby('manager_id').mean()\n",
    "     \n",
    "    temp.columns = ['ManHigh','ManLow', 'ManMedium']\n",
    "    \n",
    "    print temp.columns\n",
    "    temp['count'] = train_df.groupby('manager_id').count().iloc[:,1]\n",
    "    \n",
    "    temp['manager_skill'] = temp['ManHigh']*2 + temp['ManMedium']\n",
    "    \n",
    "    #ixes of the managers with to few sample\n",
    "    unranked_managers_ixes = temp['count']<unrank_threshold\n",
    "    ranked_managers_ixes = ~unranked_managers_ixes\n",
    "    \n",
    "    #test for using rank or unrank part for the filling values\n",
    "    mean_values = temp.loc[unranked_managers_ixes, ['ManHigh','ManLow', 'ManMedium','manager_skill']].mean()\n",
    "    mean_values_total = temp.loc[:, ['ManHigh','ManLow', 'ManMedium','manager_skill']].mean()\n",
    "    \n",
    "    #reset their values to their average\n",
    "    temp.loc[unranked_managers_ixes,['ManHigh','ManLow', 'ManMedium','manager_skill']] = mean_values.values\n",
    "    \n",
    "    #assign the features for the train set\n",
    "    new_train_df = train_df.merge(temp.reset_index(),how='left', left_on='manager_id', right_on='manager_id')\n",
    "    \n",
    "    #assign the features for the test/val set\n",
    "    new_test_df = test_df.merge(temp.reset_index(),how='left', left_on='manager_id', right_on='manager_id')\n",
    "    new_manager_ixes = new_test_df['ManHigh'].isnull()\n",
    "    new_test_df.loc[new_manager_ixes,['ManHigh','ManLow', 'ManMedium','manager_skill']] = mean_values_total.values           \n",
    "    \n",
    "    return new_train_df,new_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#encoded by sorted value\n",
    "def hcc_sorting(train_df,test_df,feature,label=None,randomize=None):\n",
    "    \"\"\"\n",
    "    sort the hcc feature by their prior on label then encode\n",
    "    the train df should be with its labels get dummied\n",
    "    \n",
    "    return the list of all the possible features in order\n",
    "    \"\"\"\n",
    "    if label ==None:\n",
    "        train_df['tempScore'] = 2*train_df['high']+train_df['medium']\n",
    "        label = 'tempScore'\n",
    "    #get dummies for the \n",
    "    grouped  = train_df.groupby(feature)[label].agg({'size':'size','mean':'mean'})\n",
    "    #unrankedMean = grouped.ix[grouped['size']<unrank_threshold,'mean'].mean()\n",
    "    #grouped.ix[grouped['size']<unrank_threshold,'mean'] = unrankedMean\n",
    "    grouped = grouped.reset_index()\n",
    "\n",
    "    #get the values for the test set\n",
    "    test_groupBy=test_df[feature].value_counts().to_frame().reset_index()\n",
    "    test_groupBy.columns = [feature,'testSize']\n",
    "\n",
    "    #merge together and reset the mean\n",
    "    totalFeature = grouped.merge(test_groupBy,on = feature, how='outer').fillna(0)\n",
    "\n",
    "    rankedMean = np.mean(grouped['mean'])\n",
    "\n",
    "    #reset those train size 0 to the ranked mean\n",
    "    totalFeature.ix[totalFeature['size']==0,'mean']=rankedMean\n",
    "    \n",
    "    #add some random \n",
    "    if randomize : \n",
    "        totalFeature['mean'] *= np.random.uniform(1 - randomize, 1 + randomize, len(totalFeature))\n",
    "\n",
    "    return list(totalFeature.sort('mean')[feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49352, 15)\n",
      "(74659, 14)\n"
     ]
    }
   ],
   "source": [
    "#lodaing data\n",
    "data_path = \"../../kaggleData/2sigma/\"\n",
    "train_file = data_path + \"train.json\"\n",
    "test_file = data_path + \"test.json\"\n",
    "train_df = pd.read_json(train_file)\n",
    "test_df = pd.read_json(test_file)\n",
    "print(train_df.shape)\n",
    "print(test_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#basic numerical features\n",
    "features_to_use  = [\"bathrooms\", \"bedrooms\", \"latitude\", \"longitude\", \"price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#some new numerical features related to the price\n",
    "train_df[\"price_per_bath\"] =  train_df[\"price\"]*1.0/train_df[\"bathrooms\"]\n",
    "train_df[\"price_per_bed\"] = train_df[\"price\"]*1.0/train_df[\"bedrooms\"]\n",
    "train_df[\"bath_per_bed\"] = train_df[\"bathrooms\"]*1.0/train_df[\"bedrooms\"]\n",
    "train_df[\"price_per_room\"] = train_df[\"price\"]*1.0/(train_df[\"bedrooms\"]+train_df[\"bathrooms\"])\n",
    "\n",
    "test_df[\"price_per_bath\"] =  test_df[\"price\"]*1.0/test_df[\"bathrooms\"]\n",
    "test_df[\"price_per_bed\"] = test_df[\"price\"]*1.0/test_df[\"bedrooms\"]\n",
    "test_df[\"bath_per_bed\"] = test_df[\"bathrooms\"]*1.0/test_df[\"bedrooms\"]\n",
    "test_df[\"price_per_room\"] = test_df[\"price\"]*1.0/(test_df[\"bedrooms\"]+test_df[\"bathrooms\"])\n",
    "\n",
    "features_to_use.extend([\"price_per_bed\",\"bath_per_bed\",\"price_per_room\"])\n",
    "#features_to_use.append('price_per_bed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#some transfromed features\n",
    "# count of photos #\n",
    "train_df[\"num_photos\"] = train_df[\"photos\"].apply(len)\n",
    "test_df[\"num_photos\"] = test_df[\"photos\"].apply(len)\n",
    "\n",
    "# count of \"features\" #\n",
    "train_df[\"num_features\"] = train_df[\"features\"].apply(len)\n",
    "test_df[\"num_features\"] = test_df[\"features\"].apply(len)\n",
    "\n",
    "# count of words present in description column #\n",
    "train_df[\"num_description_words\"] = train_df[\"description\"].apply(lambda x: len(x.split(\" \")))\n",
    "test_df[\"num_description_words\"] = test_df[\"description\"].apply(lambda x: len(x.split(\" \")))\n",
    "\n",
    "# convert the created column to datetime object so as to extract more features \n",
    "train_df[\"created\"] = pd.to_datetime(train_df[\"created\"])\n",
    "test_df[\"created\"] = pd.to_datetime(test_df[\"created\"])\n",
    "\n",
    "# Let us extract some features like year, month, day, hour from date columns #\n",
    "train_df[\"created_year\"] = train_df[\"created\"].dt.year\n",
    "test_df[\"created_year\"] = test_df[\"created\"].dt.year\n",
    "train_df[\"created_month\"] = train_df[\"created\"].dt.month\n",
    "test_df[\"created_month\"] = test_df[\"created\"].dt.month\n",
    "train_df[\"created_day\"] = train_df[\"created\"].dt.day\n",
    "test_df[\"created_day\"] = test_df[\"created\"].dt.day\n",
    "train_df[\"created_hour\"] = train_df[\"created\"].dt.hour\n",
    "test_df[\"created_hour\"] = test_df[\"created\"].dt.hour\n",
    "\n",
    "\n",
    "\n",
    "# adding all these new features to use list # \"listing_id\",\n",
    "features_to_use.extend([\"num_photos\", \"num_features\", \"num_description_words\",\"created_year\",\"listing_id\", \"created_month\", \"created_day\", \"created_hour\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#adding the street names\n",
    "train_df[\"street_name\"] = train_df[\"street_address\"].apply(proecessStreet)\n",
    "test_df[\"street_name\"] = test_df[\"street_address\"].apply(proecessStreet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:34: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n"
     ]
    }
   ],
   "source": [
    "#dealing feature with categorical features \n",
    "\"\"\"\n",
    "display_address 8826    \n",
    "building_id        7585   =》many zeros in this feature\n",
    "manager_id   3481\n",
    "street_address 15358 =》will be 3800 if no numbers in it \n",
    "adding street name to categorical data\n",
    "\"\"\"\n",
    "train_df =train_df.join(pd.get_dummies(train_df[u'interest_level']).astype(int))\n",
    "temp_feature_list = []\n",
    "\n",
    "categorical = [\"display_address\", \"manager_id\", \"building_id\", \"street_address\",\"street_name\"]\n",
    "for f in categorical:\n",
    "    #fill substitute the small size values by their mean\n",
    "    train_df,test_df  = singleValueConvert(train_df,test_df,f)\n",
    "    if train_df[f].dtype=='object':\n",
    "            #print(f)\n",
    "            lbl = preprocessing.LabelEncoder()\n",
    "            \n",
    "            #encoding from the class for high\n",
    "            lbl.fit(hcc_sorting(train_df,test_df,f,label='high',randomize = 0.05))\n",
    "            train_df[f+'high'] = lbl.transform(list(train_df[f].values))\n",
    "            test_df[f+'high'] = lbl.transform(list(test_df[f].values))\n",
    "            temp_feature_list.append(f+'high')\n",
    "            \n",
    "            #encoding from the class for medium\n",
    "            lbl.fit(hcc_sorting(train_df,test_df,f,label='medium',randomize = 0.05))\n",
    "            train_df[f+'medium'] = lbl.transform(list(train_df[f].values))\n",
    "            test_df[f+'medium'] = lbl.transform(list(test_df[f].values))\n",
    "            temp_feature_list.append(f+'medium')\n",
    "            \n",
    "            #encoding from the class for low\n",
    "            lbl.fit(hcc_sorting(train_df,test_df,f,label='low',randomize = 0.05))\n",
    "            train_df[f+'low'] = lbl.transform(list(train_df[f].values))\n",
    "            test_df[f+'low'] = lbl.transform(list(test_df[f].values))\n",
    "            temp_feature_list.append(f+'low')\n",
    "            \n",
    "features_to_use.extend(temp_feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#prepare for training\n",
    "target_num_map = {'high':0, 'medium':1, 'low':2}\n",
    "\n",
    "train_y = np.array(train_df['interest_level'].apply(lambda x: target_num_map[x]))\n",
    "\n",
    "KF=KFold(len(train_df),5,shuffle=True,random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'ManHigh', u'ManLow', u'ManMedium'], dtype='object')\n",
      "[0]\ttrain-mlogloss:1.03119\ttest-mlogloss:1.03393\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 100 rounds.\n",
      "[1]\ttrain-mlogloss:0.977357\ttest-mlogloss:0.981803\n",
      "[2]\ttrain-mlogloss:0.927768\ttest-mlogloss:0.934695\n",
      "[3]\ttrain-mlogloss:0.889514\ttest-mlogloss:0.897767\n",
      "[4]\ttrain-mlogloss:0.852174\ttest-mlogloss:0.862464\n",
      "[5]\ttrain-mlogloss:0.820021\ttest-mlogloss:0.832109\n",
      "[6]\ttrain-mlogloss:0.793766\ttest-mlogloss:0.807348\n",
      "[7]\ttrain-mlogloss:0.769123\ttest-mlogloss:0.784191\n",
      "[8]\ttrain-mlogloss:0.749407\ttest-mlogloss:0.765287\n",
      "[9]\ttrain-mlogloss:0.729083\ttest-mlogloss:0.746471\n",
      "[10]\ttrain-mlogloss:0.711326\ttest-mlogloss:0.730275\n",
      "[11]\ttrain-mlogloss:0.69614\ttest-mlogloss:0.716312\n",
      "[12]\ttrain-mlogloss:0.6813\ttest-mlogloss:0.703006\n",
      "[13]\ttrain-mlogloss:0.668804\ttest-mlogloss:0.691499\n",
      "[14]\ttrain-mlogloss:0.657599\ttest-mlogloss:0.681507\n",
      "[15]\ttrain-mlogloss:0.647617\ttest-mlogloss:0.672768\n",
      "[16]\ttrain-mlogloss:0.638503\ttest-mlogloss:0.664911\n",
      "[17]\ttrain-mlogloss:0.629571\ttest-mlogloss:0.657086\n",
      "[18]\ttrain-mlogloss:0.621534\ttest-mlogloss:0.650338\n",
      "[19]\ttrain-mlogloss:0.615049\ttest-mlogloss:0.644614\n",
      "[20]\ttrain-mlogloss:0.608325\ttest-mlogloss:0.638962\n",
      "[21]\ttrain-mlogloss:0.602782\ttest-mlogloss:0.634461\n",
      "[22]\ttrain-mlogloss:0.597192\ttest-mlogloss:0.629708\n",
      "[23]\ttrain-mlogloss:0.592439\ttest-mlogloss:0.625591\n",
      "[24]\ttrain-mlogloss:0.58765\ttest-mlogloss:0.621756\n",
      "[25]\ttrain-mlogloss:0.583471\ttest-mlogloss:0.618627\n",
      "[26]\ttrain-mlogloss:0.579016\ttest-mlogloss:0.615383\n",
      "[27]\ttrain-mlogloss:0.575489\ttest-mlogloss:0.612568\n",
      "[28]\ttrain-mlogloss:0.572101\ttest-mlogloss:0.609854\n",
      "[29]\ttrain-mlogloss:0.568577\ttest-mlogloss:0.607176\n",
      "[30]\ttrain-mlogloss:0.565472\ttest-mlogloss:0.604952\n",
      "[31]\ttrain-mlogloss:0.562643\ttest-mlogloss:0.602824\n",
      "[32]\ttrain-mlogloss:0.559873\ttest-mlogloss:0.600661\n",
      "[33]\ttrain-mlogloss:0.557164\ttest-mlogloss:0.598817\n",
      "[34]\ttrain-mlogloss:0.554554\ttest-mlogloss:0.596993\n",
      "[35]\ttrain-mlogloss:0.552062\ttest-mlogloss:0.59516\n",
      "[36]\ttrain-mlogloss:0.549826\ttest-mlogloss:0.593875\n",
      "[37]\ttrain-mlogloss:0.547719\ttest-mlogloss:0.592596\n",
      "[38]\ttrain-mlogloss:0.545518\ttest-mlogloss:0.591109\n",
      "[39]\ttrain-mlogloss:0.543667\ttest-mlogloss:0.58999\n",
      "[40]\ttrain-mlogloss:0.541893\ttest-mlogloss:0.588843\n",
      "[41]\ttrain-mlogloss:0.539921\ttest-mlogloss:0.587468\n",
      "[42]\ttrain-mlogloss:0.538497\ttest-mlogloss:0.586826\n",
      "[43]\ttrain-mlogloss:0.536899\ttest-mlogloss:0.585936\n",
      "[44]\ttrain-mlogloss:0.535288\ttest-mlogloss:0.585112\n",
      "[45]\ttrain-mlogloss:0.533677\ttest-mlogloss:0.584201\n",
      "[46]\ttrain-mlogloss:0.532084\ttest-mlogloss:0.583462\n",
      "[47]\ttrain-mlogloss:0.530868\ttest-mlogloss:0.582611\n",
      "[48]\ttrain-mlogloss:0.529419\ttest-mlogloss:0.581731\n",
      "[49]\ttrain-mlogloss:0.527851\ttest-mlogloss:0.58074\n",
      "[50]\ttrain-mlogloss:0.526723\ttest-mlogloss:0.579939\n",
      "[51]\ttrain-mlogloss:0.525043\ttest-mlogloss:0.579174\n",
      "[52]\ttrain-mlogloss:0.523435\ttest-mlogloss:0.578387\n",
      "[53]\ttrain-mlogloss:0.521877\ttest-mlogloss:0.577673\n",
      "[54]\ttrain-mlogloss:0.520636\ttest-mlogloss:0.577031\n",
      "[55]\ttrain-mlogloss:0.518975\ttest-mlogloss:0.576299\n",
      "[56]\ttrain-mlogloss:0.51798\ttest-mlogloss:0.575799\n",
      "[57]\ttrain-mlogloss:0.516449\ttest-mlogloss:0.575137\n",
      "[58]\ttrain-mlogloss:0.515317\ttest-mlogloss:0.574756\n",
      "[59]\ttrain-mlogloss:0.514156\ttest-mlogloss:0.574221\n",
      "[60]\ttrain-mlogloss:0.51304\ttest-mlogloss:0.573765\n",
      "[61]\ttrain-mlogloss:0.511617\ttest-mlogloss:0.573072\n",
      "[62]\ttrain-mlogloss:0.510233\ttest-mlogloss:0.572455\n",
      "[63]\ttrain-mlogloss:0.508905\ttest-mlogloss:0.57184\n",
      "[64]\ttrain-mlogloss:0.507582\ttest-mlogloss:0.571249\n",
      "[65]\ttrain-mlogloss:0.506653\ttest-mlogloss:0.570855\n",
      "[66]\ttrain-mlogloss:0.505337\ttest-mlogloss:0.570206\n",
      "[67]\ttrain-mlogloss:0.504289\ttest-mlogloss:0.569819\n",
      "[68]\ttrain-mlogloss:0.503369\ttest-mlogloss:0.569447\n",
      "[69]\ttrain-mlogloss:0.501925\ttest-mlogloss:0.56891\n",
      "[70]\ttrain-mlogloss:0.501266\ttest-mlogloss:0.568693\n",
      "[71]\ttrain-mlogloss:0.500217\ttest-mlogloss:0.568408\n",
      "[72]\ttrain-mlogloss:0.49893\ttest-mlogloss:0.567906\n",
      "[73]\ttrain-mlogloss:0.497659\ttest-mlogloss:0.567369\n",
      "[74]\ttrain-mlogloss:0.496664\ttest-mlogloss:0.566802\n",
      "[75]\ttrain-mlogloss:0.495696\ttest-mlogloss:0.56648\n",
      "[76]\ttrain-mlogloss:0.494652\ttest-mlogloss:0.566213\n",
      "[77]\ttrain-mlogloss:0.493471\ttest-mlogloss:0.565736\n",
      "[78]\ttrain-mlogloss:0.492521\ttest-mlogloss:0.565381\n",
      "[79]\ttrain-mlogloss:0.49171\ttest-mlogloss:0.565135\n",
      "[80]\ttrain-mlogloss:0.490478\ttest-mlogloss:0.564673\n",
      "[81]\ttrain-mlogloss:0.489653\ttest-mlogloss:0.564392\n",
      "[82]\ttrain-mlogloss:0.48865\ttest-mlogloss:0.563987\n",
      "[83]\ttrain-mlogloss:0.487956\ttest-mlogloss:0.563697\n",
      "[84]\ttrain-mlogloss:0.487022\ttest-mlogloss:0.563231\n",
      "[85]\ttrain-mlogloss:0.486103\ttest-mlogloss:0.563013\n",
      "[86]\ttrain-mlogloss:0.485446\ttest-mlogloss:0.562962\n",
      "[87]\ttrain-mlogloss:0.484687\ttest-mlogloss:0.562694\n",
      "[88]\ttrain-mlogloss:0.484236\ttest-mlogloss:0.562753\n",
      "[89]\ttrain-mlogloss:0.483067\ttest-mlogloss:0.562314\n",
      "[90]\ttrain-mlogloss:0.482236\ttest-mlogloss:0.562221\n",
      "[91]\ttrain-mlogloss:0.481321\ttest-mlogloss:0.561937\n",
      "[92]\ttrain-mlogloss:0.480386\ttest-mlogloss:0.561903\n",
      "[93]\ttrain-mlogloss:0.479299\ttest-mlogloss:0.561461\n",
      "[94]\ttrain-mlogloss:0.478523\ttest-mlogloss:0.561228\n",
      "[95]\ttrain-mlogloss:0.477474\ttest-mlogloss:0.561007\n",
      "[96]\ttrain-mlogloss:0.476697\ttest-mlogloss:0.56102\n",
      "[97]\ttrain-mlogloss:0.475846\ttest-mlogloss:0.56081\n",
      "[98]\ttrain-mlogloss:0.475089\ttest-mlogloss:0.560557\n",
      "[99]\ttrain-mlogloss:0.474199\ttest-mlogloss:0.56037\n",
      "[100]\ttrain-mlogloss:0.473223\ttest-mlogloss:0.560096\n",
      "[101]\ttrain-mlogloss:0.472552\ttest-mlogloss:0.559867\n",
      "[102]\ttrain-mlogloss:0.471703\ttest-mlogloss:0.559721\n",
      "[103]\ttrain-mlogloss:0.470751\ttest-mlogloss:0.559486\n",
      "[104]\ttrain-mlogloss:0.47013\ttest-mlogloss:0.559355\n",
      "[105]\ttrain-mlogloss:0.469312\ttest-mlogloss:0.559027\n",
      "[106]\ttrain-mlogloss:0.468118\ttest-mlogloss:0.558755\n",
      "[107]\ttrain-mlogloss:0.467183\ttest-mlogloss:0.558683\n",
      "[108]\ttrain-mlogloss:0.466136\ttest-mlogloss:0.558339\n",
      "[109]\ttrain-mlogloss:0.465431\ttest-mlogloss:0.55818\n",
      "[110]\ttrain-mlogloss:0.464436\ttest-mlogloss:0.55811\n",
      "[111]\ttrain-mlogloss:0.46373\ttest-mlogloss:0.557902\n",
      "[112]\ttrain-mlogloss:0.462792\ttest-mlogloss:0.557823\n",
      "[113]\ttrain-mlogloss:0.462062\ttest-mlogloss:0.55759\n",
      "[114]\ttrain-mlogloss:0.461486\ttest-mlogloss:0.557426\n",
      "[115]\ttrain-mlogloss:0.460582\ttest-mlogloss:0.557269\n",
      "[116]\ttrain-mlogloss:0.459852\ttest-mlogloss:0.55705\n",
      "[117]\ttrain-mlogloss:0.459206\ttest-mlogloss:0.556858\n",
      "[118]\ttrain-mlogloss:0.458278\ttest-mlogloss:0.556599\n",
      "[119]\ttrain-mlogloss:0.457385\ttest-mlogloss:0.556315\n",
      "[120]\ttrain-mlogloss:0.456738\ttest-mlogloss:0.556164\n",
      "[121]\ttrain-mlogloss:0.455958\ttest-mlogloss:0.55623\n",
      "[122]\ttrain-mlogloss:0.455426\ttest-mlogloss:0.556259\n",
      "[123]\ttrain-mlogloss:0.454596\ttest-mlogloss:0.556101\n",
      "[124]\ttrain-mlogloss:0.453957\ttest-mlogloss:0.5559\n",
      "[125]\ttrain-mlogloss:0.453391\ttest-mlogloss:0.555914\n",
      "[126]\ttrain-mlogloss:0.452804\ttest-mlogloss:0.555822\n",
      "[127]\ttrain-mlogloss:0.452208\ttest-mlogloss:0.555806\n",
      "[128]\ttrain-mlogloss:0.451352\ttest-mlogloss:0.555754\n",
      "[129]\ttrain-mlogloss:0.450699\ttest-mlogloss:0.555638\n",
      "[130]\ttrain-mlogloss:0.449766\ttest-mlogloss:0.555512\n",
      "[131]\ttrain-mlogloss:0.449095\ttest-mlogloss:0.555325\n",
      "[132]\ttrain-mlogloss:0.448517\ttest-mlogloss:0.555194\n",
      "[133]\ttrain-mlogloss:0.447528\ttest-mlogloss:0.555163\n",
      "[134]\ttrain-mlogloss:0.446937\ttest-mlogloss:0.555133\n",
      "[135]\ttrain-mlogloss:0.446244\ttest-mlogloss:0.555085\n",
      "[136]\ttrain-mlogloss:0.445595\ttest-mlogloss:0.555075\n",
      "[137]\ttrain-mlogloss:0.444876\ttest-mlogloss:0.554907\n",
      "[138]\ttrain-mlogloss:0.444323\ttest-mlogloss:0.554807\n",
      "[139]\ttrain-mlogloss:0.443519\ttest-mlogloss:0.554868\n",
      "[140]\ttrain-mlogloss:0.442862\ttest-mlogloss:0.554615\n",
      "[141]\ttrain-mlogloss:0.442056\ttest-mlogloss:0.554479\n",
      "[142]\ttrain-mlogloss:0.441196\ttest-mlogloss:0.554519\n",
      "[143]\ttrain-mlogloss:0.440419\ttest-mlogloss:0.554353\n",
      "[144]\ttrain-mlogloss:0.439857\ttest-mlogloss:0.554381\n",
      "[145]\ttrain-mlogloss:0.439328\ttest-mlogloss:0.554159\n",
      "[146]\ttrain-mlogloss:0.4387\ttest-mlogloss:0.554154\n",
      "[147]\ttrain-mlogloss:0.438137\ttest-mlogloss:0.553995\n",
      "[148]\ttrain-mlogloss:0.437597\ttest-mlogloss:0.553861\n",
      "[149]\ttrain-mlogloss:0.436846\ttest-mlogloss:0.553766\n",
      "[150]\ttrain-mlogloss:0.436247\ttest-mlogloss:0.553842\n",
      "[151]\ttrain-mlogloss:0.435713\ttest-mlogloss:0.553913\n",
      "[152]\ttrain-mlogloss:0.435159\ttest-mlogloss:0.553822\n",
      "[153]\ttrain-mlogloss:0.434512\ttest-mlogloss:0.5536\n",
      "[154]\ttrain-mlogloss:0.433793\ttest-mlogloss:0.553681\n",
      "[155]\ttrain-mlogloss:0.433097\ttest-mlogloss:0.55355\n",
      "[156]\ttrain-mlogloss:0.432177\ttest-mlogloss:0.553445\n",
      "[157]\ttrain-mlogloss:0.431302\ttest-mlogloss:0.553168\n",
      "[158]\ttrain-mlogloss:0.430623\ttest-mlogloss:0.553121\n",
      "[159]\ttrain-mlogloss:0.429903\ttest-mlogloss:0.552977\n",
      "[160]\ttrain-mlogloss:0.429285\ttest-mlogloss:0.552902\n",
      "[161]\ttrain-mlogloss:0.428653\ttest-mlogloss:0.552905\n",
      "[162]\ttrain-mlogloss:0.427983\ttest-mlogloss:0.55275\n",
      "[163]\ttrain-mlogloss:0.427246\ttest-mlogloss:0.552707\n",
      "[164]\ttrain-mlogloss:0.426779\ttest-mlogloss:0.552716\n",
      "[165]\ttrain-mlogloss:0.426113\ttest-mlogloss:0.552561\n",
      "[166]\ttrain-mlogloss:0.425519\ttest-mlogloss:0.552457\n",
      "[167]\ttrain-mlogloss:0.424713\ttest-mlogloss:0.552404\n",
      "[168]\ttrain-mlogloss:0.424201\ttest-mlogloss:0.552367\n",
      "[169]\ttrain-mlogloss:0.423563\ttest-mlogloss:0.55221\n",
      "[170]\ttrain-mlogloss:0.423063\ttest-mlogloss:0.552175\n",
      "[171]\ttrain-mlogloss:0.422378\ttest-mlogloss:0.552199\n",
      "[172]\ttrain-mlogloss:0.421719\ttest-mlogloss:0.552108\n",
      "[173]\ttrain-mlogloss:0.421032\ttest-mlogloss:0.551981\n",
      "[174]\ttrain-mlogloss:0.420377\ttest-mlogloss:0.551923\n",
      "[175]\ttrain-mlogloss:0.419984\ttest-mlogloss:0.551914\n",
      "[176]\ttrain-mlogloss:0.419355\ttest-mlogloss:0.551796\n",
      "[177]\ttrain-mlogloss:0.418616\ttest-mlogloss:0.551791\n",
      "[178]\ttrain-mlogloss:0.418108\ttest-mlogloss:0.551814\n",
      "[179]\ttrain-mlogloss:0.41751\ttest-mlogloss:0.551829\n",
      "[180]\ttrain-mlogloss:0.416989\ttest-mlogloss:0.551761\n",
      "[181]\ttrain-mlogloss:0.416206\ttest-mlogloss:0.551741\n",
      "[182]\ttrain-mlogloss:0.41554\ttest-mlogloss:0.55169\n",
      "[183]\ttrain-mlogloss:0.415055\ttest-mlogloss:0.55162\n",
      "[184]\ttrain-mlogloss:0.41437\ttest-mlogloss:0.551521\n",
      "[185]\ttrain-mlogloss:0.413624\ttest-mlogloss:0.551334\n",
      "[186]\ttrain-mlogloss:0.413152\ttest-mlogloss:0.551439\n",
      "[187]\ttrain-mlogloss:0.412585\ttest-mlogloss:0.55138\n",
      "[188]\ttrain-mlogloss:0.411893\ttest-mlogloss:0.551216\n",
      "[189]\ttrain-mlogloss:0.411309\ttest-mlogloss:0.551041\n",
      "[190]\ttrain-mlogloss:0.410678\ttest-mlogloss:0.550954\n",
      "[191]\ttrain-mlogloss:0.4103\ttest-mlogloss:0.55102\n",
      "[192]\ttrain-mlogloss:0.409774\ttest-mlogloss:0.550949\n",
      "[193]\ttrain-mlogloss:0.409296\ttest-mlogloss:0.550828\n",
      "[194]\ttrain-mlogloss:0.40857\ttest-mlogloss:0.550889\n",
      "[195]\ttrain-mlogloss:0.408024\ttest-mlogloss:0.550806\n",
      "[196]\ttrain-mlogloss:0.407353\ttest-mlogloss:0.550587\n",
      "[197]\ttrain-mlogloss:0.40671\ttest-mlogloss:0.550521\n",
      "[198]\ttrain-mlogloss:0.406323\ttest-mlogloss:0.550507\n",
      "[199]\ttrain-mlogloss:0.405868\ttest-mlogloss:0.550564\n",
      "[200]\ttrain-mlogloss:0.405467\ttest-mlogloss:0.55057\n",
      "[201]\ttrain-mlogloss:0.404922\ttest-mlogloss:0.550544\n",
      "[202]\ttrain-mlogloss:0.40445\ttest-mlogloss:0.550455\n",
      "[203]\ttrain-mlogloss:0.403789\ttest-mlogloss:0.550464\n",
      "[204]\ttrain-mlogloss:0.403239\ttest-mlogloss:0.550311\n",
      "[205]\ttrain-mlogloss:0.402749\ttest-mlogloss:0.550256\n",
      "[206]\ttrain-mlogloss:0.402189\ttest-mlogloss:0.550257\n",
      "[207]\ttrain-mlogloss:0.401591\ttest-mlogloss:0.550313\n",
      "[208]\ttrain-mlogloss:0.401193\ttest-mlogloss:0.550306\n",
      "[209]\ttrain-mlogloss:0.400824\ttest-mlogloss:0.550174\n",
      "[210]\ttrain-mlogloss:0.400325\ttest-mlogloss:0.550154\n",
      "[211]\ttrain-mlogloss:0.399796\ttest-mlogloss:0.550037\n",
      "[212]\ttrain-mlogloss:0.399283\ttest-mlogloss:0.549962\n",
      "[213]\ttrain-mlogloss:0.398631\ttest-mlogloss:0.549835\n",
      "[214]\ttrain-mlogloss:0.398048\ttest-mlogloss:0.54983\n",
      "[215]\ttrain-mlogloss:0.397419\ttest-mlogloss:0.549787\n",
      "[216]\ttrain-mlogloss:0.39689\ttest-mlogloss:0.549802\n",
      "[217]\ttrain-mlogloss:0.396477\ttest-mlogloss:0.549776\n",
      "[218]\ttrain-mlogloss:0.396031\ttest-mlogloss:0.549802\n",
      "[219]\ttrain-mlogloss:0.395526\ttest-mlogloss:0.549827\n",
      "[220]\ttrain-mlogloss:0.394988\ttest-mlogloss:0.549811\n",
      "[221]\ttrain-mlogloss:0.394635\ttest-mlogloss:0.549891\n",
      "[222]\ttrain-mlogloss:0.394025\ttest-mlogloss:0.549776\n",
      "[223]\ttrain-mlogloss:0.393373\ttest-mlogloss:0.549751\n",
      "[224]\ttrain-mlogloss:0.392705\ttest-mlogloss:0.54974\n",
      "[225]\ttrain-mlogloss:0.392244\ttest-mlogloss:0.549638\n",
      "[226]\ttrain-mlogloss:0.391506\ttest-mlogloss:0.549694\n",
      "[227]\ttrain-mlogloss:0.391012\ttest-mlogloss:0.549628\n",
      "[228]\ttrain-mlogloss:0.390636\ttest-mlogloss:0.549591\n",
      "[229]\ttrain-mlogloss:0.390191\ttest-mlogloss:0.549658\n",
      "[230]\ttrain-mlogloss:0.389619\ttest-mlogloss:0.549637\n",
      "[231]\ttrain-mlogloss:0.389284\ttest-mlogloss:0.549706\n",
      "[232]\ttrain-mlogloss:0.388573\ttest-mlogloss:0.549607\n",
      "[233]\ttrain-mlogloss:0.388221\ttest-mlogloss:0.549606\n",
      "[234]\ttrain-mlogloss:0.387743\ttest-mlogloss:0.54947\n",
      "[235]\ttrain-mlogloss:0.387063\ttest-mlogloss:0.549363\n",
      "[236]\ttrain-mlogloss:0.386397\ttest-mlogloss:0.549426\n",
      "[237]\ttrain-mlogloss:0.385794\ttest-mlogloss:0.549447\n",
      "[238]\ttrain-mlogloss:0.385199\ttest-mlogloss:0.549444\n",
      "[239]\ttrain-mlogloss:0.384738\ttest-mlogloss:0.549373\n",
      "[240]\ttrain-mlogloss:0.384307\ttest-mlogloss:0.549348\n",
      "[241]\ttrain-mlogloss:0.383839\ttest-mlogloss:0.54929\n",
      "[242]\ttrain-mlogloss:0.383379\ttest-mlogloss:0.549332\n",
      "[243]\ttrain-mlogloss:0.382859\ttest-mlogloss:0.549344\n",
      "[244]\ttrain-mlogloss:0.382138\ttest-mlogloss:0.549202\n",
      "[245]\ttrain-mlogloss:0.381831\ttest-mlogloss:0.549204\n",
      "[246]\ttrain-mlogloss:0.381286\ttest-mlogloss:0.549072\n",
      "[247]\ttrain-mlogloss:0.38094\ttest-mlogloss:0.549127\n",
      "[248]\ttrain-mlogloss:0.380475\ttest-mlogloss:0.549089\n",
      "[249]\ttrain-mlogloss:0.379836\ttest-mlogloss:0.549078\n",
      "[250]\ttrain-mlogloss:0.379339\ttest-mlogloss:0.549111\n",
      "[251]\ttrain-mlogloss:0.37905\ttest-mlogloss:0.548997\n",
      "[252]\ttrain-mlogloss:0.378495\ttest-mlogloss:0.548959\n",
      "[253]\ttrain-mlogloss:0.378095\ttest-mlogloss:0.549012\n",
      "[254]\ttrain-mlogloss:0.37768\ttest-mlogloss:0.549058\n",
      "[255]\ttrain-mlogloss:0.377183\ttest-mlogloss:0.549058\n",
      "[256]\ttrain-mlogloss:0.376613\ttest-mlogloss:0.549157\n",
      "[257]\ttrain-mlogloss:0.376051\ttest-mlogloss:0.549163\n",
      "[258]\ttrain-mlogloss:0.375524\ttest-mlogloss:0.54906\n",
      "[259]\ttrain-mlogloss:0.375091\ttest-mlogloss:0.549014\n",
      "[260]\ttrain-mlogloss:0.37464\ttest-mlogloss:0.548961\n",
      "[261]\ttrain-mlogloss:0.374057\ttest-mlogloss:0.548952\n",
      "[262]\ttrain-mlogloss:0.373486\ttest-mlogloss:0.548969\n",
      "[263]\ttrain-mlogloss:0.373046\ttest-mlogloss:0.548954\n",
      "[264]\ttrain-mlogloss:0.37247\ttest-mlogloss:0.548961\n",
      "[265]\ttrain-mlogloss:0.371989\ttest-mlogloss:0.548988\n",
      "[266]\ttrain-mlogloss:0.371391\ttest-mlogloss:0.548983\n",
      "[267]\ttrain-mlogloss:0.370844\ttest-mlogloss:0.548993\n",
      "[268]\ttrain-mlogloss:0.370346\ttest-mlogloss:0.549032\n",
      "[269]\ttrain-mlogloss:0.369951\ttest-mlogloss:0.548954\n",
      "[270]\ttrain-mlogloss:0.369634\ttest-mlogloss:0.549115\n",
      "[271]\ttrain-mlogloss:0.36915\ttest-mlogloss:0.549035\n",
      "[272]\ttrain-mlogloss:0.368733\ttest-mlogloss:0.549155\n",
      "[273]\ttrain-mlogloss:0.368257\ttest-mlogloss:0.549177\n",
      "[274]\ttrain-mlogloss:0.367939\ttest-mlogloss:0.549351\n",
      "[275]\ttrain-mlogloss:0.367355\ttest-mlogloss:0.549444\n",
      "[276]\ttrain-mlogloss:0.367016\ttest-mlogloss:0.549495\n",
      "[277]\ttrain-mlogloss:0.366531\ttest-mlogloss:0.549544\n",
      "[278]\ttrain-mlogloss:0.366038\ttest-mlogloss:0.549574\n",
      "[279]\ttrain-mlogloss:0.365606\ttest-mlogloss:0.549626\n",
      "[280]\ttrain-mlogloss:0.365141\ttest-mlogloss:0.549598\n",
      "[281]\ttrain-mlogloss:0.364654\ttest-mlogloss:0.549614\n",
      "[282]\ttrain-mlogloss:0.364214\ttest-mlogloss:0.54963\n",
      "[283]\ttrain-mlogloss:0.363805\ttest-mlogloss:0.549672\n",
      "[284]\ttrain-mlogloss:0.363513\ttest-mlogloss:0.549647\n",
      "[285]\ttrain-mlogloss:0.363032\ttest-mlogloss:0.549684\n",
      "[286]\ttrain-mlogloss:0.362399\ttest-mlogloss:0.549655\n",
      "[287]\ttrain-mlogloss:0.361965\ttest-mlogloss:0.549787\n",
      "[288]\ttrain-mlogloss:0.361294\ttest-mlogloss:0.549733\n",
      "[289]\ttrain-mlogloss:0.360882\ttest-mlogloss:0.549639\n",
      "[290]\ttrain-mlogloss:0.360598\ttest-mlogloss:0.549618\n",
      "[291]\ttrain-mlogloss:0.360033\ttest-mlogloss:0.549534\n",
      "[292]\ttrain-mlogloss:0.359688\ttest-mlogloss:0.549544\n",
      "[293]\ttrain-mlogloss:0.359111\ttest-mlogloss:0.54957\n",
      "[294]\ttrain-mlogloss:0.358649\ttest-mlogloss:0.549594\n",
      "[295]\ttrain-mlogloss:0.35812\ttest-mlogloss:0.549722\n",
      "[296]\ttrain-mlogloss:0.357741\ttest-mlogloss:0.549729\n",
      "[297]\ttrain-mlogloss:0.357157\ttest-mlogloss:0.549794\n",
      "[298]\ttrain-mlogloss:0.356737\ttest-mlogloss:0.549766\n",
      "[299]\ttrain-mlogloss:0.356334\ttest-mlogloss:0.54989\n",
      "[300]\ttrain-mlogloss:0.355826\ttest-mlogloss:0.549889\n",
      "[301]\ttrain-mlogloss:0.355541\ttest-mlogloss:0.54989\n",
      "[302]\ttrain-mlogloss:0.355104\ttest-mlogloss:0.549891\n",
      "[303]\ttrain-mlogloss:0.354658\ttest-mlogloss:0.549897\n",
      "[304]\ttrain-mlogloss:0.354129\ttest-mlogloss:0.549899\n",
      "[305]\ttrain-mlogloss:0.353754\ttest-mlogloss:0.549972\n",
      "[306]\ttrain-mlogloss:0.353368\ttest-mlogloss:0.549951\n",
      "[307]\ttrain-mlogloss:0.352758\ttest-mlogloss:0.549998\n",
      "[308]\ttrain-mlogloss:0.352312\ttest-mlogloss:0.550021\n",
      "[309]\ttrain-mlogloss:0.351799\ttest-mlogloss:0.550082\n",
      "[310]\ttrain-mlogloss:0.351418\ttest-mlogloss:0.54998\n",
      "[311]\ttrain-mlogloss:0.350894\ttest-mlogloss:0.550082\n",
      "[312]\ttrain-mlogloss:0.350382\ttest-mlogloss:0.550061\n",
      "[313]\ttrain-mlogloss:0.349969\ttest-mlogloss:0.550004\n",
      "[314]\ttrain-mlogloss:0.349452\ttest-mlogloss:0.550072\n",
      "[315]\ttrain-mlogloss:0.349003\ttest-mlogloss:0.550156\n",
      "[316]\ttrain-mlogloss:0.348575\ttest-mlogloss:0.55024\n",
      "[317]\ttrain-mlogloss:0.348122\ttest-mlogloss:0.550319\n",
      "[318]\ttrain-mlogloss:0.347568\ttest-mlogloss:0.55042\n",
      "[319]\ttrain-mlogloss:0.346958\ttest-mlogloss:0.550304\n",
      "[320]\ttrain-mlogloss:0.346564\ttest-mlogloss:0.550356\n",
      "[321]\ttrain-mlogloss:0.346175\ttest-mlogloss:0.55038\n",
      "[322]\ttrain-mlogloss:0.345916\ttest-mlogloss:0.55032\n",
      "[323]\ttrain-mlogloss:0.345474\ttest-mlogloss:0.550345\n",
      "[324]\ttrain-mlogloss:0.345136\ttest-mlogloss:0.550327\n",
      "[325]\ttrain-mlogloss:0.344842\ttest-mlogloss:0.550324\n",
      "[326]\ttrain-mlogloss:0.344421\ttest-mlogloss:0.550365\n",
      "[327]\ttrain-mlogloss:0.343964\ttest-mlogloss:0.550458\n",
      "[328]\ttrain-mlogloss:0.34348\ttest-mlogloss:0.5505\n",
      "[329]\ttrain-mlogloss:0.343135\ttest-mlogloss:0.550571\n",
      "[330]\ttrain-mlogloss:0.342604\ttest-mlogloss:0.55058\n",
      "[331]\ttrain-mlogloss:0.342208\ttest-mlogloss:0.550556\n",
      "[332]\ttrain-mlogloss:0.341824\ttest-mlogloss:0.550542\n",
      "[333]\ttrain-mlogloss:0.341255\ttest-mlogloss:0.550577\n",
      "[334]\ttrain-mlogloss:0.340693\ttest-mlogloss:0.550632\n",
      "[335]\ttrain-mlogloss:0.340226\ttest-mlogloss:0.55069\n",
      "[336]\ttrain-mlogloss:0.339925\ttest-mlogloss:0.550789\n",
      "[337]\ttrain-mlogloss:0.339606\ttest-mlogloss:0.550861\n",
      "[338]\ttrain-mlogloss:0.339178\ttest-mlogloss:0.550911\n",
      "[339]\ttrain-mlogloss:0.338793\ttest-mlogloss:0.550909\n",
      "[340]\ttrain-mlogloss:0.338254\ttest-mlogloss:0.551031\n",
      "[341]\ttrain-mlogloss:0.337764\ttest-mlogloss:0.551088\n",
      "[342]\ttrain-mlogloss:0.33728\ttest-mlogloss:0.551033\n",
      "[343]\ttrain-mlogloss:0.336941\ttest-mlogloss:0.551071\n",
      "[344]\ttrain-mlogloss:0.336542\ttest-mlogloss:0.551089\n",
      "[345]\ttrain-mlogloss:0.336002\ttest-mlogloss:0.551104\n",
      "[346]\ttrain-mlogloss:0.335632\ttest-mlogloss:0.551031\n",
      "[347]\ttrain-mlogloss:0.335235\ttest-mlogloss:0.551086\n",
      "[348]\ttrain-mlogloss:0.334841\ttest-mlogloss:0.551013\n",
      "[349]\ttrain-mlogloss:0.334393\ttest-mlogloss:0.551109\n",
      "[350]\ttrain-mlogloss:0.33414\ttest-mlogloss:0.551119\n",
      "[351]\ttrain-mlogloss:0.33378\ttest-mlogloss:0.551174\n",
      "[352]\ttrain-mlogloss:0.333427\ttest-mlogloss:0.551217\n",
      "[353]\ttrain-mlogloss:0.332986\ttest-mlogloss:0.551327\n",
      "[354]\ttrain-mlogloss:0.332565\ttest-mlogloss:0.55145\n",
      "[355]\ttrain-mlogloss:0.332135\ttest-mlogloss:0.551381\n",
      "[356]\ttrain-mlogloss:0.331789\ttest-mlogloss:0.55141\n",
      "[357]\ttrain-mlogloss:0.331331\ttest-mlogloss:0.551457\n",
      "[358]\ttrain-mlogloss:0.330952\ttest-mlogloss:0.55157\n",
      "[359]\ttrain-mlogloss:0.330455\ttest-mlogloss:0.551555\n",
      "[360]\ttrain-mlogloss:0.330077\ttest-mlogloss:0.551505\n",
      "[361]\ttrain-mlogloss:0.329721\ttest-mlogloss:0.551473\n",
      "Stopping. Best iteration:\n",
      "[261]\ttrain-mlogloss:0.374057\ttest-mlogloss:0.548952\n",
      "\n",
      "[0.55147250963518901]\n"
     ]
    }
   ],
   "source": [
    "#running and getting the cv from xgboost\n",
    "cv_scores = []\n",
    "#K-FOLD already defined.If not ,use\n",
    "#KF=KFold(len(train_X),5,shuffle=True,random_state = 42)\n",
    "for dev_index, val_index in KF:\n",
    "        #split the orginal train set into dev_set and val_set\n",
    "        dev_set, val_set = train_df.iloc[dev_index,:] , train_df.iloc[val_index,:] \n",
    "        \n",
    "        #apply the function for createing some featues\n",
    "        dev_set, val_set =manager_skill_eval(dev_set,val_set)\n",
    "        #features_to_use.extend(['ManHigh','ManLow', 'ManMedium','manager_skill'])\n",
    "        \n",
    "        #filter the features\n",
    "        dev_X, val_X = dev_set[features_to_use].as_matrix(), val_set[features_to_use].as_matrix()\n",
    "        dev_y, val_y = train_y[dev_index], train_y[val_index]\n",
    "        \n",
    "        preds, model = runXGB(dev_X, dev_y, val_X, val_y,feature_names=features_to_use)\n",
    "        cv_scores.append(log_loss(val_y, preds))\n",
    "        print(cv_scores)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'ManHigh', u'ManLow', u'ManMedium'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#output the outcome - using xgboost\n",
    "train_set, test_set =manager_skill_eval(train_df,test_df)\n",
    "features_to_use.append('manager_skill')\n",
    "\n",
    "train_X = train_set[features_to_use]\n",
    "test_X = test_set[features_to_use]\n",
    "\n",
    "train_X_m = train_X.as_matrix()\n",
    "test_X_m = test_X.as_matrix()\n",
    "\n",
    "preds, model = runXGB(train_X_m, train_y, test_X_m, num_rounds=260)\n",
    "out_df = pd.DataFrame(preds)\n",
    "out_df.columns = [\"high\", \"medium\", \"low\"]\n",
    "out_df[\"listing_id\"] = test_df.listing_id.values\n",
    "out_df.to_csv(\"xgb_beta1point2withHccSortedWithLabel.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([            u'bathrooms',              u'bedrooms',\n",
       "                 u'building_id',               u'created',\n",
       "                 u'description',       u'display_address',\n",
       "                    u'features',        u'interest_level',\n",
       "                    u'latitude',            u'listing_id',\n",
       "                   u'longitude',            u'manager_id',\n",
       "                      u'photos',                 u'price',\n",
       "              u'street_address',            u'num_photos',\n",
       "                u'num_features', u'num_description_words',\n",
       "                u'created_year',         u'created_month',\n",
       "                 u'created_day',          u'created_hour'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dev_set.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bathrooms': 0.010285346346753424,\n",
       " 'bedrooms': 0.030466314219872576,\n",
       " 'building_id': 0.06857462383082553,\n",
       " 'created_day': 0.046309475396502646,\n",
       " 'created_hour': 0.04346278975193168,\n",
       " 'created_month': 0.006015317879896977,\n",
       " 'display_address': 0.0806899823776603,\n",
       " 'latitude': 0.09202589128371967,\n",
       " 'listing_id': 0.09887149247661652,\n",
       " 'longitude': 0.07911413853870138,\n",
       " 'manager_id': 0.09904093805069812,\n",
       " 'num_description_words': 0.0829605530703538,\n",
       " 'num_features': 0.04493696624644164,\n",
       " 'num_photos': 0.04109055171478921,\n",
       " 'price': 0.0970753693913515,\n",
       " 'street_address': 0.07908024942388504}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ananlysis by the feature importance by weight\n",
    "\"\"\"\n",
    "weight = model.get_score()\n",
    "total = sum(weight.values())\n",
    "for key in weight:\n",
    "    weight[key] = weight[key]*1.0/total\n",
    "weight\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#ananlysis by the feature importance by gain\n",
    "\"\"\"\n",
    "gain = model.get_score(importance_type='gain')\n",
    "total = sum(gain.values())\n",
    "#for key in gain:\n",
    "#    gain[key] = gain[key]*1.0/total\n",
    "gain\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bathrooms': 0.15003324661763429,\n",
       " 'bedrooms': 0.11847222747849985,\n",
       " 'building_id': 0.05966144646752775,\n",
       " 'created_day': 0.027908091350767217,\n",
       " 'created_hour': 0.04913703475375256,\n",
       " 'created_month': 0.015463921187964249,\n",
       " 'display_address': 0.051917534421511584,\n",
       " 'latitude': 0.062329192852910546,\n",
       " 'listing_id': 0.05823796559748455,\n",
       " 'longitude': 0.05796867229011468,\n",
       " 'manager_id': 0.0658834209429622,\n",
       " 'num_description_words': 0.04385875263322271,\n",
       " 'num_features': 0.05493240649113651,\n",
       " 'num_photos': 0.053803480057786596,\n",
       " 'price': 0.07955324745771991,\n",
       " 'street_address': 0.050839359399004566}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ananlysis by the feature importance by coverage\n",
    "\"\"\"\n",
    "cover = model.get_score(importance_type='cover')\n",
    "total = sum(cover.values())\n",
    "for key in cover:\n",
    "    cover[key] = cover[key]*1.0/total\n",
    "cover\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
