{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn import  preprocessing, ensemble\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.cross_validation import KFold\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#try xgboost\n",
    "#fucntion from SRK\n",
    "def runXGB(train_X, train_y, test_X, test_y=None, feature_names=None, \\\n",
    "     seed_val=0, early_stop = 20,num_rounds=10000, eta = 0.1,\\\n",
    "     max_depth = 6,cv_dict = None,verbose_eval=True):\n",
    "    param = {}\n",
    "    param['objective'] = 'multi:softprob'\n",
    "    param['eta'] = eta\n",
    "    param['max_depth'] = max_depth\n",
    "    param['silent'] = 1\n",
    "    param['num_class'] = 3\n",
    "    param['eval_metric'] = \"mlogloss\"\n",
    "    param['min_child_weight'] = 1\n",
    "    param['subsample'] = 0.7\n",
    "    param['colsample_bytree'] = 0.7\n",
    "    param['seed'] = seed_val\n",
    "    num_rounds = num_rounds\n",
    "\n",
    "    plst = list(param.items())\n",
    "    xgtrain = xgb.DMatrix(train_X, label=train_y,feature_names=feature_names)\n",
    "\n",
    "    if test_y is not None:\n",
    "        xgtest = xgb.DMatrix(test_X, label=test_y,feature_names=feature_names)\n",
    "        watchlist = [ (xgtrain,'train'), (xgtest, 'test') ]\n",
    "        model = xgb.train(plst, xgtrain, num_rounds, watchlist,\\\n",
    "        early_stopping_rounds=early_stop,evals_result = cv_dict,verbose_eval = verbose_eval)\n",
    "    else:\n",
    "        xgtest = xgb.DMatrix(test_X,feature_names=feature_names)\n",
    "        model = xgb.train(plst, xgtrain, num_rounds)\n",
    "\n",
    "    pred_test_y = model.predict(xgtest)\n",
    "    return pred_test_y, model\n",
    "\n",
    "class CVstatistics(object):\n",
    "    \n",
    "    \"\"\"\n",
    "    self.result : the result dataframe storing the cv results\n",
    "    self.endpoint : the first ending point for the validations\n",
    "    self.turns: the turns for each validation\n",
    "    \n",
    "    validCurve : plot the validation curve,stop at the first endpoint\n",
    "    \"\"\"\n",
    "    def __init__(self,result_dict,metric,k=5):\n",
    "        self.metric = metric\n",
    "        if type(result_dict) == pd.DataFrame:\n",
    "            self.result = result_dict\n",
    "        else:\n",
    "            tempDict = {}\n",
    "            for phase in ['train','test']:\n",
    "                for turn in range(k):\n",
    "                    tempDict[phase+str(turn)]=cv_result[turn][phase][metric]\n",
    "                    self.result=pd.DataFrame(dict([ (key,pd.Series(v)) for key,v in tempDict.iteritems()]))    \n",
    "        \n",
    "        self.endpoint =len(self.result.filter(like = 'train').dropna())\n",
    "        \n",
    "        self.turns = self.result.filter(like = 'test').\\\n",
    "            apply(lambda x : ~np.isnan(x)).cumsum(axis=0).iloc[len(self.result)-1,:]\n",
    "\n",
    "    def validCurve(self,start=0,stop_at_first = True):\n",
    "        if stop_at_first:\n",
    "            eout = self.result.filter(like = 'test').dropna().mean(axis=1)\n",
    "            ein =  self.result.filter(like = 'train').dropna().mean(axis=1)\n",
    "        else:\n",
    "            eout = self.result.filter(like = 'test').mean(axis=1)\n",
    "            ein =  self.result.filter(like = 'train').mean(axis=1)\n",
    "        plt.plot(range(len(eout)), eout,\n",
    "        range(len(ein)), ein)\n",
    "        plt.xlabel(\"turn\")\n",
    "        plt.ylabel(self.metric)\n",
    "        plt.title('Validation Curve')\n",
    "        \n",
    "        plt.show()\n",
    "    \n",
    "    def errorsAt(self,turn):\n",
    "        eout = self.result.filter(like = 'test').loc[turn].mean()\n",
    "        ein = self.result.filter(like = 'train').loc[turn].mean()\n",
    "        return eout,ein\n",
    "    \n",
    "\n",
    "def showImportance(model,factor_name):\n",
    "    factors = model.get_score(importance_type=factor_name)\n",
    "    factor_list = []\n",
    "    total = sum(factors.values())\n",
    "    for key in factors:\n",
    "        factors[key] = factors[key]*1.0/total\n",
    "        factor_list.append((key,factors[key]))\n",
    "    print sorted(factor_list,key=lambda x : x[1],reverse=True)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49352, 15)\n",
      "(74659, 14)\n"
     ]
    }
   ],
   "source": [
    "#lodaing data\n",
    "data_path = \"../../kaggleData/2sigma/\"\n",
    "train_file = data_path + \"train.json\"\n",
    "test_file = data_path + \"test.json\"\n",
    "train_df = pd.read_json(train_file)\n",
    "test_df = pd.read_json(test_file)\n",
    "print(train_df.shape)\n",
    "print(test_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#basic numerical features\n",
    "features_to_use  = [\"bathrooms\", \"bedrooms\", \"latitude\", \"longitude\", \"price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#some transfromed features\n",
    "# count of photos #\n",
    "train_df[\"num_photos\"] = train_df[\"photos\"].apply(len)\n",
    "\n",
    "# count of \"features\" #\n",
    "train_df[\"num_features\"] = train_df[\"features\"].apply(len)\n",
    "\n",
    "# count of words present in description column #\n",
    "train_df[\"num_description_words\"] = train_df[\"description\"].apply(lambda x: len(x.split(\" \")))\n",
    "\n",
    "# convert the created column to datetime object so as to extract more features \n",
    "train_df[\"created\"] = pd.to_datetime(train_df[\"created\"])\n",
    "\n",
    "# Let us extract some features like year, month, day, hour from date columns #\n",
    "train_df[\"created_year\"] = train_df[\"created\"].dt.year\n",
    "train_df[\"created_month\"] = train_df[\"created\"].dt.month\n",
    "train_df[\"created_day\"] = train_df[\"created\"].dt.day\n",
    "train_df[\"created_hour\"] = train_df[\"created\"].dt.hour\n",
    "\n",
    "#some new numerical features related to the price\n",
    "train_df[\"price_per_bath\"] =  (train_df[\"price\"]*1.0/train_df[\"bathrooms\"]).replace(np.Inf,-1)\n",
    "train_df[\"price_per_bed\"] = (train_df[\"price\"]*1.0/train_df[\"bedrooms\"]).replace(np.Inf,-1)\n",
    "train_df[\"bath_per_bed\"] = (train_df[\"bathrooms\"]*1.0/train_df[\"bedrooms\"]).replace(np.Inf,-1)\n",
    "train_df[\"price_per_room\"] = (train_df[\"price\"]*1.0/(train_df[\"bedrooms\"]+train_df[\"bathrooms\"])).replace(np.Inf,-1)\n",
    "\n",
    "# adding all these new features to use list # \"listing_id\",\n",
    "features_to_use.extend([\"num_photos\", \"num_features\", \"num_description_words\",\\\n",
    "                        \"created_year\",\"listing_id\", \"created_month\", \"created_day\", \"created_hour\"])\n",
    "#price new features\n",
    "features_to_use.extend([\"price_per_bed\",\"bath_per_bed\",\"price_per_room\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df['building0']=map(lambda x:1 if x== '0' else 0,train_df['building_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features_to_use.append('building0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#prepare for training\n",
    "target_num_map = {'high':0, 'medium':1, 'low':2}\n",
    "\n",
    "train_y = np.array(train_df['interest_level'].apply(lambda x: target_num_map[x]))\n",
    "\n",
    "KF=KFold(len(train_df),5,shuffle=True,random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:1.03871\ttest-mlogloss:1.04018\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.518441\ttest-mlogloss:0.582541\n",
      "[200]\ttrain-mlogloss:0.457869\ttest-mlogloss:0.57244\n",
      "[300]\ttrain-mlogloss:0.414763\ttest-mlogloss:0.571141\n",
      "Stopping. Best iteration:\n",
      "[289]\ttrain-mlogloss:0.418549\ttest-mlogloss:0.570816\n",
      "\n",
      "loss for the turn 1 is 0.571214682806\n",
      "[0]\ttrain-mlogloss:1.03835\ttest-mlogloss:1.03931\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.519311\ttest-mlogloss:0.577454\n",
      "[200]\ttrain-mlogloss:0.459132\ttest-mlogloss:0.566997\n",
      "[300]\ttrain-mlogloss:0.414989\ttest-mlogloss:0.565139\n",
      "Stopping. Best iteration:\n",
      "[290]\ttrain-mlogloss:0.419158\ttest-mlogloss:0.564895\n",
      "\n",
      "loss for the turn 2 is 0.565283945159\n",
      "[0]\ttrain-mlogloss:1.03683\ttest-mlogloss:1.03715\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.516916\ttest-mlogloss:0.580066\n",
      "[200]\ttrain-mlogloss:0.459288\ttest-mlogloss:0.571331\n",
      "Stopping. Best iteration:\n",
      "[253]\ttrain-mlogloss:0.434815\ttest-mlogloss:0.569536\n",
      "\n",
      "loss for the turn 3 is 0.569752490896\n",
      "[0]\ttrain-mlogloss:1.03699\ttest-mlogloss:1.03762\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.518847\ttest-mlogloss:0.578706\n",
      "[200]\ttrain-mlogloss:0.461743\ttest-mlogloss:0.569028\n",
      "[300]\ttrain-mlogloss:0.416316\ttest-mlogloss:0.566422\n",
      "Stopping. Best iteration:\n",
      "[290]\ttrain-mlogloss:0.420598\ttest-mlogloss:0.566282\n",
      "\n",
      "loss for the turn 4 is 0.566664836575\n",
      "[0]\ttrain-mlogloss:1.03716\ttest-mlogloss:1.03745\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.516621\ttest-mlogloss:0.579105\n",
      "[200]\ttrain-mlogloss:0.456753\ttest-mlogloss:0.573959\n",
      "Stopping. Best iteration:\n",
      "[216]\ttrain-mlogloss:0.448622\ttest-mlogloss:0.573326\n",
      "\n",
      "loss for the turn 5 is 0.573801805071\n"
     ]
    }
   ],
   "source": [
    "#running and getting the cv from xgboost\n",
    "cv_scores = []\n",
    "cv_result = []\n",
    "\n",
    "#K-FOLD already defined.If not ,use\n",
    "#KF=KFold(len(train_X),5,shuffle=True,random_state = 42)\n",
    "i=0\n",
    "for dev_index, val_index in KF:\n",
    "        result_dict = {}\n",
    "        \n",
    "        \"\"\"some preprocessing like feature constructed in cv manners\"\"\"\n",
    "        \n",
    "        #split the orginal train set into dev_set and val_set\n",
    "        dev_set, val_set = train_df.iloc[dev_index,:] , train_df.iloc[val_index,:] \n",
    "        \n",
    "        dev_X, val_X = dev_set[features_to_use].as_matrix(), val_set[features_to_use].as_matrix()\n",
    "        dev_y, val_y = train_y[dev_index], train_y[val_index]\n",
    "        \n",
    "        \"\"\" \n",
    "         runXGB(train_X, train_y, test_X, test_y=None, feature_names=None, \\\n",
    "         seed_val=0, early_stop = 20,num_rounds=10000, eta = 0.1,\\\n",
    "         max_depth = 6,cv_dict = None):\n",
    "         \"\"\"\n",
    "        \n",
    "        preds, model = runXGB(dev_X, dev_y, val_X, val_y,early_stop  = 20,\\\n",
    "                              feature_names = features_to_use,cv_dict = result_dict,verbose_eval=100)\n",
    "        loss = log_loss(val_y, preds)\n",
    "        cv_scores.append(loss)\n",
    "        cv_result.append(result_dict)\n",
    "        i+=1\n",
    "        print 'loss for the turn '+str(i)+' is '+str(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "test0    254\n",
       "test1    260\n",
       "test2    342\n",
       "test3    296\n",
       "test4    273\n",
       "Name: 341, dtype: int32"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#plot the validation curv\n",
    "cvResult = CVstatistics(cv_result,'mlogloss')\n",
    "cvResult.turns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.56934355210142784"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cvResult.validCurve(stop=False)\n",
    "#some errors at certain turn to see the descending\n",
    "cv_scores\n",
    "np.mean(cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('bathrooms', 0.09725565800916634), ('price', 0.09499099365937312), ('price_per_room', 0.09205531264056366), ('created_hour', 0.09194288123746672), ('price_per_bed', 0.08666569315447636), ('num_photos', 0.07428368001559033), ('bedrooms', 0.07012971325635668), ('bath_per_bed', 0.061415666612366956), ('num_features', 0.06043546567125035), ('latitude', 0.058875420604080596), ('longitude', 0.05741437403240373), ('num_description_words', 0.04480527126354566), ('listing_id', 0.042255845208890516), ('created_day', 0.03503384908900436), ('created_month', 0.03244017554546452)]\n"
     ]
    }
   ],
   "source": [
    "#show the importance of the features\n",
    "showImportance(model,'gain')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
