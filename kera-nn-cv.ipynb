{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.cross_validation import KFold\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_path = '/home/raku/kaggleData/2sigma/lr4/'\n",
    "\n",
    "train_df=pd.read_json(data_path+'lr4-n-train.json')\n",
    "test_df=pd.read_json(data_path+'lr4-n-test.json')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "223\n"
     ]
    }
   ],
   "source": [
    "pickl_file = '/home/raku/kaggleData/2sigma/loglr/'+'loglrfeatures.pickle'\n",
    "fileObject = open(pickl_file,'r') \n",
    "features=pickle.load(fileObject)   \n",
    "fileObject.close()\n",
    "print len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numericals = [u'bath_per_bed',u'bathrooms',u'bedrooms',u'building0',u'cluster_id_10_d',u'cluster_id_30_d',u'dayofyear',\n",
    " u'latitude',u'listing_id',u'longitude',u'm14perf',u'm14perf_f',u'm30perf',u'm30perf_f',u'm3perf',u'm3perf_f',\n",
    " u'm7perf',u'm7perf_f',u'm_c_distance',u'm_m_distance',u'manager_id_nrank',u'manager_id_perf',u'mlat',\n",
    " u'mlon',u'num_description_words',u'num_features', u'num_photos',\n",
    " u'price',u'price_per_bath',u'price_per_bed',u'price_per_room',]\n",
    "len(numericals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.regularizers import l2\n",
    "from keras import optimizers\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nn_model(features,num_classes=3,lr=0.1):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64,  \n",
    "                    activation='softplus',\n",
    "                    input_shape = (len(features),),\n",
    "                                  kernel_initializer='he_normal',\n",
    "                                  kernel_regularizer=l2(0.000025)\n",
    "                                  ))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Dense(16,\n",
    "                    activation='softplus', \n",
    "                    kernel_initializer='he_normal',\n",
    "                    kernel_regularizer=l2(0.000025)\n",
    "                    ))\n",
    "    model.add(Dropout(0.1))\n",
    "\n",
    "    model.add(Dense(units=num_classes, \n",
    "                    activation='softmax', \n",
    "                    kernel_initializer='he_normal',\n",
    "                    ))\n",
    "    opt = optimizers.Adadelta(lr=1)\n",
    "    model.compile(loss='sparse_categorical_crossentropy', \n",
    "                  optimizer=opt,\n",
    "                  metrics=['accuracy']\n",
    "                  )\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#prepare for training\n",
    "target_num_map = {'high':0, 'medium':1, 'low':2}\n",
    "\n",
    "train_y = np.array(train_df['interest_level'].apply(lambda x: target_num_map[x]))\n",
    "\n",
    "KF=KFold(len(train_df),5,shuffle=True,random_state = 2333)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 39481 samples, validate on 9871 samples\n",
      "Epoch 1/1000\n",
      "8s - loss: 0.7141 - acc: 0.7015 - val_loss: 0.6133 - val_acc: 0.7320\n",
      "Epoch 2/1000\n",
      "7s - loss: 0.6272 - acc: 0.7243 - val_loss: 0.6017 - val_acc: 0.7336\n",
      "Epoch 3/1000\n",
      "7s - loss: 0.6129 - acc: 0.7295 - val_loss: 0.5978 - val_acc: 0.7345\n",
      "Epoch 4/1000\n",
      "7s - loss: 0.6057 - acc: 0.7335 - val_loss: 0.5953 - val_acc: 0.7352\n",
      "Epoch 5/1000\n",
      "9s - loss: 0.6005 - acc: 0.7357 - val_loss: 0.5932 - val_acc: 0.7354\n",
      "Epoch 6/1000\n",
      "8s - loss: 0.5961 - acc: 0.7356 - val_loss: 0.5921 - val_acc: 0.7369\n",
      "Epoch 7/1000\n",
      "7s - loss: 0.5941 - acc: 0.7372 - val_loss: 0.5912 - val_acc: 0.7399\n",
      "Epoch 8/1000\n",
      "7s - loss: 0.5946 - acc: 0.7357 - val_loss: 0.5899 - val_acc: 0.7407\n",
      "Epoch 9/1000\n",
      "8s - loss: 0.5910 - acc: 0.7373 - val_loss: 0.5895 - val_acc: 0.7394\n",
      "Epoch 10/1000\n",
      "8s - loss: 0.5875 - acc: 0.7381 - val_loss: 0.5894 - val_acc: 0.7408\n",
      "Epoch 11/1000\n",
      "8s - loss: 0.5861 - acc: 0.7418 - val_loss: 0.5881 - val_acc: 0.7394\n",
      "Epoch 12/1000\n",
      "9s - loss: 0.5874 - acc: 0.7384 - val_loss: 0.5872 - val_acc: 0.7419\n",
      "Epoch 13/1000\n",
      "8s - loss: 0.5849 - acc: 0.7408 - val_loss: 0.5861 - val_acc: 0.7415\n",
      "Epoch 14/1000\n",
      "8s - loss: 0.5833 - acc: 0.7411 - val_loss: 0.5860 - val_acc: 0.7438\n",
      "Epoch 15/1000\n",
      "6s - loss: 0.5836 - acc: 0.7408 - val_loss: 0.5848 - val_acc: 0.7432\n",
      "Epoch 16/1000\n",
      "6s - loss: 0.5808 - acc: 0.7412 - val_loss: 0.5842 - val_acc: 0.7439\n",
      "Epoch 17/1000\n",
      "7s - loss: 0.5793 - acc: 0.7427 - val_loss: 0.5847 - val_acc: 0.7433\n",
      "Epoch 18/1000\n",
      "9s - loss: 0.5800 - acc: 0.7422 - val_loss: 0.5836 - val_acc: 0.7459\n",
      "Epoch 19/1000\n",
      "9s - loss: 0.5785 - acc: 0.7428 - val_loss: 0.5833 - val_acc: 0.7449\n",
      "Epoch 20/1000\n",
      "7s - loss: 0.5770 - acc: 0.7436 - val_loss: 0.5828 - val_acc: 0.7446\n",
      "Epoch 21/1000\n",
      "8s - loss: 0.5762 - acc: 0.7439 - val_loss: 0.5831 - val_acc: 0.7450\n",
      "Epoch 22/1000\n",
      "7s - loss: 0.5767 - acc: 0.7434 - val_loss: 0.5807 - val_acc: 0.7452\n",
      "Epoch 23/1000\n",
      "9s - loss: 0.5745 - acc: 0.7434 - val_loss: 0.5810 - val_acc: 0.7451\n",
      "Epoch 24/1000\n",
      "8s - loss: 0.5745 - acc: 0.7428 - val_loss: 0.5805 - val_acc: 0.7460\n",
      "Epoch 25/1000\n",
      "8s - loss: 0.5745 - acc: 0.7427 - val_loss: 0.5797 - val_acc: 0.7449\n",
      "Epoch 26/1000\n",
      "9s - loss: 0.5739 - acc: 0.7456 - val_loss: 0.5803 - val_acc: 0.7444\n",
      "Epoch 27/1000\n",
      "7s - loss: 0.5713 - acc: 0.7456 - val_loss: 0.5812 - val_acc: 0.7458\n",
      "Epoch 28/1000\n",
      "10s - loss: 0.5734 - acc: 0.7450 - val_loss: 0.5800 - val_acc: 0.7474\n",
      "Epoch 29/1000\n",
      "7s - loss: 0.5714 - acc: 0.7465 - val_loss: 0.5803 - val_acc: 0.7455\n",
      "Epoch 30/1000\n",
      "8s - loss: 0.5705 - acc: 0.7470 - val_loss: 0.5800 - val_acc: 0.7464\n",
      "Epoch 31/1000\n",
      "8s - loss: 0.5715 - acc: 0.7472 - val_loss: 0.5798 - val_acc: 0.7465\n",
      "Epoch 32/1000\n",
      "8s - loss: 0.5699 - acc: 0.7470 - val_loss: 0.5807 - val_acc: 0.7453\n",
      "Epoch 33/1000\n",
      "7s - loss: 0.5710 - acc: 0.7463 - val_loss: 0.5784 - val_acc: 0.7464\n",
      "Epoch 34/1000\n",
      "7s - loss: 0.5696 - acc: 0.7469 - val_loss: 0.5806 - val_acc: 0.7460\n",
      "Epoch 35/1000\n",
      "6s - loss: 0.5688 - acc: 0.7488 - val_loss: 0.5784 - val_acc: 0.7469\n",
      "Epoch 36/1000\n",
      "8s - loss: 0.5678 - acc: 0.7478 - val_loss: 0.5787 - val_acc: 0.7479\n",
      "Epoch 37/1000\n",
      "8s - loss: 0.5671 - acc: 0.7488 - val_loss: 0.5788 - val_acc: 0.7483\n",
      "Epoch 38/1000\n",
      "6s - loss: 0.5679 - acc: 0.7472 - val_loss: 0.5794 - val_acc: 0.7472\n",
      "Epoch 39/1000\n",
      "7s - loss: 0.5649 - acc: 0.7495 - val_loss: 0.5798 - val_acc: 0.7483\n",
      "Epoch 40/1000\n",
      "8s - loss: 0.5674 - acc: 0.7478 - val_loss: 0.5782 - val_acc: 0.7508\n",
      "Epoch 41/1000\n",
      "9s - loss: 0.5659 - acc: 0.7498 - val_loss: 0.5777 - val_acc: 0.7501\n",
      "Epoch 42/1000\n",
      "7s - loss: 0.5661 - acc: 0.7482 - val_loss: 0.5770 - val_acc: 0.7498\n",
      "Epoch 43/1000\n",
      "7s - loss: 0.5643 - acc: 0.7497 - val_loss: 0.5764 - val_acc: 0.7485\n",
      "Epoch 44/1000\n",
      "8s - loss: 0.5652 - acc: 0.7502 - val_loss: 0.5777 - val_acc: 0.7479\n",
      "Epoch 45/1000\n",
      "7s - loss: 0.5652 - acc: 0.7485 - val_loss: 0.5777 - val_acc: 0.7494\n",
      "Epoch 46/1000\n",
      "7s - loss: 0.5640 - acc: 0.7509 - val_loss: 0.5776 - val_acc: 0.7488\n",
      "Epoch 47/1000\n",
      "9s - loss: 0.5635 - acc: 0.7497 - val_loss: 0.5760 - val_acc: 0.7492\n",
      "Epoch 48/1000\n",
      "8s - loss: 0.5630 - acc: 0.7501 - val_loss: 0.5773 - val_acc: 0.7511\n",
      "Epoch 49/1000\n",
      "7s - loss: 0.5614 - acc: 0.7509 - val_loss: 0.5771 - val_acc: 0.7504\n",
      "Epoch 50/1000\n",
      "7s - loss: 0.5621 - acc: 0.7504 - val_loss: 0.5773 - val_acc: 0.7490\n",
      "Epoch 51/1000\n",
      "7s - loss: 0.5616 - acc: 0.7504 - val_loss: 0.5770 - val_acc: 0.7511\n",
      "Epoch 52/1000\n",
      "9s - loss: 0.5620 - acc: 0.7510 - val_loss: 0.5770 - val_acc: 0.7493\n",
      "Epoch 53/1000\n",
      "7s - loss: 0.5612 - acc: 0.7511 - val_loss: 0.5766 - val_acc: 0.7490\n",
      "Epoch 54/1000\n",
      "8s - loss: 0.5611 - acc: 0.7522 - val_loss: 0.5767 - val_acc: 0.7484\n",
      "Epoch 55/1000\n",
      "8s - loss: 0.5624 - acc: 0.7517 - val_loss: 0.5774 - val_acc: 0.7485\n",
      "Epoch 56/1000\n",
      "8s - loss: 0.5602 - acc: 0.7539 - val_loss: 0.5760 - val_acc: 0.7495\n",
      "Epoch 57/1000\n",
      "8s - loss: 0.5610 - acc: 0.7521 - val_loss: 0.5775 - val_acc: 0.7501\n",
      "Epoch 58/1000\n",
      "7s - loss: 0.5584 - acc: 0.7539 - val_loss: 0.5764 - val_acc: 0.7494\n",
      "Epoch 59/1000\n",
      "8s - loss: 0.5598 - acc: 0.7538 - val_loss: 0.5768 - val_acc: 0.7512\n",
      "Epoch 60/1000\n",
      "8s - loss: 0.5580 - acc: 0.7543 - val_loss: 0.5781 - val_acc: 0.7497\n",
      "Epoch 61/1000\n",
      "6s - loss: 0.5598 - acc: 0.7534 - val_loss: 0.5767 - val_acc: 0.7506\n",
      "Epoch 62/1000\n",
      "6s - loss: 0.5589 - acc: 0.7536 - val_loss: 0.5771 - val_acc: 0.7492\n",
      "Epoch 63/1000\n",
      "8s - loss: 0.5588 - acc: 0.7533 - val_loss: 0.5750 - val_acc: 0.7495\n",
      "Epoch 64/1000\n",
      "8s - loss: 0.5582 - acc: 0.7533 - val_loss: 0.5750 - val_acc: 0.7485\n",
      "Epoch 65/1000\n",
      "7s - loss: 0.5586 - acc: 0.7531 - val_loss: 0.5772 - val_acc: 0.7516\n",
      "Epoch 66/1000\n",
      "7s - loss: 0.5577 - acc: 0.7554 - val_loss: 0.5771 - val_acc: 0.7510\n",
      "Epoch 67/1000\n",
      "6s - loss: 0.5584 - acc: 0.7537 - val_loss: 0.5765 - val_acc: 0.7494\n",
      "Epoch 68/1000\n",
      "7s - loss: 0.5571 - acc: 0.7565 - val_loss: 0.5763 - val_acc: 0.7500\n",
      "Epoch 69/1000\n",
      "7s - loss: 0.5566 - acc: 0.7545 - val_loss: 0.5759 - val_acc: 0.7502\n",
      "Epoch 70/1000\n",
      "7s - loss: 0.5584 - acc: 0.7535 - val_loss: 0.5767 - val_acc: 0.7493\n",
      "Epoch 71/1000\n",
      "7s - loss: 0.5571 - acc: 0.7524 - val_loss: 0.5762 - val_acc: 0.7516\n",
      "Epoch 72/1000\n",
      "7s - loss: 0.5564 - acc: 0.7549 - val_loss: 0.5763 - val_acc: 0.7510\n",
      "Epoch 73/1000\n",
      "6s - loss: 0.5569 - acc: 0.7527 - val_loss: 0.5778 - val_acc: 0.7483\n",
      "Epoch 74/1000\n",
      "7s - loss: 0.5555 - acc: 0.7550 - val_loss: 0.5750 - val_acc: 0.7489\n",
      "Epoch 75/1000\n",
      "6s - loss: 0.5568 - acc: 0.7559 - val_loss: 0.5765 - val_acc: 0.7500\n",
      "Epoch 76/1000\n",
      "8s - loss: 0.5563 - acc: 0.7541 - val_loss: 0.5762 - val_acc: 0.7509\n",
      "Epoch 77/1000\n",
      "7s - loss: 0.5553 - acc: 0.7561 - val_loss: 0.5770 - val_acc: 0.7495\n",
      "Epoch 78/1000\n",
      "8s - loss: 0.5563 - acc: 0.7559 - val_loss: 0.5761 - val_acc: 0.7498\n",
      "Epoch 79/1000\n",
      "7s - loss: 0.5543 - acc: 0.7566 - val_loss: 0.5767 - val_acc: 0.7508\n",
      "Epoch 80/1000\n",
      "6s - loss: 0.5539 - acc: 0.7561 - val_loss: 0.5761 - val_acc: 0.7513\n",
      "Epoch 81/1000\n",
      "7s - loss: 0.5552 - acc: 0.7542 - val_loss: 0.5768 - val_acc: 0.7492\n",
      "Epoch 82/1000\n",
      "7s - loss: 0.5559 - acc: 0.7558 - val_loss: 0.5763 - val_acc: 0.7485\n",
      "Epoch 83/1000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-e438c969a016>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         model.fit(dev_X, dev_y, epochs = 1000, batch_size=batch_size, verbose = 2, \n\u001b[0;32m---> 16\u001b[0;31m           validation_data=[val_X, val_y], callbacks=[early_stopping])\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda2/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    851\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 853\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    854\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/opt/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1487\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m   1139\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1140\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1141\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1142\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda2/lib/python2.7/site-packages/keras/backend/theano_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1122\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda2/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    882\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 884\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    885\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda2/lib/python2.7/site-packages/theano/ifelse.pyc\u001b[0m in \u001b[0;36mthunk\u001b[0;34m()\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m         \u001b[0;32mdef\u001b[0m \u001b[0mthunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcompute_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for batch_size in [64,128]:\n",
    "#first edition:\n",
    "#numericals from xgb142 + some new hcc encoding + with_feat from xgb142\n",
    "    cv_scores=[]\n",
    "    for dev_index, val_index in KF:\n",
    "        dev_set, val_set = train_df.iloc[dev_index,:] , train_df.iloc[val_index,:] \n",
    "        dev_X, val_X = dev_set[features].as_matrix(), val_set[features].as_matrix()\n",
    "        dev_y, val_y = train_y[dev_index], train_y[val_index]\n",
    "    \n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=20)\n",
    "\n",
    "        seed = 0\n",
    "        np.random.seed(seed)\n",
    "        model = nn_model(features,lr=0.1)\n",
    "        model.fit(dev_X, dev_y, epochs = 1000, batch_size=batch_size, verbose = 2, \n",
    "          validation_data=[val_X, val_y], callbacks=[early_stopping])\n",
    "\n",
    "        preds =  model.predict_proba(val_X)\n",
    "        \n",
    "        cv_scores.append(log_loss(val_y, preds))\n",
    "        \n",
    "        print(cv_scores)\n",
    "    \n",
    "    print np.mean(cv_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for batch_size in [256,512]:\n",
    "#first edition:\n",
    "#numericals from xgb142 + some new hcc encoding + with_feat from xgb142\n",
    "    cv_scores=[]\n",
    "    for dev_index, val_index in KF:\n",
    "        dev_set, val_set = train_df.iloc[dev_index,:] , train_df.iloc[val_index,:] \n",
    "        dev_X, val_X = dev_set[features].as_matrix(), val_set[features].as_matrix()\n",
    "        dev_y, val_y = train_y[dev_index], train_y[val_index]\n",
    "    \n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=20)\n",
    "\n",
    "        seed = 0\n",
    "        np.random.seed(seed)\n",
    "        model = nn_model(features,lr=0.1)\n",
    "        model.fit(dev_X, dev_y, epochs = 1000, batch_size=batch_size, verbose = 2, \n",
    "          validation_data=[val_X, val_y], callbacks=[early_stopping])\n",
    "\n",
    "        preds =  model.predict_proba(val_X)\n",
    "        \n",
    "        cv_scores.append(log_loss(val_y, preds))\n",
    "        \n",
    "        print(cv_scores)\n",
    "    \n",
    "    print np.mean(cv_scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
