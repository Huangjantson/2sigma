{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn import  preprocessing\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.cross_validation import KFold,StratifiedKFold\n",
    "#import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mochi import *\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#try xgboost\n",
    "#original fucntion from SRK\n",
    "def runXGB(train_X, train_y, test_X, test_y=None, feature_names=None,      seed_val=0, early_stop = 20,num_rounds=10000, eta = 0.1,     max_depth = 6,cv_dict = None,verbose_eval=True):\n",
    "    param = {}\n",
    "    param['objective'] = 'multi:softprob'\n",
    "    param['eta'] = eta\n",
    "    param['max_depth'] = max_depth\n",
    "    param['silent'] = 1\n",
    "    param['num_class'] = 3\n",
    "    param['eval_metric'] = \"mlogloss\"\n",
    "    param['min_child_weight'] = 1\n",
    "    param['subsample'] = 0.7\n",
    "    param['colsample_bytree'] = 0.3\n",
    "    param['seed'] = seed_val\n",
    "    param['nthread'] = 2\n",
    "    num_rounds = num_rounds\n",
    "\n",
    "    plst = list(param.items())\n",
    "    xgtrain = xgb.DMatrix(train_X, label=train_y,feature_names=feature_names)\n",
    "\n",
    "    if test_y is not None:\n",
    "        xgtest = xgb.DMatrix(test_X, label=test_y,feature_names=feature_names)\n",
    "        watchlist = [ (xgtrain,'train'), (xgtest, 'test') ]\n",
    "        model = xgb.train(plst, xgtrain, num_rounds, watchlist,        early_stopping_rounds=early_stop,evals_result = cv_dict,verbose_eval = verbose_eval)\n",
    "    else:\n",
    "        xgtest = xgb.DMatrix(test_X,feature_names=feature_names)\n",
    "        model = xgb.train(plst, xgtrain, num_rounds)\n",
    "\n",
    "    pred_test_y = model.predict(xgtest)\n",
    "    return pred_test_y, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49352, 293)\n",
      "(74659, 292)\n"
     ]
    }
   ],
   "source": [
    "data_path = \"/home/raku/kaggleData/2sigma/xgb142/\"\n",
    "train_file = data_path + \"xgb1.42-train.json\"\n",
    "test_file = data_path + \"xgb1.42-test.json\"\n",
    "train_df = pd.read_json(train_file)\n",
    "test_df = pd.read_json(test_file)\n",
    "print(train_df.shape)\n",
    "print(test_df.shape)\n",
    "\n",
    "pickl_file = data_path+'xgb142features.pickle'\n",
    "fileObject = open(pickl_file,'r') \n",
    "features=pickle.load(fileObject)   \n",
    "fileObject.close()\n",
    "print len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df['pic_created']=train_df['time_stamp'].apply(datetime.datetime.fromtimestamp)\n",
    "test_df['pic_created']=test_df['time_stamp'].apply(datetime.datetime.fromtimestamp)\n",
    "\n",
    "train_df[\"pic_month\"] = train_df[\"pic_created\"].dt.month\n",
    "test_df[\"pic_month\"] = test_df[\"pic_created\"].dt.month\n",
    "train_df[\"pic_day\"] = train_df[\"pic_created\"].dt.day\n",
    "test_df[\"pic_day\"] = test_df[\"pic_created\"].dt.day\n",
    "train_df[\"pic_hour\"] = train_df[\"pic_created\"].dt.hour\n",
    "test_df[\"pic_hour\"] = test_df[\"pic_created\"].dt.hour\n",
    "\n",
    "features.extend(['pic_month','pic_day','pic_hour'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = train_df.fillna(-1)\n",
    "test_df = test_df.fillna(-1)\n",
    "\n",
    "store = '/home/raku/kaggleData/2sigma/xgb145/'\n",
    "\n",
    "train_df.to_json(store+'xgb1.45-train.json')\n",
    "test_df.to_json(store+'xgb1.45-test.json')\n",
    "\n",
    "pickl_file = store+'xgb145features.pickle'\n",
    "fileObject = open(pickl_file,'wb') \n",
    "pickle.dump(features,fileObject)   \n",
    "fileObject.close()\n",
    "print len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#prepare for training\n",
    "target_num_map = {'high':0, 'medium':1, 'low':2}\n",
    "\n",
    "train_y = np.array(train_df['interest_level'].apply(lambda x: target_num_map[x]))\n",
    "\n",
    "KF=KFold(len(train_df),5,shuffle=True,random_state = 2333)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv_scores=[]\n",
    "i=0\n",
    "for dev_index, val_index in KF: \n",
    "    result_dict = {}\n",
    "    \n",
    "    dev_set, val_set = train_df.iloc[dev_index,:] , train_df.iloc[val_index,:] \n",
    "       #filter the features\n",
    "    dev_X, val_X = dev_set[new_features].as_matrix(), val_set[new_features].as_matrix()\n",
    "    dev_y, val_y = train_y[dev_index], train_y[val_index]\n",
    "    \n",
    "    preds,model = runXGB(dev_X, dev_y, val_X, val_y,feature_names=new_features,\\\n",
    "           early_stop = 64,num_rounds=4500,eta = 0.1,max_depth=4,cv_dict = result_dict,verbose_eval=100)\n",
    "\n",
    "    loss = log_loss(val_y, preds)\n",
    "    \n",
    "    cv_scores.append(loss)\n",
    "    cv_result.append(result_dict)\n",
    "    models.append(model)\n",
    "    i+=1\n",
    "    print 'loss for the turn '+str(i)+' is '+str(loss)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print 'The mean of the cv_scores is:'\n",
    "print np.mean(cv_scores)\n",
    "\n",
    "cvResult = CVstatistics(cv_result,'mlogloss')\n",
    "\n",
    "meanTestError = cvResult.result.filter(like='test').mean(axis=1)\n",
    "\n",
    "print meanTestError[meanTestError==np.min(meanTestError)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
