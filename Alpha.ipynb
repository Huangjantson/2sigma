{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn import  preprocessing, ensemble\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.cross_validation import KFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49352, 15)\n",
      "(74659, 14)\n"
     ]
    }
   ],
   "source": [
    "#lodaing data\n",
    "data_path = \"../\"\n",
    "train_file = data_path + \"train.json\"\n",
    "test_file = data_path + \"test.json\"\n",
    "train_df = pd.read_json(train_file)\n",
    "test_df = pd.read_json(test_file)\n",
    "print(train_df.shape)\n",
    "print(test_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49352\n"
     ]
    }
   ],
   "source": [
    "print len(train_df['listing_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#basic numerical features\n",
    "features_to_use  = [\"bathrooms\", \"bedrooms\", \"latitude\", \"longitude\", \"price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#some transfromed features\n",
    "# count of photos #\n",
    "train_df[\"num_photos\"] = train_df[\"photos\"].apply(len)\n",
    "test_df[\"num_photos\"] = test_df[\"photos\"].apply(len)\n",
    "\n",
    "# count of \"features\" #\n",
    "train_df[\"num_features\"] = train_df[\"features\"].apply(len)\n",
    "test_df[\"num_features\"] = test_df[\"features\"].apply(len)\n",
    "\n",
    "# count of words present in description column #\n",
    "train_df[\"num_description_words\"] = train_df[\"description\"].apply(lambda x: len(x.split(\" \")))\n",
    "test_df[\"num_description_words\"] = test_df[\"description\"].apply(lambda x: len(x.split(\" \")))\n",
    "\n",
    "# convert the created column to datetime object so as to extract more features \n",
    "train_df[\"created\"] = pd.to_datetime(train_df[\"created\"])\n",
    "test_df[\"created\"] = pd.to_datetime(test_df[\"created\"])\n",
    "\n",
    "# Let us extract some features like year, month, day, hour from date columns #\n",
    "train_df[\"created_year\"] = train_df[\"created\"].dt.year\n",
    "test_df[\"created_year\"] = test_df[\"created\"].dt.year\n",
    "train_df[\"created_month\"] = train_df[\"created\"].dt.month\n",
    "test_df[\"created_month\"] = test_df[\"created\"].dt.month\n",
    "train_df[\"created_day\"] = train_df[\"created\"].dt.day\n",
    "test_df[\"created_day\"] = test_df[\"created\"].dt.day\n",
    "train_df[\"created_hour\"] = train_df[\"created\"].dt.hour\n",
    "test_df[\"created_hour\"] = test_df[\"created\"].dt.hour\n",
    "\n",
    "# adding all these new features to use list # \"listing_id\",\n",
    "features_to_use.extend([\"num_photos\", \"num_features\", \"num_description_words\",\"created_year\", \"created_month\", \"created_day\", \"created_hour\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#prepare for training\n",
    "target_num_map = {'high':0, 'medium':1, 'low':2}\n",
    "\n",
    "train_X = train_df[features_to_use]\n",
    "test_X = test_df[features_to_use]\n",
    "\n",
    "train_y = np.array(train_df['interest_level'].apply(lambda x: target_num_map[x]))\n",
    "\n",
    "KF=KFold(len(train_X),5,shuffle=True,random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.74837249223604518, 0.79366237125772254, 0.79842061493694294, 0.77195708244100802, 0.78614071073619329]\n",
      "0.779710654322\n"
     ]
    }
   ],
   "source": [
    "#cross-validation\n",
    "cv_scores = []\n",
    "\n",
    "#using entropy\n",
    "for dev_index, val_index in KF:\n",
    "        dev_X, val_X = train_X.iloc[dev_index,:], train_X.iloc[val_index,:]\n",
    "        dev_y, val_y = train_y[dev_index], train_y[val_index]\n",
    "        \n",
    "        #random forest us\n",
    "        rf30 = ensemble.RandomForestClassifier(40,'entropy',random_state = 42,class_weight='balanced',n_jobs =4)\n",
    "        rf30.fit(dev_X,dev_y)\n",
    "        preds = rf30.predict_proba(val_X)\n",
    "        \n",
    "        cv_scores.append(log_loss(val_y, preds))\n",
    "\n",
    "print(cv_scores)\n",
    "print np.mean(cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.77877718302774535, 0.81746625031163511, 0.8264890405946187, 0.76887150006849192, 0.79372930664408248]\n",
      "0.797066656129\n"
     ]
    }
   ],
   "source": [
    "#cross-validation\n",
    "cv_scores = []\n",
    "\n",
    "#usning gini\n",
    "for dev_index, val_index in KF:\n",
    "        dev_X, val_X = train_X.iloc[dev_index,:], train_X.iloc[val_index,:]\n",
    "        dev_y, val_y = train_y[dev_index], train_y[val_index]\n",
    "        \n",
    "        #random forest us\n",
    "        rf30 = ensemble.RandomForestClassifier(40,random_state = 42,class_weight='balanced',n_jobs =4)\n",
    "        rf30.fit(dev_X,dev_y)\n",
    "        preds = rf30.predict_proba(val_X)\n",
    "        \n",
    "        cv_scores.append(log_loss(val_y, preds))\n",
    "\n",
    "print(cv_scores)\n",
    "print np.mean(cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\__init__.py:93: DeprecationWarning: Function transform is deprecated; Support to use estimators as feature selectors will be removed in version 0.19. Use SelectFromModel instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The importance of bathrooms:0.00956833183615\n",
      "The importance of bedrooms:0.0340186837628\n",
      "The importance of latitude:0.069102380505\n",
      "The importance of longitude:0.0655026445719\n",
      "The importance of price:0.12589901976\n",
      "The importance of num_photos:0.0253333787294\n",
      "The importance of num_features:0.0226569119691\n",
      "The importance of num_description_words:0.0442462638534\n",
      "The importance of created_year:0.0\n",
      "The importance of created_month:0.00639664716156\n",
      "The importance of created_day:0.0276721388561\n",
      "The importance of created_hour:0.0218762746722\n",
      "The importance of num_photos:0.02580651389\n",
      "The importance of num_features:0.0228404045006\n",
      "The importance of num_description_words:0.0427328686161\n",
      "The importance of created_year:0.0\n",
      "The importance of created_month:0.00610253560645\n",
      "The importance of created_day:0.0284776448726\n",
      "The importance of listing_id:0.0515252657779\n",
      "The importance of created_hour:0.019956686499\n",
      "The importance of num_photos:0.025644014719\n",
      "The importance of num_features:0.022731499198\n",
      "The importance of num_description_words:0.0432846608876\n",
      "The importance of created_year:0.0\n",
      "The importance of created_month:0.00615394658154\n",
      "The importance of created_day:0.0283517484064\n",
      "The importance of created_hour:0.023829379797\n",
      "The importance of num_photos:0.0267358103566\n",
      "The importance of num_features:0.0228573916948\n",
      "The importance of num_description_words:0.0421485942418\n",
      "The importance of created_year:0.0\n",
      "The importance of created_month:0.00587618336988\n",
      "The importance of created_day:0.02848998932\n",
      "The importance of listing_id:0.0525382173196\n",
      "The importance of created_hour:0.0216439686676\n"
     ]
    }
   ],
   "source": [
    "rf30 = ensemble.RandomForestClassifier(40,random_state = 42,class_weight='balanced')\n",
    "y_train_prediceted=rf30.fit_transform(train_df[features_to_use],train_df[u'interest_level'])\n",
    "#using random forest testing the importance\n",
    "for i in range(len(features_to_use)):\n",
    "    print \"The importance of \"+features_to_use[i]+\":\"+str(rf30.feature_importances_[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#try xgboost\n",
    "#fucntion from SRK\n",
    "def runXGB(train_X, train_y, test_X, test_y=None, feature_names=None, seed_val=0, num_rounds=1000):\n",
    "    param = {}\n",
    "    param['objective'] = 'multi:softprob'\n",
    "    param['eta'] = 0.1\n",
    "    param['max_depth'] = 6\n",
    "    param['silent'] = 1\n",
    "    param['num_class'] = 3\n",
    "    param['eval_metric'] = \"mlogloss\"\n",
    "    param['min_child_weight'] = 1\n",
    "    param['subsample'] = 0.7\n",
    "    param['colsample_bytree'] = 0.7\n",
    "    param['seed'] = seed_val\n",
    "    num_rounds = num_rounds\n",
    "\n",
    "    plst = list(param.items())\n",
    "    xgtrain = xgb.DMatrix(train_X, label=train_y)\n",
    "\n",
    "    if test_y is not None:\n",
    "        xgtest = xgb.DMatrix(test_X, label=test_y)\n",
    "        watchlist = [ (xgtrain,'train'), (xgtest, 'test') ]\n",
    "        model = xgb.train(plst, xgtrain, num_rounds, watchlist, early_stopping_rounds=20)\n",
    "    else:\n",
    "        xgtest = xgb.DMatrix(test_X)\n",
    "        model = xgb.train(plst, xgtrain, num_rounds)\n",
    "\n",
    "    pred_test_y = model.predict(xgtest)\n",
    "    return pred_test_y, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:1.03929\ttest-mlogloss:1.04042\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[1]\ttrain-mlogloss:0.989238\ttest-mlogloss:0.991651\n",
      "[2]\ttrain-mlogloss:0.949522\ttest-mlogloss:0.952915\n",
      "[3]\ttrain-mlogloss:0.911372\ttest-mlogloss:0.915763\n",
      "[4]\ttrain-mlogloss:0.88116\ttest-mlogloss:0.886343\n",
      "[5]\ttrain-mlogloss:0.85213\ttest-mlogloss:0.858297\n",
      "[6]\ttrain-mlogloss:0.83001\ttest-mlogloss:0.837036\n",
      "[7]\ttrain-mlogloss:0.807276\ttest-mlogloss:0.815203\n",
      "[8]\ttrain-mlogloss:0.788864\ttest-mlogloss:0.797492\n",
      "[9]\ttrain-mlogloss:0.77175\ttest-mlogloss:0.781211\n",
      "[10]\ttrain-mlogloss:0.756505\ttest-mlogloss:0.766717\n",
      "[11]\ttrain-mlogloss:0.742759\ttest-mlogloss:0.75366\n",
      "[12]\ttrain-mlogloss:0.730125\ttest-mlogloss:0.741775\n",
      "[13]\ttrain-mlogloss:0.719421\ttest-mlogloss:0.731629\n",
      "[14]\ttrain-mlogloss:0.709882\ttest-mlogloss:0.722846\n",
      "[15]\ttrain-mlogloss:0.701253\ttest-mlogloss:0.714845\n",
      "[16]\ttrain-mlogloss:0.693011\ttest-mlogloss:0.707443\n",
      "[17]\ttrain-mlogloss:0.684908\ttest-mlogloss:0.699987\n",
      "[18]\ttrain-mlogloss:0.679298\ttest-mlogloss:0.694905\n",
      "[19]\ttrain-mlogloss:0.673191\ttest-mlogloss:0.689345\n",
      "[20]\ttrain-mlogloss:0.667187\ttest-mlogloss:0.683948\n",
      "[21]\ttrain-mlogloss:0.662661\ttest-mlogloss:0.68\n",
      "[22]\ttrain-mlogloss:0.657078\ttest-mlogloss:0.675025\n",
      "[23]\ttrain-mlogloss:0.652627\ttest-mlogloss:0.671203\n",
      "[24]\ttrain-mlogloss:0.648633\ttest-mlogloss:0.667874\n",
      "[25]\ttrain-mlogloss:0.644193\ttest-mlogloss:0.664077\n",
      "[26]\ttrain-mlogloss:0.641475\ttest-mlogloss:0.661823\n",
      "[27]\ttrain-mlogloss:0.638766\ttest-mlogloss:0.659797\n",
      "[28]\ttrain-mlogloss:0.636164\ttest-mlogloss:0.657855\n",
      "[29]\ttrain-mlogloss:0.633399\ttest-mlogloss:0.655714\n",
      "[30]\ttrain-mlogloss:0.63051\ttest-mlogloss:0.65364\n",
      "[31]\ttrain-mlogloss:0.627018\ttest-mlogloss:0.65104\n",
      "[32]\ttrain-mlogloss:0.624847\ttest-mlogloss:0.649394\n",
      "[33]\ttrain-mlogloss:0.621953\ttest-mlogloss:0.647109\n",
      "[34]\ttrain-mlogloss:0.618968\ttest-mlogloss:0.645032\n",
      "[35]\ttrain-mlogloss:0.616182\ttest-mlogloss:0.643009\n",
      "[36]\ttrain-mlogloss:0.613866\ttest-mlogloss:0.641343\n",
      "[37]\ttrain-mlogloss:0.611607\ttest-mlogloss:0.639494\n",
      "[38]\ttrain-mlogloss:0.608798\ttest-mlogloss:0.63736\n",
      "[39]\ttrain-mlogloss:0.606537\ttest-mlogloss:0.635785\n",
      "[40]\ttrain-mlogloss:0.603912\ttest-mlogloss:0.633791\n",
      "[41]\ttrain-mlogloss:0.601919\ttest-mlogloss:0.632557\n",
      "[42]\ttrain-mlogloss:0.600162\ttest-mlogloss:0.631378\n",
      "[43]\ttrain-mlogloss:0.598774\ttest-mlogloss:0.630506\n",
      "[44]\ttrain-mlogloss:0.597145\ttest-mlogloss:0.629412\n",
      "[45]\ttrain-mlogloss:0.595454\ttest-mlogloss:0.628437\n",
      "[46]\ttrain-mlogloss:0.593422\ttest-mlogloss:0.627145\n",
      "[47]\ttrain-mlogloss:0.592081\ttest-mlogloss:0.626493\n",
      "[48]\ttrain-mlogloss:0.590558\ttest-mlogloss:0.625698\n",
      "[49]\ttrain-mlogloss:0.589566\ttest-mlogloss:0.625086\n",
      "[50]\ttrain-mlogloss:0.587537\ttest-mlogloss:0.623865\n",
      "[51]\ttrain-mlogloss:0.586268\ttest-mlogloss:0.623092\n",
      "[52]\ttrain-mlogloss:0.584652\ttest-mlogloss:0.622207\n",
      "[53]\ttrain-mlogloss:0.582766\ttest-mlogloss:0.621076\n",
      "[54]\ttrain-mlogloss:0.581011\ttest-mlogloss:0.620048\n",
      "[55]\ttrain-mlogloss:0.579787\ttest-mlogloss:0.619395\n",
      "[56]\ttrain-mlogloss:0.578662\ttest-mlogloss:0.618713\n",
      "[57]\ttrain-mlogloss:0.577029\ttest-mlogloss:0.61777\n",
      "[58]\ttrain-mlogloss:0.57572\ttest-mlogloss:0.617195\n",
      "[59]\ttrain-mlogloss:0.573966\ttest-mlogloss:0.616152\n",
      "[60]\ttrain-mlogloss:0.572656\ttest-mlogloss:0.615398\n",
      "[61]\ttrain-mlogloss:0.571701\ttest-mlogloss:0.614974\n",
      "[62]\ttrain-mlogloss:0.570487\ttest-mlogloss:0.614468\n",
      "[63]\ttrain-mlogloss:0.569065\ttest-mlogloss:0.613994\n",
      "[64]\ttrain-mlogloss:0.568195\ttest-mlogloss:0.613608\n",
      "[65]\ttrain-mlogloss:0.566959\ttest-mlogloss:0.613078\n",
      "[66]\ttrain-mlogloss:0.565723\ttest-mlogloss:0.612558\n",
      "[67]\ttrain-mlogloss:0.564475\ttest-mlogloss:0.612109\n",
      "[68]\ttrain-mlogloss:0.563713\ttest-mlogloss:0.611753\n",
      "[69]\ttrain-mlogloss:0.562985\ttest-mlogloss:0.611472\n",
      "[70]\ttrain-mlogloss:0.562034\ttest-mlogloss:0.610985\n",
      "[71]\ttrain-mlogloss:0.560657\ttest-mlogloss:0.610105\n",
      "[72]\ttrain-mlogloss:0.559444\ttest-mlogloss:0.609494\n",
      "[73]\ttrain-mlogloss:0.55831\ttest-mlogloss:0.608842\n",
      "[74]\ttrain-mlogloss:0.557607\ttest-mlogloss:0.608597\n",
      "[75]\ttrain-mlogloss:0.556471\ttest-mlogloss:0.608022\n",
      "[76]\ttrain-mlogloss:0.55553\ttest-mlogloss:0.607555\n",
      "[77]\ttrain-mlogloss:0.554476\ttest-mlogloss:0.607302\n",
      "[78]\ttrain-mlogloss:0.553371\ttest-mlogloss:0.606997\n",
      "[79]\ttrain-mlogloss:0.552148\ttest-mlogloss:0.606491\n",
      "[80]\ttrain-mlogloss:0.551082\ttest-mlogloss:0.605888\n",
      "[81]\ttrain-mlogloss:0.550441\ttest-mlogloss:0.605511\n",
      "[82]\ttrain-mlogloss:0.549695\ttest-mlogloss:0.605171\n",
      "[83]\ttrain-mlogloss:0.548557\ttest-mlogloss:0.604724\n",
      "[84]\ttrain-mlogloss:0.547984\ttest-mlogloss:0.604659\n",
      "[85]\ttrain-mlogloss:0.546842\ttest-mlogloss:0.604162\n",
      "[86]\ttrain-mlogloss:0.54581\ttest-mlogloss:0.603779\n",
      "[87]\ttrain-mlogloss:0.544785\ttest-mlogloss:0.603317\n",
      "[88]\ttrain-mlogloss:0.54361\ttest-mlogloss:0.602797\n",
      "[89]\ttrain-mlogloss:0.542674\ttest-mlogloss:0.602545\n",
      "[90]\ttrain-mlogloss:0.541821\ttest-mlogloss:0.602233\n",
      "[91]\ttrain-mlogloss:0.541038\ttest-mlogloss:0.602054\n",
      "[92]\ttrain-mlogloss:0.5405\ttest-mlogloss:0.601896\n",
      "[93]\ttrain-mlogloss:0.539705\ttest-mlogloss:0.60162\n",
      "[94]\ttrain-mlogloss:0.539041\ttest-mlogloss:0.601403\n",
      "[95]\ttrain-mlogloss:0.538404\ttest-mlogloss:0.601196\n",
      "[96]\ttrain-mlogloss:0.53746\ttest-mlogloss:0.600939\n",
      "[97]\ttrain-mlogloss:0.536486\ttest-mlogloss:0.600591\n",
      "[98]\ttrain-mlogloss:0.535632\ttest-mlogloss:0.600316\n",
      "[99]\ttrain-mlogloss:0.534936\ttest-mlogloss:0.600114\n",
      "[100]\ttrain-mlogloss:0.534238\ttest-mlogloss:0.599893\n",
      "[101]\ttrain-mlogloss:0.533231\ttest-mlogloss:0.599558\n",
      "[102]\ttrain-mlogloss:0.532354\ttest-mlogloss:0.599349\n",
      "[103]\ttrain-mlogloss:0.531671\ttest-mlogloss:0.599281\n",
      "[104]\ttrain-mlogloss:0.53101\ttest-mlogloss:0.599157\n",
      "[105]\ttrain-mlogloss:0.530045\ttest-mlogloss:0.598907\n",
      "[106]\ttrain-mlogloss:0.52916\ttest-mlogloss:0.598565\n",
      "[107]\ttrain-mlogloss:0.528235\ttest-mlogloss:0.598371\n",
      "[108]\ttrain-mlogloss:0.527566\ttest-mlogloss:0.598144\n",
      "[109]\ttrain-mlogloss:0.526907\ttest-mlogloss:0.598036\n",
      "[110]\ttrain-mlogloss:0.52618\ttest-mlogloss:0.597903\n",
      "[111]\ttrain-mlogloss:0.525571\ttest-mlogloss:0.597667\n",
      "[112]\ttrain-mlogloss:0.524903\ttest-mlogloss:0.59744\n",
      "[113]\ttrain-mlogloss:0.524417\ttest-mlogloss:0.59738\n",
      "[114]\ttrain-mlogloss:0.523654\ttest-mlogloss:0.597094\n",
      "[115]\ttrain-mlogloss:0.522888\ttest-mlogloss:0.596972\n",
      "[116]\ttrain-mlogloss:0.522182\ttest-mlogloss:0.59679\n",
      "[117]\ttrain-mlogloss:0.521397\ttest-mlogloss:0.596654\n",
      "[118]\ttrain-mlogloss:0.52065\ttest-mlogloss:0.596398\n",
      "[119]\ttrain-mlogloss:0.519871\ttest-mlogloss:0.596249\n",
      "[120]\ttrain-mlogloss:0.519381\ttest-mlogloss:0.596237\n",
      "[121]\ttrain-mlogloss:0.518755\ttest-mlogloss:0.596233\n",
      "[122]\ttrain-mlogloss:0.518299\ttest-mlogloss:0.596072\n",
      "[123]\ttrain-mlogloss:0.517591\ttest-mlogloss:0.595896\n",
      "[124]\ttrain-mlogloss:0.516781\ttest-mlogloss:0.595579\n",
      "[125]\ttrain-mlogloss:0.515822\ttest-mlogloss:0.59534\n",
      "[126]\ttrain-mlogloss:0.515078\ttest-mlogloss:0.595199\n",
      "[127]\ttrain-mlogloss:0.514302\ttest-mlogloss:0.595067\n",
      "[128]\ttrain-mlogloss:0.513769\ttest-mlogloss:0.595024\n",
      "[129]\ttrain-mlogloss:0.513103\ttest-mlogloss:0.594834\n",
      "[130]\ttrain-mlogloss:0.512582\ttest-mlogloss:0.594648\n",
      "[131]\ttrain-mlogloss:0.511911\ttest-mlogloss:0.594486\n",
      "[132]\ttrain-mlogloss:0.51111\ttest-mlogloss:0.594276\n",
      "[133]\ttrain-mlogloss:0.510488\ttest-mlogloss:0.594049\n",
      "[134]\ttrain-mlogloss:0.509685\ttest-mlogloss:0.593762\n",
      "[135]\ttrain-mlogloss:0.509078\ttest-mlogloss:0.593661\n",
      "[136]\ttrain-mlogloss:0.508415\ttest-mlogloss:0.593584\n",
      "[137]\ttrain-mlogloss:0.508087\ttest-mlogloss:0.593625\n",
      "[138]\ttrain-mlogloss:0.507328\ttest-mlogloss:0.593559\n",
      "[139]\ttrain-mlogloss:0.506795\ttest-mlogloss:0.593466\n",
      "[140]\ttrain-mlogloss:0.50602\ttest-mlogloss:0.593241\n",
      "[141]\ttrain-mlogloss:0.505356\ttest-mlogloss:0.593116\n",
      "[142]\ttrain-mlogloss:0.504764\ttest-mlogloss:0.593107\n",
      "[143]\ttrain-mlogloss:0.504077\ttest-mlogloss:0.593081\n",
      "[144]\ttrain-mlogloss:0.503462\ttest-mlogloss:0.592808\n",
      "[145]\ttrain-mlogloss:0.503004\ttest-mlogloss:0.592871\n",
      "[146]\ttrain-mlogloss:0.502218\ttest-mlogloss:0.592636\n",
      "[147]\ttrain-mlogloss:0.501503\ttest-mlogloss:0.592481\n",
      "[148]\ttrain-mlogloss:0.500808\ttest-mlogloss:0.592304\n",
      "[149]\ttrain-mlogloss:0.500315\ttest-mlogloss:0.592212\n",
      "[150]\ttrain-mlogloss:0.499585\ttest-mlogloss:0.59218\n",
      "[151]\ttrain-mlogloss:0.498844\ttest-mlogloss:0.59219\n",
      "[152]\ttrain-mlogloss:0.498074\ttest-mlogloss:0.592136\n",
      "[153]\ttrain-mlogloss:0.497368\ttest-mlogloss:0.591896\n",
      "[154]\ttrain-mlogloss:0.496733\ttest-mlogloss:0.591725\n",
      "[155]\ttrain-mlogloss:0.49605\ttest-mlogloss:0.591535\n",
      "[156]\ttrain-mlogloss:0.495558\ttest-mlogloss:0.591333\n",
      "[157]\ttrain-mlogloss:0.494982\ttest-mlogloss:0.591207\n",
      "[158]\ttrain-mlogloss:0.49427\ttest-mlogloss:0.591127\n",
      "[159]\ttrain-mlogloss:0.493728\ttest-mlogloss:0.591115\n",
      "[160]\ttrain-mlogloss:0.49333\ttest-mlogloss:0.59108\n",
      "[161]\ttrain-mlogloss:0.492673\ttest-mlogloss:0.591204\n",
      "[162]\ttrain-mlogloss:0.492166\ttest-mlogloss:0.591255\n",
      "[163]\ttrain-mlogloss:0.491418\ttest-mlogloss:0.590941\n",
      "[164]\ttrain-mlogloss:0.490828\ttest-mlogloss:0.590931\n",
      "[165]\ttrain-mlogloss:0.490462\ttest-mlogloss:0.590929\n",
      "[166]\ttrain-mlogloss:0.490069\ttest-mlogloss:0.590772\n",
      "[167]\ttrain-mlogloss:0.489587\ttest-mlogloss:0.590698\n",
      "[168]\ttrain-mlogloss:0.489044\ttest-mlogloss:0.590606\n",
      "[169]\ttrain-mlogloss:0.488607\ttest-mlogloss:0.590662\n",
      "[170]\ttrain-mlogloss:0.488101\ttest-mlogloss:0.590551\n",
      "[171]\ttrain-mlogloss:0.487645\ttest-mlogloss:0.590451\n",
      "[172]\ttrain-mlogloss:0.487088\ttest-mlogloss:0.590337\n",
      "[173]\ttrain-mlogloss:0.486326\ttest-mlogloss:0.590322\n",
      "[174]\ttrain-mlogloss:0.485804\ttest-mlogloss:0.590243\n",
      "[175]\ttrain-mlogloss:0.485282\ttest-mlogloss:0.590246\n",
      "[176]\ttrain-mlogloss:0.484755\ttest-mlogloss:0.590155\n",
      "[177]\ttrain-mlogloss:0.484159\ttest-mlogloss:0.590025\n",
      "[178]\ttrain-mlogloss:0.483618\ttest-mlogloss:0.589941\n",
      "[179]\ttrain-mlogloss:0.483158\ttest-mlogloss:0.589883\n",
      "[180]\ttrain-mlogloss:0.482747\ttest-mlogloss:0.589899\n",
      "[181]\ttrain-mlogloss:0.482088\ttest-mlogloss:0.589716\n",
      "[182]\ttrain-mlogloss:0.481764\ttest-mlogloss:0.589626\n",
      "[183]\ttrain-mlogloss:0.481171\ttest-mlogloss:0.589648\n",
      "[184]\ttrain-mlogloss:0.48048\ttest-mlogloss:0.589498\n",
      "[185]\ttrain-mlogloss:0.48001\ttest-mlogloss:0.589434\n",
      "[186]\ttrain-mlogloss:0.479424\ttest-mlogloss:0.58947\n",
      "[187]\ttrain-mlogloss:0.479005\ttest-mlogloss:0.58948\n",
      "[188]\ttrain-mlogloss:0.478527\ttest-mlogloss:0.589442\n",
      "[189]\ttrain-mlogloss:0.478129\ttest-mlogloss:0.58945\n",
      "[190]\ttrain-mlogloss:0.477709\ttest-mlogloss:0.589344\n",
      "[191]\ttrain-mlogloss:0.477047\ttest-mlogloss:0.58931\n",
      "[192]\ttrain-mlogloss:0.47657\ttest-mlogloss:0.589271\n",
      "[193]\ttrain-mlogloss:0.47592\ttest-mlogloss:0.589114\n",
      "[194]\ttrain-mlogloss:0.475389\ttest-mlogloss:0.589151\n",
      "[195]\ttrain-mlogloss:0.475072\ttest-mlogloss:0.589088\n",
      "[196]\ttrain-mlogloss:0.474533\ttest-mlogloss:0.589094\n",
      "[197]\ttrain-mlogloss:0.473956\ttest-mlogloss:0.589101\n",
      "[198]\ttrain-mlogloss:0.473504\ttest-mlogloss:0.589035\n",
      "[199]\ttrain-mlogloss:0.472882\ttest-mlogloss:0.588958\n",
      "[200]\ttrain-mlogloss:0.472309\ttest-mlogloss:0.588865\n",
      "[201]\ttrain-mlogloss:0.471857\ttest-mlogloss:0.588704\n",
      "[202]\ttrain-mlogloss:0.471249\ttest-mlogloss:0.588481\n",
      "[203]\ttrain-mlogloss:0.470826\ttest-mlogloss:0.588478\n",
      "[204]\ttrain-mlogloss:0.470227\ttest-mlogloss:0.588407\n",
      "[205]\ttrain-mlogloss:0.469514\ttest-mlogloss:0.588451\n",
      "[206]\ttrain-mlogloss:0.469114\ttest-mlogloss:0.588344\n",
      "[207]\ttrain-mlogloss:0.468596\ttest-mlogloss:0.588459\n",
      "[208]\ttrain-mlogloss:0.468306\ttest-mlogloss:0.588421\n",
      "[209]\ttrain-mlogloss:0.467865\ttest-mlogloss:0.588531\n",
      "[210]\ttrain-mlogloss:0.467245\ttest-mlogloss:0.588435\n",
      "[211]\ttrain-mlogloss:0.466645\ttest-mlogloss:0.588371\n",
      "[212]\ttrain-mlogloss:0.466143\ttest-mlogloss:0.588379\n",
      "[213]\ttrain-mlogloss:0.465766\ttest-mlogloss:0.588431\n",
      "[214]\ttrain-mlogloss:0.465103\ttest-mlogloss:0.588444\n",
      "[215]\ttrain-mlogloss:0.464596\ttest-mlogloss:0.588344\n",
      "[216]\ttrain-mlogloss:0.464159\ttest-mlogloss:0.588288\n",
      "[217]\ttrain-mlogloss:0.463591\ttest-mlogloss:0.588302\n",
      "[218]\ttrain-mlogloss:0.463175\ttest-mlogloss:0.588212\n",
      "[219]\ttrain-mlogloss:0.462671\ttest-mlogloss:0.58822\n",
      "[220]\ttrain-mlogloss:0.462317\ttest-mlogloss:0.588252\n",
      "[221]\ttrain-mlogloss:0.461762\ttest-mlogloss:0.588192\n",
      "[222]\ttrain-mlogloss:0.461201\ttest-mlogloss:0.588133\n",
      "[223]\ttrain-mlogloss:0.460854\ttest-mlogloss:0.588119\n",
      "[224]\ttrain-mlogloss:0.460444\ttest-mlogloss:0.588098\n",
      "[225]\ttrain-mlogloss:0.46005\ttest-mlogloss:0.588127\n",
      "[226]\ttrain-mlogloss:0.459643\ttest-mlogloss:0.587998\n",
      "[227]\ttrain-mlogloss:0.459062\ttest-mlogloss:0.588009\n",
      "[228]\ttrain-mlogloss:0.458481\ttest-mlogloss:0.587884\n",
      "[229]\ttrain-mlogloss:0.458007\ttest-mlogloss:0.587887\n",
      "[230]\ttrain-mlogloss:0.457559\ttest-mlogloss:0.5879\n",
      "[231]\ttrain-mlogloss:0.457027\ttest-mlogloss:0.587866\n",
      "[232]\ttrain-mlogloss:0.456523\ttest-mlogloss:0.587895\n",
      "[233]\ttrain-mlogloss:0.45623\ttest-mlogloss:0.587876\n",
      "[234]\ttrain-mlogloss:0.45578\ttest-mlogloss:0.587789\n",
      "[235]\ttrain-mlogloss:0.455201\ttest-mlogloss:0.587676\n",
      "[236]\ttrain-mlogloss:0.454596\ttest-mlogloss:0.587766\n",
      "[237]\ttrain-mlogloss:0.454087\ttest-mlogloss:0.587889\n",
      "[238]\ttrain-mlogloss:0.453529\ttest-mlogloss:0.587926\n",
      "[239]\ttrain-mlogloss:0.453087\ttest-mlogloss:0.587871\n",
      "[240]\ttrain-mlogloss:0.452675\ttest-mlogloss:0.587905\n",
      "[241]\ttrain-mlogloss:0.4523\ttest-mlogloss:0.58789\n",
      "[242]\ttrain-mlogloss:0.451825\ttest-mlogloss:0.587928\n",
      "[243]\ttrain-mlogloss:0.451295\ttest-mlogloss:0.587944\n",
      "[244]\ttrain-mlogloss:0.45075\ttest-mlogloss:0.587974\n",
      "[245]\ttrain-mlogloss:0.450228\ttest-mlogloss:0.58785\n",
      "[246]\ttrain-mlogloss:0.44978\ttest-mlogloss:0.587863\n",
      "[247]\ttrain-mlogloss:0.449317\ttest-mlogloss:0.587869\n",
      "[248]\ttrain-mlogloss:0.448944\ttest-mlogloss:0.587784\n",
      "[249]\ttrain-mlogloss:0.448558\ttest-mlogloss:0.587783\n",
      "[250]\ttrain-mlogloss:0.448121\ttest-mlogloss:0.587693\n",
      "[251]\ttrain-mlogloss:0.447758\ttest-mlogloss:0.587606\n",
      "[252]\ttrain-mlogloss:0.447203\ttest-mlogloss:0.587644\n",
      "[253]\ttrain-mlogloss:0.446871\ttest-mlogloss:0.587699\n",
      "[254]\ttrain-mlogloss:0.446431\ttest-mlogloss:0.587681\n",
      "[255]\ttrain-mlogloss:0.446057\ttest-mlogloss:0.587629\n",
      "[256]\ttrain-mlogloss:0.445612\ttest-mlogloss:0.587508\n",
      "[257]\ttrain-mlogloss:0.445185\ttest-mlogloss:0.587529\n",
      "[258]\ttrain-mlogloss:0.444745\ttest-mlogloss:0.58765\n",
      "[259]\ttrain-mlogloss:0.44425\ttest-mlogloss:0.587686\n",
      "[260]\ttrain-mlogloss:0.443948\ttest-mlogloss:0.587767\n",
      "[261]\ttrain-mlogloss:0.443485\ttest-mlogloss:0.587724\n",
      "[262]\ttrain-mlogloss:0.442783\ttest-mlogloss:0.587686\n",
      "[263]\ttrain-mlogloss:0.442294\ttest-mlogloss:0.587673\n",
      "[264]\ttrain-mlogloss:0.441751\ttest-mlogloss:0.587583\n",
      "[265]\ttrain-mlogloss:0.441443\ttest-mlogloss:0.587571\n",
      "[266]\ttrain-mlogloss:0.441077\ttest-mlogloss:0.5876\n",
      "[267]\ttrain-mlogloss:0.440664\ttest-mlogloss:0.587408\n",
      "[268]\ttrain-mlogloss:0.440127\ttest-mlogloss:0.587449\n",
      "[269]\ttrain-mlogloss:0.439686\ttest-mlogloss:0.587363\n",
      "[270]\ttrain-mlogloss:0.439376\ttest-mlogloss:0.587345\n",
      "[271]\ttrain-mlogloss:0.438999\ttest-mlogloss:0.587241\n",
      "[272]\ttrain-mlogloss:0.438451\ttest-mlogloss:0.587379\n",
      "[273]\ttrain-mlogloss:0.438022\ttest-mlogloss:0.587322\n",
      "[274]\ttrain-mlogloss:0.437643\ttest-mlogloss:0.587274\n",
      "[275]\ttrain-mlogloss:0.437227\ttest-mlogloss:0.587279\n",
      "[276]\ttrain-mlogloss:0.436923\ttest-mlogloss:0.587234\n",
      "[277]\ttrain-mlogloss:0.436604\ttest-mlogloss:0.587186\n",
      "[278]\ttrain-mlogloss:0.436148\ttest-mlogloss:0.587118\n",
      "[279]\ttrain-mlogloss:0.435696\ttest-mlogloss:0.586975\n",
      "[280]\ttrain-mlogloss:0.435241\ttest-mlogloss:0.586886\n",
      "[281]\ttrain-mlogloss:0.434768\ttest-mlogloss:0.587019\n",
      "[282]\ttrain-mlogloss:0.434271\ttest-mlogloss:0.586975\n",
      "[283]\ttrain-mlogloss:0.433803\ttest-mlogloss:0.586898\n",
      "[284]\ttrain-mlogloss:0.433301\ttest-mlogloss:0.586889\n",
      "[285]\ttrain-mlogloss:0.432866\ttest-mlogloss:0.587022\n",
      "[286]\ttrain-mlogloss:0.432478\ttest-mlogloss:0.587021\n",
      "[287]\ttrain-mlogloss:0.432082\ttest-mlogloss:0.587059\n",
      "[288]\ttrain-mlogloss:0.431623\ttest-mlogloss:0.587026\n",
      "[289]\ttrain-mlogloss:0.431206\ttest-mlogloss:0.587136\n",
      "[290]\ttrain-mlogloss:0.430942\ttest-mlogloss:0.58706\n",
      "[291]\ttrain-mlogloss:0.430566\ttest-mlogloss:0.586992\n",
      "[292]\ttrain-mlogloss:0.430099\ttest-mlogloss:0.586958\n",
      "[293]\ttrain-mlogloss:0.429752\ttest-mlogloss:0.586943\n",
      "[294]\ttrain-mlogloss:0.429343\ttest-mlogloss:0.586995\n",
      "[295]\ttrain-mlogloss:0.42881\ttest-mlogloss:0.587023\n",
      "[296]\ttrain-mlogloss:0.428382\ttest-mlogloss:0.586991\n",
      "[297]\ttrain-mlogloss:0.428016\ttest-mlogloss:0.586988\n",
      "[298]\ttrain-mlogloss:0.427678\ttest-mlogloss:0.587013\n",
      "[299]\ttrain-mlogloss:0.427245\ttest-mlogloss:0.586972\n",
      "[300]\ttrain-mlogloss:0.426795\ttest-mlogloss:0.58686\n",
      "[301]\ttrain-mlogloss:0.426286\ttest-mlogloss:0.586843\n",
      "[302]\ttrain-mlogloss:0.425888\ttest-mlogloss:0.586881\n",
      "[303]\ttrain-mlogloss:0.425469\ttest-mlogloss:0.586855\n",
      "[304]\ttrain-mlogloss:0.425178\ttest-mlogloss:0.586851\n",
      "[305]\ttrain-mlogloss:0.424752\ttest-mlogloss:0.586911\n",
      "[306]\ttrain-mlogloss:0.424324\ttest-mlogloss:0.587005\n",
      "[307]\ttrain-mlogloss:0.423754\ttest-mlogloss:0.587007\n",
      "[308]\ttrain-mlogloss:0.423358\ttest-mlogloss:0.586993\n",
      "[309]\ttrain-mlogloss:0.4229\ttest-mlogloss:0.587139\n",
      "[310]\ttrain-mlogloss:0.422548\ttest-mlogloss:0.587226\n",
      "[311]\ttrain-mlogloss:0.422053\ttest-mlogloss:0.58712\n",
      "[312]\ttrain-mlogloss:0.421621\ttest-mlogloss:0.5872\n",
      "[313]\ttrain-mlogloss:0.421201\ttest-mlogloss:0.587232\n",
      "[314]\ttrain-mlogloss:0.420784\ttest-mlogloss:0.587272\n",
      "[315]\ttrain-mlogloss:0.420455\ttest-mlogloss:0.587221\n",
      "[316]\ttrain-mlogloss:0.419961\ttest-mlogloss:0.587256\n",
      "[317]\ttrain-mlogloss:0.419523\ttest-mlogloss:0.587378\n",
      "[318]\ttrain-mlogloss:0.419062\ttest-mlogloss:0.587405\n",
      "[319]\ttrain-mlogloss:0.418722\ttest-mlogloss:0.587518\n",
      "[320]\ttrain-mlogloss:0.41838\ttest-mlogloss:0.587504\n",
      "[321]\ttrain-mlogloss:0.417819\ttest-mlogloss:0.58744\n",
      "Stopping. Best iteration:\n",
      "[301]\ttrain-mlogloss:0.426286\ttest-mlogloss:0.586843\n",
      "\n",
      "[0.58744014564170066]\n"
     ]
    }
   ],
   "source": [
    "#running and getting the cv from xgboost\n",
    "cv_scores = []\n",
    "#K-FOLD already defined.If not ,use\n",
    "#KF=KFold(len(train_X),5,shuffle=True,random_state = 42)\n",
    "for dev_index, val_index in KF:\n",
    "        dev_X, val_X = train_X.iloc[dev_index,:].as_matrix(), train_X.iloc[val_index,:].as_matrix()\n",
    "        dev_y, val_y = train_y[dev_index], train_y[val_index]\n",
    "        preds, model = runXGB(dev_X, dev_y, val_X, val_y)\n",
    "        cv_scores.append(log_loss(val_y, preds))\n",
    "        print(cv_scores)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#output the outcome - using xgboost\n",
    "train_X_m = train_X.as_matrix()\n",
    "test_X_m = test_X.as_matrix()\n",
    "\n",
    "preds, model = runXGB(train_X_m, train_y, test_X_m, num_rounds=400)\n",
    "out_df = pd.DataFrame(preds)\n",
    "out_df.columns = [\"high\", \"medium\", \"low\"]\n",
    "out_df[\"listing_id\"] = test_df.listing_id.values\n",
    "out_df.to_csv(\"xgb_alpha.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
