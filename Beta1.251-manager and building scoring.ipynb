{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn import  preprocessing, ensemble\n",
    "from sklearn.metrics import log_loss,accuracy_score\n",
    "from sklearn.cross_validation import KFold,StratifiedKFold\n",
    "import re\n",
    "import string\n",
    "from collections import defaultdict, Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#try xgboost\n",
    "#fucntion from SRK\n",
    "def runXGB(train_X, train_y, test_X, test_y=None, feature_names=None, \\\n",
    "     seed_val=0, early_stop = 20,num_rounds=10000, eta = 0.1, max_depth = 6):\n",
    "    param = {}\n",
    "    param['objective'] = 'multi:softprob'\n",
    "    param['eta'] = eta\n",
    "    param['max_depth'] = max_depth\n",
    "    param['silent'] = 1\n",
    "    param['num_class'] = 3\n",
    "    param['eval_metric'] = \"mlogloss\"\n",
    "    param['min_child_weight'] = 1\n",
    "    param['subsample'] = 0.7\n",
    "    param['colsample_bytree'] = 0.7\n",
    "    param['seed'] = seed_val\n",
    "    num_rounds = num_rounds\n",
    "\n",
    "    plst = list(param.items())\n",
    "    xgtrain = xgb.DMatrix(train_X, label=train_y,feature_names=feature_names)\n",
    "\n",
    "    if test_y is not None:\n",
    "        xgtest = xgb.DMatrix(test_X, label=test_y,feature_names=feature_names)\n",
    "        watchlist = [ (xgtrain,'train'), (xgtest, 'test') ]\n",
    "        model = xgb.train(plst, xgtrain, num_rounds, watchlist,\\\n",
    "        early_stopping_rounds=early_stop)\n",
    "    else:\n",
    "        xgtest = xgb.DMatrix(test_X,feature_names=feature_names)\n",
    "        model = xgb.train(plst, xgtrain, num_rounds)\n",
    "\n",
    "    pred_test_y = model.predict(xgtest)\n",
    "    return pred_test_y, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#feature processing functions\n",
    "#define punctutaion filter\n",
    "def removePunctuation(x):\n",
    "    #filter the head or tail blanks\n",
    "    x = re.sub(r'^\\s+',r' ',x)\n",
    "    x = re.sub(r'\\s+$',r' ',x)\n",
    "    \n",
    "    # Lowercasing all words\n",
    "    x = x.lower()\n",
    "    # Removing non ASCII chars, warning if you are dealing with other languages!!!!!!!!!!!!!!!\n",
    "    x = re.sub(r'[^\\x00-\\x7f]',r' ',x)\n",
    "    #change all the blank to space\n",
    "    x = re.sub(r'\\s',r' ',x)\n",
    "    # Removing (replacing with empty spaces actually) all the punctuations\n",
    "    removing = string.punctuation#.replace('-','')# except '-'\n",
    "    removed = re.sub(\"[\"+removing+\"]\", \"\", x)\n",
    "    #removing the line-changing\n",
    "    #removed = re.sub('\\\\n',\" \",removed)    \n",
    "    return removed\n",
    "\n",
    "#feature processing functions\n",
    "def proecessStreet(address):\n",
    "    #remove the building number\n",
    "    pattern = re.compile('^[\\d-]*[\\s]+')\n",
    "    street = removePunctuation(pattern.sub('',address))\n",
    "    \n",
    "    #sub the st to street\n",
    "    pattern = re.compile('( st)$')\n",
    "    street = pattern.sub(' street',street)\n",
    "    \n",
    "    #sub the ave to avenue\n",
    "    pattern = re.compile('( ave)$')\n",
    "    street = pattern.sub(' avenue',street)\n",
    "    \n",
    "    pattern = re.compile('(\\d+)((th)|(st)|(rd)|(nd))')\n",
    "    street = pattern.sub('\\g<1>',street)\n",
    "    \n",
    "    #deal with the w 14 street => west 14 street\n",
    "    pattern = re.compile('(w)(\\s+)(\\d+)')    \n",
    "    street = pattern.sub('west \\g<3>',street)\n",
    "    \n",
    "    #deal with the e....\n",
    "    pattern = re.compile('(e)(\\s+)(\\d+)')    \n",
    "    street = pattern.sub('east \\g<3>',street)\n",
    "    \n",
    "    return street\n",
    "    \n",
    "#from \"this is a lit\"s python version by rakhlin\n",
    "def singleValueConvert(df1,df2,column,minimum_size=5):\n",
    "    ps = df1[column].append(df2[column])\n",
    "    grouped = ps.groupby(ps).size().to_frame().rename(columns={0: \"size\"})\n",
    "    df1.loc[df1.join(grouped, on=column, how=\"left\")[\"size\"] <= minimum_size, column] = -1\n",
    "    df2.loc[df2.join(grouped, on=column, how=\"left\")[\"size\"] <= minimum_size, column] = -1\n",
    "    return df1, df2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def performance_eval(train_df,test_df,feature,k,g=1,f=1,update_df =None,random = None):\n",
    "    target_num_map = {'High':2, 'Medium':1, 'Low':0}\n",
    "    temp=pd.concat([train_df[feature],pd.get_dummies(train_df.interest_level)], axis = 1)\\\n",
    "         .groupby(feature).mean()\n",
    "     \n",
    "    new_feature = feature+'_perf'\n",
    "    \n",
    "    temp.columns = ['tempHigh','tempLow', 'tempMed']\n",
    "    \n",
    "    temp['count'] = train_df.groupby(feature).count().iloc[:,1]\n",
    "    temp[\"lambda\"] = g / (g + np.exp((k - temp[\"count\"] )/f))\n",
    "    temp[feature+'_origin'] = temp['tempHigh']*2 + temp['tempMed']\n",
    "    mean_values = temp.loc[:, feature+'_origin'].mean()\n",
    "    \n",
    "    temp[new_feature] = temp[\"lambda\"]*temp[feature+'_origin']+(1-temp[\"lambda\"])*mean_values    \n",
    "    \n",
    "    # Add uniform noise. Not mentioned in original paper.adding to each manager\n",
    "    if random:\n",
    "        temp[new_feature] *= np.random.uniform(1 - random, 1 + random, len(temp))     \n",
    "\n",
    "    value = test_df[[feature]].join(temp, on=feature, how=\"left\")[new_feature].fillna(mean_values)\n",
    "    \n",
    "    if update_df is None: update_df = test_df\n",
    "    if new_feature not in update_df.columns: update_df[new_feature] = np.nan\n",
    "    update_df.update(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#hcc encoding for building id instead of the performance eval\n",
    "def hcc_scoring(train_df,test_df,feature,labelValue,randomize=0.01,k=5,f=1,g=1,unrank_threshold =5,update_df =None):    \n",
    "    #input is the train dataframe with its labels mapped to dummies\n",
    "    #such as:\n",
    "    tempTrain = train_df.join(pd.get_dummies(train_df[u'interest_level']).astype(int))\n",
    "    \n",
    "    new_feature = '_'.join(['hcc',feature,labelValue])\n",
    "    \n",
    "    #take the mean  for the feature on the given featureValue which is mapped to dummies\n",
    "    prob = tempTrain[labelValue].mean()\n",
    "    \n",
    "    #take the mean and count for each feature value\n",
    "    grouped = tempTrain.groupby(feature)[labelValue].agg({'count':'size','mean':'mean'})\n",
    "    \n",
    "    #perform the transform for lambda and the final score\n",
    "    grouped[\"lambda\"] = g / (g + np.exp((k - grouped[\"count\"]) / f))\n",
    "    grouped[new_feature] = grouped['lambda']*grouped['mean']+(1-grouped['lambda'])*prob\n",
    "    \n",
    "    #get the average score for the unrank features and reset them to this average\n",
    "    unrankedMean = grouped.ix[grouped['count']<unrank_threshold,new_feature].mean()\n",
    "    grouped.ix[grouped['count']<unrank_threshold,new_feature] = unrankedMean\n",
    "    grouped = grouped.reset_index()\n",
    "    \n",
    "    #adding to the test_df\n",
    "    update_value  = test_df[[feature]].merge(grouped,on = feature,how='left')[new_feature].fillna(prob)\n",
    "    \n",
    "    if randomize : update_value *= np.random.uniform(1 - randomize, 1 + randomize, len(test_df))\n",
    "        \n",
    "    #adding some noise to the new \n",
    "    #print 'New feature added:'+new_feature\n",
    "\n",
    "    if update_df is None:\n",
    "        update_df = test_df\n",
    "    if new_feature not in update_df.columns: \n",
    "        update_df[new_feature] = np.nan\n",
    "        \n",
    "    update_df.update(update_value)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#functions for features\n",
    "def featureList(train_df,test_df,limit = 0.001):\n",
    "    #acquiring the feature lists\n",
    "    features_in_train = train_df[\"features\"].apply(pd.Series).unstack().reset_index(drop = True).dropna().value_counts()\n",
    "    features_in_test = test_df[\"features\"].apply(pd.Series).unstack().reset_index(drop = True).dropna().value_counts()\n",
    "    \n",
    "    filtered_features_in_train = features_in_train[features_in_train > limit*len(train_df)]\n",
    "    filtered_features_in_test = features_in_test[features_in_test > limit*len(test_df)]\n",
    "    accept_list = set(filtered_features_in_train.index).union(set(filtered_features_in_test.index))\n",
    "    return accept_list\n",
    "\n",
    "def featureMapping(train_df,test_df,feature_list):\n",
    "    for feature in feature_list:\n",
    "        #add the feature column for both\n",
    "        #if feature in the row, then set the value for (row,feature) to 1\n",
    "        train_df['with_'+feature]=train_df['features'].apply(lambda x : 1 if feature in x else 0)\n",
    "        test_df['with_'+feature]=test_df['features'].apply(lambda x : 1 if feature in x else 0)\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49352, 15)\n",
      "(74659, 14)\n"
     ]
    }
   ],
   "source": [
    "#lodaing data\n",
    "data_path = \"../../kaggleData/2sigma/\"\n",
    "train_file = data_path + \"train.json\"\n",
    "test_file = data_path + \"test.json\"\n",
    "train_df = pd.read_json(train_file)\n",
    "test_df = pd.read_json(test_file)\n",
    "print(train_df.shape)\n",
    "print(test_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#basic numerical features\n",
    "features_to_use  = [\"bathrooms\", \"bedrooms\", \"latitude\", \"longitude\", \"price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#some new numerical features related to the price\n",
    "train_df[\"price_per_bath\"] =  (train_df[\"price\"]*1.0/train_df[\"bathrooms\"]).replace(np.Inf,-1)\n",
    "train_df[\"price_per_bed\"] = (train_df[\"price\"]*1.0/train_df[\"bedrooms\"]).replace(np.Inf,-1)\n",
    "train_df[\"bath_per_bed\"] = (train_df[\"bathrooms\"]*1.0/train_df[\"bedrooms\"]).replace(np.Inf,-1)\n",
    "train_df[\"price_per_room\"] = (train_df[\"price\"]*1.0/(train_df[\"bedrooms\"]+train_df[\"bathrooms\"])).replace(np.Inf,-1)\n",
    "\n",
    "test_df[\"price_per_bath\"] =  (test_df[\"price\"]*1.0/test_df[\"bathrooms\"]).replace(np.Inf,-1)\n",
    "test_df[\"price_per_bed\"] = (test_df[\"price\"]*1.0/test_df[\"bedrooms\"]).replace(np.Inf,-1)\n",
    "test_df[\"bath_per_bed\"] = (test_df[\"bathrooms\"]*1.0/test_df[\"bedrooms\"]).replace(np.Inf,-1)\n",
    "test_df[\"price_per_room\"] = (test_df[\"price\"]*1.0/(test_df[\"bedrooms\"]+test_df[\"bathrooms\"])).replace(np.Inf,-1)\n",
    "\n",
    "features_to_use.extend([\"price_per_bed\",\"bath_per_bed\",\"price_per_room\"])\n",
    "#features_to_use.append('price_per_bed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#some transfromed features\n",
    "# count of photos #\n",
    "train_df[\"num_photos\"] = train_df[\"photos\"].apply(len)\n",
    "test_df[\"num_photos\"] = test_df[\"photos\"].apply(len)\n",
    "\n",
    "# count of \"features\" #\n",
    "train_df[\"num_features\"] = train_df[\"features\"].apply(len)\n",
    "test_df[\"num_features\"] = test_df[\"features\"].apply(len)\n",
    "\n",
    "# count of words present in description column #\n",
    "train_df[\"num_description_words\"] = train_df[\"description\"].apply(lambda x: len(x.split(\" \")))\n",
    "test_df[\"num_description_words\"] = test_df[\"description\"].apply(lambda x: len(x.split(\" \")))\n",
    "\n",
    "# convert the created column to datetime object so as to extract more features \n",
    "train_df[\"created\"] = pd.to_datetime(train_df[\"created\"])\n",
    "test_df[\"created\"] = pd.to_datetime(test_df[\"created\"])\n",
    "\n",
    "# Let us extract some features like year, month, day, hour from date columns #\n",
    "train_df[\"created_year\"] = train_df[\"created\"].dt.year\n",
    "test_df[\"created_year\"] = test_df[\"created\"].dt.year\n",
    "train_df[\"created_month\"] = train_df[\"created\"].dt.month\n",
    "test_df[\"created_month\"] = test_df[\"created\"].dt.month\n",
    "train_df[\"created_day\"] = train_df[\"created\"].dt.day\n",
    "test_df[\"created_day\"] = test_df[\"created\"].dt.day\n",
    "train_df[\"created_hour\"] = train_df[\"created\"].dt.hour\n",
    "test_df[\"created_hour\"] = test_df[\"created\"].dt.hour\n",
    "\n",
    "# adding all these new features to use list # \"listing_id\",\n",
    "features_to_use.extend([\"num_photos\", \"num_features\", \"num_description_words\",\"created_year\",\"listing_id\", \"created_month\", \"created_day\", \"created_hour\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "new categorical data append and converting label dummies for future use\n",
    "\"\"\"\n",
    "#new feature for the street_address, use them instead of the original one\n",
    "train_df[\"street_name\"] = train_df[\"street_address\"].apply(proecessStreet)\n",
    "test_df[\"street_name\"] = test_df[\"street_address\"].apply(proecessStreet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#dealing with features\n",
    "\n",
    "#preprocessing for features\n",
    "train_df[\"features\"] = train_df[\"features\"].apply(lambda x:[\"_\".join(i.split(\" \")).lower().strip().replace('-','_') \\\n",
    "                                                            for i in x])\n",
    "test_df[\"features\"] = test_df[\"features\"].apply(lambda x:[\"_\".join(i.split(\" \")).lower().strip().replace('-','_')\\\n",
    "                                                          for i in x])\n",
    "#create the accept list\n",
    "accept_list = list(featureList(train_df,test_df,limit = 0.001))\n",
    "\n",
    "#map the feature to dummy slots\n",
    "featureMapping(train_df,test_df,accept_list)\n",
    "features_to_use.extend(map(lambda x : 'with_'+x,accept_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#prepare for training\n",
    "target_num_map = {'high':0, 'medium':1, 'low':2}\n",
    "\n",
    "train_y = np.array(train_df['interest_level'].apply(lambda x: target_num_map[x]))\n",
    "\n",
    "KF=StratifiedKFold(train_y,5,shuffle=True,random_state = 42)\n",
    "\n",
    "train_df = train_df.fillna(-1)\n",
    "test_df = test_df.fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_to_use.extend(['manager_id_perf'])\n",
    "features_to_use.extend(['hcc_building_id_medium'])\n",
    "features_to_use.extend(['hcc_building_id_high'])\n",
    "\n",
    "#using these categorical features for direct labeling\n",
    "categorical = [\"display_address\", \"street_address\",\"street_name\",'manager_id']\n",
    "features_to_use.extend(categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_to_use.remove('hcc_building_id_high')\n",
    "features_to_use.remove('hcc_building_id_medium')\n",
    "features_to_use.remove('street_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#features_to_use.append('building_id')\n",
    "categorical.append('building_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bathrooms',\n",
       " 'bedrooms',\n",
       " 'latitude',\n",
       " 'longitude',\n",
       " 'price',\n",
       " 'price_per_bed',\n",
       " 'bath_per_bed',\n",
       " 'price_per_room',\n",
       " 'num_photos',\n",
       " 'num_features',\n",
       " 'num_description_words',\n",
       " 'created_year',\n",
       " 'listing_id',\n",
       " 'created_month',\n",
       " 'created_day',\n",
       " 'created_hour',\n",
       " u'with_exclusive',\n",
       " u'with_furnished',\n",
       " u'with_lowrise',\n",
       " u'with_common_parking/garage',\n",
       " u'with_pets_on_approval',\n",
       " u'with_terrace',\n",
       " u'with_live_in_superintendent',\n",
       " u'with_newly_renovated',\n",
       " u'with_full_time_doorman',\n",
       " u'with_duplex',\n",
       " u'with_dryer_in_unit',\n",
       " u'with_multi_level',\n",
       " u'with_garden',\n",
       " u'with_hardwood_floors',\n",
       " u'with_on_site_garage',\n",
       " u'with_fireplace',\n",
       " u'with_eat_in_kitchen',\n",
       " u'with_wifi_access',\n",
       " u'with_garage',\n",
       " u'with_subway',\n",
       " u'with_dining_room',\n",
       " u'with_view',\n",
       " u'with_publicoutdoor',\n",
       " u'with_hardwood',\n",
       " u'with_fitness_center',\n",
       " u'with_high_speed_internet',\n",
       " u'with_laundry_in_building',\n",
       " u'with_parking',\n",
       " u'with_garden/patio',\n",
       " u'with_prewar',\n",
       " u'with_on_site_laundry',\n",
       " u'with_valet',\n",
       " u'with_green_building',\n",
       " u'with_short_term_allowed',\n",
       " u'with_new_construction',\n",
       " u'with_reduced_fee',\n",
       " u'with_roofdeck',\n",
       " u'with_stainless_steel_appliances',\n",
       " u'with_simplex',\n",
       " u'with_dishwasher',\n",
       " u'with_washer_in_unit',\n",
       " u'with_cats_allowed',\n",
       " u'with_exposed_brick',\n",
       " u'with_roof_deck',\n",
       " u'with_common_outdoor_space',\n",
       " u'with_outdoor_areas',\n",
       " u'with_common_roof_deck',\n",
       " u'with_no_pets',\n",
       " u'with_childrens_playroom',\n",
       " u'with_central_a/c',\n",
       " u'with_wheelchair_access',\n",
       " u'with_post_war',\n",
       " u'with_renovated',\n",
       " u'with_elevator',\n",
       " u'with_highrise',\n",
       " u'with_loft',\n",
       " u'with_gym',\n",
       " u'with_luxury_building',\n",
       " u'with_outdoor_space',\n",
       " u'with_pre_war',\n",
       " u'with_residents_lounge',\n",
       " u'with_laundry_room',\n",
       " u'with_marble_bath',\n",
       " u'with_laundry_in_unit',\n",
       " u'with_parking_space',\n",
       " u'with_private_outdoor_space',\n",
       " u'with_high_ceiling',\n",
       " u'with_concierge',\n",
       " u'with_walk_in_closet(s)',\n",
       " u'with_doorman',\n",
       " u'with_balcony',\n",
       " u'with_dogs_allowed',\n",
       " u'with_gym/fitness',\n",
       " u'with_storage',\n",
       " u'with_live_in_super',\n",
       " u'with_lounge',\n",
       " u'with_granite_kitchen',\n",
       " u'with_private_balcony',\n",
       " u'with_laundry',\n",
       " u'with_actual_apt._photos',\n",
       " u'with_residents_garden',\n",
       " u'with_pool',\n",
       " u'with_washer/dryer',\n",
       " u'with_light',\n",
       " u'with_swimming_pool',\n",
       " u'with_high_ceilings',\n",
       " u'with_patio',\n",
       " u'with_no_fee',\n",
       " u'with_bike_room',\n",
       " 'manager_id_perf',\n",
       " 'display_address',\n",
       " 'street_address',\n",
       " 'manager_id',\n",
       " 'building_id']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_to_use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\dell\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\dell\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\dell\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:1.04187\ttest-mlogloss:1.04194\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 64 rounds.\n",
      "[1]\ttrain-mlogloss:0.987843\ttest-mlogloss:0.988401\n",
      "[2]\ttrain-mlogloss:0.943556\ttest-mlogloss:0.944462\n",
      "[3]\ttrain-mlogloss:0.903352\ttest-mlogloss:0.904668\n",
      "[4]\ttrain-mlogloss:0.869269\ttest-mlogloss:0.871077\n",
      "[5]\ttrain-mlogloss:0.839196\ttest-mlogloss:0.841235\n",
      "[6]\ttrain-mlogloss:0.812991\ttest-mlogloss:0.81528\n",
      "[7]\ttrain-mlogloss:0.790213\ttest-mlogloss:0.792859\n",
      "[8]\ttrain-mlogloss:0.770565\ttest-mlogloss:0.773343\n",
      "[9]\ttrain-mlogloss:0.752718\ttest-mlogloss:0.755686\n",
      "[10]\ttrain-mlogloss:0.737359\ttest-mlogloss:0.740574\n",
      "[11]\ttrain-mlogloss:0.722879\ttest-mlogloss:0.726218\n",
      "[12]\ttrain-mlogloss:0.709878\ttest-mlogloss:0.71336\n",
      "[13]\ttrain-mlogloss:0.699288\ttest-mlogloss:0.702913\n",
      "[14]\ttrain-mlogloss:0.689615\ttest-mlogloss:0.693401\n",
      "[15]\ttrain-mlogloss:0.680105\ttest-mlogloss:0.684221\n",
      "[16]\ttrain-mlogloss:0.671702\ttest-mlogloss:0.676144\n",
      "[17]\ttrain-mlogloss:0.664493\ttest-mlogloss:0.669199\n",
      "[18]\ttrain-mlogloss:0.657408\ttest-mlogloss:0.662298\n",
      "[19]\ttrain-mlogloss:0.651486\ttest-mlogloss:0.656618\n",
      "[20]\ttrain-mlogloss:0.646047\ttest-mlogloss:0.6515\n",
      "[21]\ttrain-mlogloss:0.640705\ttest-mlogloss:0.646301\n",
      "[22]\ttrain-mlogloss:0.635489\ttest-mlogloss:0.641245\n",
      "[23]\ttrain-mlogloss:0.63089\ttest-mlogloss:0.636832\n",
      "[24]\ttrain-mlogloss:0.626617\ttest-mlogloss:0.632862\n",
      "[25]\ttrain-mlogloss:0.622949\ttest-mlogloss:0.629372\n",
      "[26]\ttrain-mlogloss:0.619489\ttest-mlogloss:0.626137\n",
      "[27]\ttrain-mlogloss:0.616296\ttest-mlogloss:0.623149\n",
      "[28]\ttrain-mlogloss:0.613227\ttest-mlogloss:0.620173\n",
      "[29]\ttrain-mlogloss:0.610176\ttest-mlogloss:0.617417\n",
      "[30]\ttrain-mlogloss:0.607581\ttest-mlogloss:0.615132\n",
      "[31]\ttrain-mlogloss:0.605064\ttest-mlogloss:0.612885\n",
      "[32]\ttrain-mlogloss:0.602903\ttest-mlogloss:0.61104\n",
      "[33]\ttrain-mlogloss:0.600666\ttest-mlogloss:0.608971\n",
      "[34]\ttrain-mlogloss:0.598279\ttest-mlogloss:0.606776\n",
      "[35]\ttrain-mlogloss:0.596286\ttest-mlogloss:0.604925\n",
      "[36]\ttrain-mlogloss:0.59447\ttest-mlogloss:0.603331\n",
      "[37]\ttrain-mlogloss:0.59275\ttest-mlogloss:0.601843\n",
      "[38]\ttrain-mlogloss:0.591114\ttest-mlogloss:0.600428\n",
      "[39]\ttrain-mlogloss:0.589377\ttest-mlogloss:0.598803\n",
      "[40]\ttrain-mlogloss:0.587862\ttest-mlogloss:0.597571\n",
      "[41]\ttrain-mlogloss:0.586538\ttest-mlogloss:0.596485\n",
      "[42]\ttrain-mlogloss:0.584731\ttest-mlogloss:0.594865\n",
      "[43]\ttrain-mlogloss:0.58349\ttest-mlogloss:0.593913\n",
      "[44]\ttrain-mlogloss:0.581905\ttest-mlogloss:0.592552\n",
      "[45]\ttrain-mlogloss:0.580542\ttest-mlogloss:0.591299\n",
      "[46]\ttrain-mlogloss:0.57901\ttest-mlogloss:0.590064\n",
      "[47]\ttrain-mlogloss:0.577791\ttest-mlogloss:0.589089\n",
      "[48]\ttrain-mlogloss:0.576702\ttest-mlogloss:0.588216\n",
      "[49]\ttrain-mlogloss:0.5753\ttest-mlogloss:0.587099\n",
      "[50]\ttrain-mlogloss:0.574154\ttest-mlogloss:0.586214\n",
      "[51]\ttrain-mlogloss:0.573134\ttest-mlogloss:0.585542\n",
      "[52]\ttrain-mlogloss:0.571944\ttest-mlogloss:0.584624\n",
      "[53]\ttrain-mlogloss:0.570803\ttest-mlogloss:0.583556\n",
      "[54]\ttrain-mlogloss:0.569786\ttest-mlogloss:0.582785\n",
      "[55]\ttrain-mlogloss:0.568847\ttest-mlogloss:0.581992\n",
      "[56]\ttrain-mlogloss:0.567993\ttest-mlogloss:0.581354\n",
      "[57]\ttrain-mlogloss:0.567035\ttest-mlogloss:0.580569\n",
      "[58]\ttrain-mlogloss:0.56632\ttest-mlogloss:0.580004\n",
      "[59]\ttrain-mlogloss:0.565299\ttest-mlogloss:0.579151\n",
      "[60]\ttrain-mlogloss:0.564109\ttest-mlogloss:0.578359\n",
      "[61]\ttrain-mlogloss:0.563119\ttest-mlogloss:0.577671\n",
      "[62]\ttrain-mlogloss:0.562079\ttest-mlogloss:0.576921\n",
      "[63]\ttrain-mlogloss:0.561284\ttest-mlogloss:0.576333\n",
      "[64]\ttrain-mlogloss:0.560365\ttest-mlogloss:0.57571\n",
      "[65]\ttrain-mlogloss:0.559631\ttest-mlogloss:0.575142\n",
      "[66]\ttrain-mlogloss:0.558858\ttest-mlogloss:0.574523\n",
      "[67]\ttrain-mlogloss:0.558035\ttest-mlogloss:0.573881\n",
      "[68]\ttrain-mlogloss:0.557106\ttest-mlogloss:0.573207\n",
      "[69]\ttrain-mlogloss:0.556299\ttest-mlogloss:0.572621\n",
      "[70]\ttrain-mlogloss:0.555646\ttest-mlogloss:0.572164\n",
      "[71]\ttrain-mlogloss:0.55497\ttest-mlogloss:0.57168\n",
      "[72]\ttrain-mlogloss:0.554487\ttest-mlogloss:0.571385\n",
      "[73]\ttrain-mlogloss:0.553842\ttest-mlogloss:0.570863\n",
      "[74]\ttrain-mlogloss:0.553241\ttest-mlogloss:0.570576\n",
      "[75]\ttrain-mlogloss:0.552353\ttest-mlogloss:0.570089\n",
      "[76]\ttrain-mlogloss:0.55163\ttest-mlogloss:0.5696\n",
      "[77]\ttrain-mlogloss:0.550967\ttest-mlogloss:0.56916\n",
      "[78]\ttrain-mlogloss:0.550544\ttest-mlogloss:0.568902\n",
      "[79]\ttrain-mlogloss:0.549964\ttest-mlogloss:0.568517\n",
      "[80]\ttrain-mlogloss:0.549121\ttest-mlogloss:0.567902\n",
      "[81]\ttrain-mlogloss:0.548608\ttest-mlogloss:0.567629\n",
      "[82]\ttrain-mlogloss:0.547823\ttest-mlogloss:0.567207\n",
      "[83]\ttrain-mlogloss:0.547216\ttest-mlogloss:0.566773\n",
      "[84]\ttrain-mlogloss:0.546748\ttest-mlogloss:0.566464\n",
      "[85]\ttrain-mlogloss:0.546175\ttest-mlogloss:0.565926\n",
      "[86]\ttrain-mlogloss:0.545447\ttest-mlogloss:0.565498\n",
      "[87]\ttrain-mlogloss:0.544866\ttest-mlogloss:0.5651\n",
      "[88]\ttrain-mlogloss:0.544231\ttest-mlogloss:0.564768\n",
      "[89]\ttrain-mlogloss:0.543581\ttest-mlogloss:0.564372\n",
      "[90]\ttrain-mlogloss:0.542977\ttest-mlogloss:0.564111\n",
      "[91]\ttrain-mlogloss:0.542397\ttest-mlogloss:0.563826\n",
      "[92]\ttrain-mlogloss:0.541801\ttest-mlogloss:0.563398\n",
      "[93]\ttrain-mlogloss:0.541203\ttest-mlogloss:0.562968\n",
      "[94]\ttrain-mlogloss:0.540622\ttest-mlogloss:0.562566\n",
      "[95]\ttrain-mlogloss:0.540205\ttest-mlogloss:0.562166\n",
      "[96]\ttrain-mlogloss:0.539729\ttest-mlogloss:0.561823\n",
      "[97]\ttrain-mlogloss:0.539155\ttest-mlogloss:0.561456\n",
      "[98]\ttrain-mlogloss:0.538518\ttest-mlogloss:0.561113\n",
      "[99]\ttrain-mlogloss:0.538048\ttest-mlogloss:0.56086\n",
      "[100]\ttrain-mlogloss:0.537416\ttest-mlogloss:0.560475\n",
      "[101]\ttrain-mlogloss:0.536867\ttest-mlogloss:0.56006\n",
      "[102]\ttrain-mlogloss:0.536337\ttest-mlogloss:0.559783\n",
      "[103]\ttrain-mlogloss:0.535857\ttest-mlogloss:0.559633\n",
      "[104]\ttrain-mlogloss:0.535477\ttest-mlogloss:0.559366\n",
      "[105]\ttrain-mlogloss:0.535076\ttest-mlogloss:0.559173\n",
      "[106]\ttrain-mlogloss:0.534494\ttest-mlogloss:0.558819\n",
      "[107]\ttrain-mlogloss:0.533917\ttest-mlogloss:0.558463\n",
      "[108]\ttrain-mlogloss:0.533449\ttest-mlogloss:0.558224\n",
      "[109]\ttrain-mlogloss:0.532943\ttest-mlogloss:0.558029\n",
      "[110]\ttrain-mlogloss:0.532431\ttest-mlogloss:0.557756\n",
      "[111]\ttrain-mlogloss:0.532011\ttest-mlogloss:0.557488\n",
      "[112]\ttrain-mlogloss:0.531482\ttest-mlogloss:0.557228\n",
      "[113]\ttrain-mlogloss:0.531071\ttest-mlogloss:0.556996\n",
      "[114]\ttrain-mlogloss:0.530519\ttest-mlogloss:0.556726\n",
      "[115]\ttrain-mlogloss:0.530086\ttest-mlogloss:0.556395\n",
      "[116]\ttrain-mlogloss:0.529588\ttest-mlogloss:0.556225\n",
      "[117]\ttrain-mlogloss:0.529125\ttest-mlogloss:0.555911\n",
      "[118]\ttrain-mlogloss:0.528681\ttest-mlogloss:0.555664\n",
      "[119]\ttrain-mlogloss:0.528223\ttest-mlogloss:0.555413\n",
      "[120]\ttrain-mlogloss:0.527822\ttest-mlogloss:0.555235\n",
      "[121]\ttrain-mlogloss:0.527337\ttest-mlogloss:0.554861\n",
      "[122]\ttrain-mlogloss:0.52689\ttest-mlogloss:0.554687\n",
      "[123]\ttrain-mlogloss:0.52639\ttest-mlogloss:0.554326\n",
      "[124]\ttrain-mlogloss:0.525911\ttest-mlogloss:0.55416\n",
      "[125]\ttrain-mlogloss:0.525473\ttest-mlogloss:0.553933\n",
      "[126]\ttrain-mlogloss:0.524966\ttest-mlogloss:0.553747\n",
      "[127]\ttrain-mlogloss:0.524391\ttest-mlogloss:0.553528\n",
      "[128]\ttrain-mlogloss:0.524122\ttest-mlogloss:0.553371\n",
      "[129]\ttrain-mlogloss:0.523653\ttest-mlogloss:0.55304\n",
      "[130]\ttrain-mlogloss:0.523244\ttest-mlogloss:0.552826\n",
      "[131]\ttrain-mlogloss:0.522764\ttest-mlogloss:0.552639\n",
      "[132]\ttrain-mlogloss:0.522406\ttest-mlogloss:0.552465\n",
      "[133]\ttrain-mlogloss:0.522011\ttest-mlogloss:0.5522\n",
      "[134]\ttrain-mlogloss:0.521543\ttest-mlogloss:0.551965\n",
      "[135]\ttrain-mlogloss:0.521265\ttest-mlogloss:0.551828\n",
      "[136]\ttrain-mlogloss:0.520775\ttest-mlogloss:0.551644\n",
      "[137]\ttrain-mlogloss:0.52027\ttest-mlogloss:0.551328\n",
      "[138]\ttrain-mlogloss:0.519762\ttest-mlogloss:0.551086\n",
      "[139]\ttrain-mlogloss:0.519319\ttest-mlogloss:0.55093\n",
      "[140]\ttrain-mlogloss:0.518952\ttest-mlogloss:0.550816\n",
      "[141]\ttrain-mlogloss:0.518648\ttest-mlogloss:0.550678\n",
      "[142]\ttrain-mlogloss:0.518275\ttest-mlogloss:0.550417\n",
      "[143]\ttrain-mlogloss:0.51784\ttest-mlogloss:0.550074\n",
      "[144]\ttrain-mlogloss:0.517488\ttest-mlogloss:0.549883\n",
      "[145]\ttrain-mlogloss:0.517043\ttest-mlogloss:0.549648\n",
      "[146]\ttrain-mlogloss:0.516579\ttest-mlogloss:0.549365\n",
      "[147]\ttrain-mlogloss:0.516259\ttest-mlogloss:0.549347\n",
      "[148]\ttrain-mlogloss:0.515972\ttest-mlogloss:0.549224\n",
      "[149]\ttrain-mlogloss:0.515529\ttest-mlogloss:0.549004\n",
      "[150]\ttrain-mlogloss:0.515285\ttest-mlogloss:0.548894\n",
      "[151]\ttrain-mlogloss:0.514931\ttest-mlogloss:0.54881\n",
      "[152]\ttrain-mlogloss:0.51463\ttest-mlogloss:0.548681\n",
      "[153]\ttrain-mlogloss:0.514323\ttest-mlogloss:0.548506\n",
      "[154]\ttrain-mlogloss:0.514038\ttest-mlogloss:0.5484\n",
      "[155]\ttrain-mlogloss:0.51367\ttest-mlogloss:0.548266\n",
      "[156]\ttrain-mlogloss:0.51328\ttest-mlogloss:0.548085\n",
      "[157]\ttrain-mlogloss:0.513067\ttest-mlogloss:0.547953\n",
      "[158]\ttrain-mlogloss:0.51281\ttest-mlogloss:0.547855\n",
      "[159]\ttrain-mlogloss:0.512418\ttest-mlogloss:0.547698\n",
      "[160]\ttrain-mlogloss:0.512041\ttest-mlogloss:0.547544\n",
      "[161]\ttrain-mlogloss:0.511694\ttest-mlogloss:0.54733\n",
      "[162]\ttrain-mlogloss:0.511412\ttest-mlogloss:0.547193\n",
      "[163]\ttrain-mlogloss:0.511029\ttest-mlogloss:0.547014\n",
      "[164]\ttrain-mlogloss:0.510712\ttest-mlogloss:0.546904\n",
      "[165]\ttrain-mlogloss:0.510421\ttest-mlogloss:0.546759\n",
      "[166]\ttrain-mlogloss:0.5101\ttest-mlogloss:0.54661\n",
      "[167]\ttrain-mlogloss:0.509768\ttest-mlogloss:0.546459\n",
      "[168]\ttrain-mlogloss:0.509456\ttest-mlogloss:0.546309\n",
      "[169]\ttrain-mlogloss:0.509087\ttest-mlogloss:0.546234\n",
      "[170]\ttrain-mlogloss:0.508823\ttest-mlogloss:0.546189\n",
      "[171]\ttrain-mlogloss:0.508567\ttest-mlogloss:0.54607\n",
      "[172]\ttrain-mlogloss:0.508171\ttest-mlogloss:0.54595\n",
      "[173]\ttrain-mlogloss:0.507833\ttest-mlogloss:0.54573\n",
      "[174]\ttrain-mlogloss:0.507533\ttest-mlogloss:0.545608\n",
      "[175]\ttrain-mlogloss:0.507275\ttest-mlogloss:0.54546\n",
      "[176]\ttrain-mlogloss:0.506994\ttest-mlogloss:0.545373\n",
      "[177]\ttrain-mlogloss:0.506772\ttest-mlogloss:0.545302\n",
      "[178]\ttrain-mlogloss:0.506399\ttest-mlogloss:0.545073\n",
      "[179]\ttrain-mlogloss:0.505996\ttest-mlogloss:0.544875\n",
      "[180]\ttrain-mlogloss:0.505757\ttest-mlogloss:0.54487\n",
      "[181]\ttrain-mlogloss:0.505425\ttest-mlogloss:0.544717\n",
      "[182]\ttrain-mlogloss:0.505154\ttest-mlogloss:0.544687\n",
      "[183]\ttrain-mlogloss:0.504884\ttest-mlogloss:0.544591\n",
      "[184]\ttrain-mlogloss:0.504608\ttest-mlogloss:0.544577\n",
      "[185]\ttrain-mlogloss:0.504293\ttest-mlogloss:0.544477\n",
      "[186]\ttrain-mlogloss:0.503979\ttest-mlogloss:0.544267\n",
      "[187]\ttrain-mlogloss:0.503663\ttest-mlogloss:0.544126\n",
      "[188]\ttrain-mlogloss:0.503416\ttest-mlogloss:0.544023\n",
      "[189]\ttrain-mlogloss:0.503063\ttest-mlogloss:0.543741\n",
      "[190]\ttrain-mlogloss:0.502824\ttest-mlogloss:0.543584\n",
      "[191]\ttrain-mlogloss:0.502539\ttest-mlogloss:0.543551\n",
      "[192]\ttrain-mlogloss:0.502157\ttest-mlogloss:0.543387\n",
      "[193]\ttrain-mlogloss:0.5018\ttest-mlogloss:0.543273\n",
      "[194]\ttrain-mlogloss:0.501565\ttest-mlogloss:0.543149\n",
      "[195]\ttrain-mlogloss:0.501316\ttest-mlogloss:0.543148\n",
      "[196]\ttrain-mlogloss:0.500951\ttest-mlogloss:0.542968\n",
      "[197]\ttrain-mlogloss:0.50065\ttest-mlogloss:0.542837\n",
      "[198]\ttrain-mlogloss:0.500315\ttest-mlogloss:0.542663\n",
      "[199]\ttrain-mlogloss:0.500062\ttest-mlogloss:0.542531\n",
      "[200]\ttrain-mlogloss:0.499624\ttest-mlogloss:0.54231\n",
      "[201]\ttrain-mlogloss:0.499299\ttest-mlogloss:0.542215\n",
      "[202]\ttrain-mlogloss:0.499027\ttest-mlogloss:0.542145\n",
      "[203]\ttrain-mlogloss:0.498785\ttest-mlogloss:0.541989\n",
      "[204]\ttrain-mlogloss:0.498444\ttest-mlogloss:0.541862\n",
      "[205]\ttrain-mlogloss:0.498189\ttest-mlogloss:0.541813\n",
      "[206]\ttrain-mlogloss:0.497853\ttest-mlogloss:0.541776\n",
      "[207]\ttrain-mlogloss:0.497531\ttest-mlogloss:0.541652\n",
      "[208]\ttrain-mlogloss:0.497273\ttest-mlogloss:0.541645\n",
      "[209]\ttrain-mlogloss:0.496985\ttest-mlogloss:0.541507\n",
      "[210]\ttrain-mlogloss:0.496713\ttest-mlogloss:0.541384\n",
      "[211]\ttrain-mlogloss:0.496433\ttest-mlogloss:0.54129\n",
      "[212]\ttrain-mlogloss:0.496161\ttest-mlogloss:0.541183\n",
      "[213]\ttrain-mlogloss:0.495908\ttest-mlogloss:0.541108\n",
      "[214]\ttrain-mlogloss:0.495615\ttest-mlogloss:0.54101\n",
      "[215]\ttrain-mlogloss:0.495272\ttest-mlogloss:0.540915\n",
      "[216]\ttrain-mlogloss:0.494987\ttest-mlogloss:0.540834\n",
      "[217]\ttrain-mlogloss:0.494724\ttest-mlogloss:0.540765\n",
      "[218]\ttrain-mlogloss:0.49447\ttest-mlogloss:0.540668\n",
      "[219]\ttrain-mlogloss:0.49422\ttest-mlogloss:0.540656\n",
      "[220]\ttrain-mlogloss:0.493988\ttest-mlogloss:0.540582\n",
      "[221]\ttrain-mlogloss:0.493754\ttest-mlogloss:0.540489\n",
      "[222]\ttrain-mlogloss:0.493432\ttest-mlogloss:0.540434\n",
      "[223]\ttrain-mlogloss:0.493148\ttest-mlogloss:0.540312\n",
      "[224]\ttrain-mlogloss:0.49278\ttest-mlogloss:0.540225\n",
      "[225]\ttrain-mlogloss:0.492559\ttest-mlogloss:0.540126\n",
      "[226]\ttrain-mlogloss:0.492333\ttest-mlogloss:0.540034\n",
      "[227]\ttrain-mlogloss:0.49205\ttest-mlogloss:0.539836\n",
      "[228]\ttrain-mlogloss:0.491856\ttest-mlogloss:0.539786\n",
      "[229]\ttrain-mlogloss:0.491629\ttest-mlogloss:0.539677\n",
      "[230]\ttrain-mlogloss:0.49136\ttest-mlogloss:0.539559\n",
      "[231]\ttrain-mlogloss:0.491076\ttest-mlogloss:0.539553\n",
      "[232]\ttrain-mlogloss:0.490869\ttest-mlogloss:0.539521\n",
      "[233]\ttrain-mlogloss:0.490757\ttest-mlogloss:0.539461\n",
      "[234]\ttrain-mlogloss:0.490438\ttest-mlogloss:0.539289\n",
      "[235]\ttrain-mlogloss:0.490104\ttest-mlogloss:0.539158\n",
      "[236]\ttrain-mlogloss:0.489769\ttest-mlogloss:0.539035\n",
      "[237]\ttrain-mlogloss:0.489555\ttest-mlogloss:0.538971\n",
      "[238]\ttrain-mlogloss:0.489299\ttest-mlogloss:0.538935\n",
      "[239]\ttrain-mlogloss:0.489073\ttest-mlogloss:0.538886\n",
      "[240]\ttrain-mlogloss:0.488756\ttest-mlogloss:0.538727\n",
      "[241]\ttrain-mlogloss:0.488503\ttest-mlogloss:0.538733\n",
      "[242]\ttrain-mlogloss:0.48824\ttest-mlogloss:0.538711\n",
      "[243]\ttrain-mlogloss:0.487973\ttest-mlogloss:0.538677\n",
      "[244]\ttrain-mlogloss:0.487645\ttest-mlogloss:0.53855\n",
      "[245]\ttrain-mlogloss:0.48743\ttest-mlogloss:0.538498\n",
      "[246]\ttrain-mlogloss:0.487199\ttest-mlogloss:0.538453\n",
      "[247]\ttrain-mlogloss:0.486951\ttest-mlogloss:0.53833\n",
      "[248]\ttrain-mlogloss:0.486726\ttest-mlogloss:0.538318\n",
      "[249]\ttrain-mlogloss:0.486463\ttest-mlogloss:0.538128\n",
      "[250]\ttrain-mlogloss:0.486247\ttest-mlogloss:0.538046\n",
      "[251]\ttrain-mlogloss:0.485931\ttest-mlogloss:0.537993\n",
      "[252]\ttrain-mlogloss:0.485609\ttest-mlogloss:0.537918\n",
      "[253]\ttrain-mlogloss:0.485357\ttest-mlogloss:0.537796\n",
      "[254]\ttrain-mlogloss:0.485096\ttest-mlogloss:0.537776\n",
      "[255]\ttrain-mlogloss:0.484831\ttest-mlogloss:0.537796\n",
      "[256]\ttrain-mlogloss:0.484536\ttest-mlogloss:0.537821\n",
      "[257]\ttrain-mlogloss:0.484271\ttest-mlogloss:0.537702\n",
      "[258]\ttrain-mlogloss:0.484057\ttest-mlogloss:0.537709\n",
      "[259]\ttrain-mlogloss:0.483698\ttest-mlogloss:0.537516\n",
      "[260]\ttrain-mlogloss:0.483364\ttest-mlogloss:0.537333\n",
      "[261]\ttrain-mlogloss:0.483141\ttest-mlogloss:0.53735\n",
      "[262]\ttrain-mlogloss:0.482937\ttest-mlogloss:0.537372\n",
      "[263]\ttrain-mlogloss:0.482669\ttest-mlogloss:0.537358\n",
      "[264]\ttrain-mlogloss:0.482334\ttest-mlogloss:0.537286\n",
      "[265]\ttrain-mlogloss:0.482053\ttest-mlogloss:0.537249\n",
      "[266]\ttrain-mlogloss:0.481748\ttest-mlogloss:0.537233\n",
      "[267]\ttrain-mlogloss:0.481602\ttest-mlogloss:0.537146\n",
      "[268]\ttrain-mlogloss:0.481365\ttest-mlogloss:0.537081\n",
      "[269]\ttrain-mlogloss:0.481112\ttest-mlogloss:0.536984\n",
      "[270]\ttrain-mlogloss:0.480855\ttest-mlogloss:0.537006\n",
      "[271]\ttrain-mlogloss:0.480597\ttest-mlogloss:0.536951\n",
      "[272]\ttrain-mlogloss:0.480373\ttest-mlogloss:0.5369\n",
      "[273]\ttrain-mlogloss:0.480118\ttest-mlogloss:0.536872\n",
      "[274]\ttrain-mlogloss:0.47986\ttest-mlogloss:0.536747\n",
      "[275]\ttrain-mlogloss:0.479648\ttest-mlogloss:0.536646\n",
      "[276]\ttrain-mlogloss:0.479356\ttest-mlogloss:0.536624\n",
      "[277]\ttrain-mlogloss:0.479079\ttest-mlogloss:0.536534\n",
      "[278]\ttrain-mlogloss:0.478804\ttest-mlogloss:0.536505\n",
      "[279]\ttrain-mlogloss:0.478565\ttest-mlogloss:0.536444\n",
      "[280]\ttrain-mlogloss:0.478318\ttest-mlogloss:0.536341\n",
      "[281]\ttrain-mlogloss:0.478138\ttest-mlogloss:0.536287\n",
      "[282]\ttrain-mlogloss:0.477977\ttest-mlogloss:0.536286\n",
      "[283]\ttrain-mlogloss:0.477666\ttest-mlogloss:0.536099\n",
      "[284]\ttrain-mlogloss:0.477442\ttest-mlogloss:0.536009\n",
      "[285]\ttrain-mlogloss:0.477286\ttest-mlogloss:0.535955\n",
      "[286]\ttrain-mlogloss:0.477001\ttest-mlogloss:0.535929\n",
      "[287]\ttrain-mlogloss:0.476698\ttest-mlogloss:0.535778\n",
      "[288]\ttrain-mlogloss:0.476371\ttest-mlogloss:0.53567\n",
      "[289]\ttrain-mlogloss:0.476167\ttest-mlogloss:0.535609\n",
      "[290]\ttrain-mlogloss:0.475945\ttest-mlogloss:0.53564\n",
      "[291]\ttrain-mlogloss:0.475623\ttest-mlogloss:0.53553\n",
      "[292]\ttrain-mlogloss:0.47539\ttest-mlogloss:0.535471\n",
      "[293]\ttrain-mlogloss:0.475118\ttest-mlogloss:0.535382\n",
      "[294]\ttrain-mlogloss:0.474847\ttest-mlogloss:0.535302\n",
      "[295]\ttrain-mlogloss:0.474665\ttest-mlogloss:0.535252\n",
      "[296]\ttrain-mlogloss:0.474412\ttest-mlogloss:0.535115\n",
      "[297]\ttrain-mlogloss:0.474139\ttest-mlogloss:0.534986\n",
      "[298]\ttrain-mlogloss:0.473978\ttest-mlogloss:0.534994\n",
      "[299]\ttrain-mlogloss:0.473734\ttest-mlogloss:0.534906\n",
      "[300]\ttrain-mlogloss:0.473477\ttest-mlogloss:0.5348\n",
      "[301]\ttrain-mlogloss:0.473273\ttest-mlogloss:0.53477\n",
      "[302]\ttrain-mlogloss:0.473068\ttest-mlogloss:0.534732\n",
      "[303]\ttrain-mlogloss:0.472851\ttest-mlogloss:0.534767\n",
      "[304]\ttrain-mlogloss:0.472561\ttest-mlogloss:0.534697\n",
      "[305]\ttrain-mlogloss:0.472386\ttest-mlogloss:0.534643\n",
      "[306]\ttrain-mlogloss:0.472094\ttest-mlogloss:0.53452\n",
      "[307]\ttrain-mlogloss:0.471953\ttest-mlogloss:0.534518\n",
      "[308]\ttrain-mlogloss:0.471737\ttest-mlogloss:0.534451\n",
      "[309]\ttrain-mlogloss:0.471512\ttest-mlogloss:0.534422\n",
      "[310]\ttrain-mlogloss:0.471321\ttest-mlogloss:0.534363\n",
      "[311]\ttrain-mlogloss:0.471106\ttest-mlogloss:0.534349\n",
      "[312]\ttrain-mlogloss:0.470796\ttest-mlogloss:0.53428\n",
      "[313]\ttrain-mlogloss:0.470618\ttest-mlogloss:0.534305\n",
      "[314]\ttrain-mlogloss:0.470477\ttest-mlogloss:0.534291\n",
      "[315]\ttrain-mlogloss:0.470246\ttest-mlogloss:0.534256\n",
      "[316]\ttrain-mlogloss:0.470009\ttest-mlogloss:0.534238\n",
      "[317]\ttrain-mlogloss:0.46976\ttest-mlogloss:0.534296\n",
      "[318]\ttrain-mlogloss:0.469488\ttest-mlogloss:0.534119\n",
      "[319]\ttrain-mlogloss:0.469342\ttest-mlogloss:0.534104\n",
      "[320]\ttrain-mlogloss:0.4692\ttest-mlogloss:0.534124\n",
      "[321]\ttrain-mlogloss:0.469035\ttest-mlogloss:0.534167\n",
      "[322]\ttrain-mlogloss:0.468819\ttest-mlogloss:0.534168\n",
      "[323]\ttrain-mlogloss:0.468586\ttest-mlogloss:0.534103\n",
      "[324]\ttrain-mlogloss:0.468304\ttest-mlogloss:0.533987\n",
      "[325]\ttrain-mlogloss:0.468077\ttest-mlogloss:0.534055\n",
      "[326]\ttrain-mlogloss:0.467918\ttest-mlogloss:0.534018\n",
      "[327]\ttrain-mlogloss:0.46776\ttest-mlogloss:0.534004\n",
      "[328]\ttrain-mlogloss:0.46755\ttest-mlogloss:0.533965\n",
      "[329]\ttrain-mlogloss:0.467256\ttest-mlogloss:0.533879\n",
      "[330]\ttrain-mlogloss:0.467015\ttest-mlogloss:0.533895\n",
      "[331]\ttrain-mlogloss:0.466815\ttest-mlogloss:0.533874\n",
      "[332]\ttrain-mlogloss:0.466574\ttest-mlogloss:0.533903\n",
      "[333]\ttrain-mlogloss:0.466323\ttest-mlogloss:0.533887\n",
      "[334]\ttrain-mlogloss:0.466082\ttest-mlogloss:0.533842\n",
      "[335]\ttrain-mlogloss:0.465845\ttest-mlogloss:0.53381\n",
      "[336]\ttrain-mlogloss:0.465629\ttest-mlogloss:0.533708\n",
      "[337]\ttrain-mlogloss:0.46537\ttest-mlogloss:0.53355\n",
      "[338]\ttrain-mlogloss:0.465098\ttest-mlogloss:0.533512\n",
      "[339]\ttrain-mlogloss:0.464869\ttest-mlogloss:0.533508\n",
      "[340]\ttrain-mlogloss:0.464638\ttest-mlogloss:0.533484\n",
      "[341]\ttrain-mlogloss:0.464397\ttest-mlogloss:0.53346\n",
      "[342]\ttrain-mlogloss:0.464199\ttest-mlogloss:0.53339\n",
      "[343]\ttrain-mlogloss:0.464053\ttest-mlogloss:0.533339\n",
      "[344]\ttrain-mlogloss:0.463876\ttest-mlogloss:0.533292\n",
      "[345]\ttrain-mlogloss:0.463681\ttest-mlogloss:0.533302\n",
      "[346]\ttrain-mlogloss:0.463379\ttest-mlogloss:0.533207\n",
      "[347]\ttrain-mlogloss:0.463202\ttest-mlogloss:0.5332\n",
      "[348]\ttrain-mlogloss:0.46299\ttest-mlogloss:0.53317\n",
      "[349]\ttrain-mlogloss:0.462766\ttest-mlogloss:0.533184\n",
      "[350]\ttrain-mlogloss:0.462599\ttest-mlogloss:0.533308\n",
      "[351]\ttrain-mlogloss:0.462325\ttest-mlogloss:0.533251\n",
      "[352]\ttrain-mlogloss:0.462159\ttest-mlogloss:0.533409\n",
      "[353]\ttrain-mlogloss:0.461939\ttest-mlogloss:0.533369\n",
      "[354]\ttrain-mlogloss:0.461762\ttest-mlogloss:0.533394\n",
      "[355]\ttrain-mlogloss:0.461554\ttest-mlogloss:0.533322\n",
      "[356]\ttrain-mlogloss:0.461343\ttest-mlogloss:0.533294\n",
      "[357]\ttrain-mlogloss:0.46107\ttest-mlogloss:0.533258\n",
      "[358]\ttrain-mlogloss:0.460826\ttest-mlogloss:0.533244\n",
      "[359]\ttrain-mlogloss:0.46061\ttest-mlogloss:0.533201\n",
      "[360]\ttrain-mlogloss:0.460476\ttest-mlogloss:0.533195\n",
      "[361]\ttrain-mlogloss:0.460263\ttest-mlogloss:0.533192\n",
      "[362]\ttrain-mlogloss:0.460028\ttest-mlogloss:0.533101\n",
      "[363]\ttrain-mlogloss:0.459859\ttest-mlogloss:0.533032\n",
      "[364]\ttrain-mlogloss:0.459708\ttest-mlogloss:0.533058\n",
      "[365]\ttrain-mlogloss:0.459507\ttest-mlogloss:0.533038\n",
      "[366]\ttrain-mlogloss:0.459279\ttest-mlogloss:0.53294\n",
      "[367]\ttrain-mlogloss:0.459025\ttest-mlogloss:0.532874\n",
      "[368]\ttrain-mlogloss:0.45886\ttest-mlogloss:0.532852\n",
      "[369]\ttrain-mlogloss:0.458638\ttest-mlogloss:0.532789\n",
      "[370]\ttrain-mlogloss:0.458395\ttest-mlogloss:0.532766\n",
      "[371]\ttrain-mlogloss:0.458165\ttest-mlogloss:0.53275\n",
      "[372]\ttrain-mlogloss:0.457915\ttest-mlogloss:0.532665\n",
      "[373]\ttrain-mlogloss:0.457695\ttest-mlogloss:0.532715\n",
      "[374]\ttrain-mlogloss:0.457464\ttest-mlogloss:0.532629\n",
      "[375]\ttrain-mlogloss:0.457274\ttest-mlogloss:0.53259\n",
      "[376]\ttrain-mlogloss:0.457078\ttest-mlogloss:0.532525\n",
      "[377]\ttrain-mlogloss:0.456894\ttest-mlogloss:0.532491\n",
      "[378]\ttrain-mlogloss:0.456647\ttest-mlogloss:0.532436\n",
      "[379]\ttrain-mlogloss:0.456428\ttest-mlogloss:0.532373\n",
      "[380]\ttrain-mlogloss:0.456227\ttest-mlogloss:0.532386\n",
      "[381]\ttrain-mlogloss:0.456044\ttest-mlogloss:0.532439\n",
      "[382]\ttrain-mlogloss:0.455822\ttest-mlogloss:0.532332\n",
      "[383]\ttrain-mlogloss:0.455585\ttest-mlogloss:0.532296\n",
      "[384]\ttrain-mlogloss:0.45541\ttest-mlogloss:0.532247\n",
      "[385]\ttrain-mlogloss:0.455156\ttest-mlogloss:0.532126\n",
      "[386]\ttrain-mlogloss:0.454934\ttest-mlogloss:0.532172\n",
      "[387]\ttrain-mlogloss:0.454717\ttest-mlogloss:0.532055\n",
      "[388]\ttrain-mlogloss:0.45447\ttest-mlogloss:0.532074\n",
      "[389]\ttrain-mlogloss:0.454234\ttest-mlogloss:0.532032\n",
      "[390]\ttrain-mlogloss:0.453971\ttest-mlogloss:0.531879\n",
      "[391]\ttrain-mlogloss:0.453773\ttest-mlogloss:0.531889\n",
      "[392]\ttrain-mlogloss:0.453647\ttest-mlogloss:0.531878\n",
      "[393]\ttrain-mlogloss:0.453453\ttest-mlogloss:0.5319\n",
      "[394]\ttrain-mlogloss:0.45323\ttest-mlogloss:0.531931\n",
      "[395]\ttrain-mlogloss:0.453059\ttest-mlogloss:0.531851\n",
      "[396]\ttrain-mlogloss:0.452879\ttest-mlogloss:0.531819\n",
      "[397]\ttrain-mlogloss:0.452652\ttest-mlogloss:0.531746\n",
      "[398]\ttrain-mlogloss:0.452401\ttest-mlogloss:0.531776\n",
      "[399]\ttrain-mlogloss:0.452234\ttest-mlogloss:0.531808\n",
      "[400]\ttrain-mlogloss:0.452099\ttest-mlogloss:0.531727\n",
      "[401]\ttrain-mlogloss:0.451903\ttest-mlogloss:0.531646\n",
      "[402]\ttrain-mlogloss:0.451712\ttest-mlogloss:0.531654\n",
      "[403]\ttrain-mlogloss:0.451544\ttest-mlogloss:0.53162\n",
      "[404]\ttrain-mlogloss:0.451329\ttest-mlogloss:0.531526\n",
      "[405]\ttrain-mlogloss:0.451104\ttest-mlogloss:0.531555\n",
      "[406]\ttrain-mlogloss:0.450884\ttest-mlogloss:0.53154\n",
      "[407]\ttrain-mlogloss:0.450684\ttest-mlogloss:0.531509\n",
      "[408]\ttrain-mlogloss:0.450491\ttest-mlogloss:0.531508\n",
      "[409]\ttrain-mlogloss:0.450266\ttest-mlogloss:0.531518\n",
      "[410]\ttrain-mlogloss:0.450053\ttest-mlogloss:0.531552\n",
      "[411]\ttrain-mlogloss:0.449895\ttest-mlogloss:0.5315\n",
      "[412]\ttrain-mlogloss:0.449685\ttest-mlogloss:0.531522\n",
      "[413]\ttrain-mlogloss:0.449511\ttest-mlogloss:0.531527\n",
      "[414]\ttrain-mlogloss:0.44923\ttest-mlogloss:0.531429\n",
      "[415]\ttrain-mlogloss:0.448966\ttest-mlogloss:0.531439\n",
      "[416]\ttrain-mlogloss:0.448764\ttest-mlogloss:0.531367\n",
      "[417]\ttrain-mlogloss:0.448636\ttest-mlogloss:0.531352\n",
      "[418]\ttrain-mlogloss:0.448282\ttest-mlogloss:0.531263\n",
      "[419]\ttrain-mlogloss:0.44815\ttest-mlogloss:0.531254\n",
      "[420]\ttrain-mlogloss:0.447901\ttest-mlogloss:0.531246\n",
      "[421]\ttrain-mlogloss:0.447771\ttest-mlogloss:0.531295\n",
      "[422]\ttrain-mlogloss:0.447582\ttest-mlogloss:0.531248\n",
      "[423]\ttrain-mlogloss:0.447365\ttest-mlogloss:0.531169\n",
      "[424]\ttrain-mlogloss:0.447181\ttest-mlogloss:0.53111\n",
      "[425]\ttrain-mlogloss:0.447042\ttest-mlogloss:0.531096\n",
      "[426]\ttrain-mlogloss:0.446769\ttest-mlogloss:0.531054\n",
      "[427]\ttrain-mlogloss:0.446555\ttest-mlogloss:0.531026\n",
      "[428]\ttrain-mlogloss:0.446278\ttest-mlogloss:0.530938\n",
      "[429]\ttrain-mlogloss:0.446109\ttest-mlogloss:0.530896\n",
      "[430]\ttrain-mlogloss:0.445908\ttest-mlogloss:0.530856\n",
      "[431]\ttrain-mlogloss:0.445759\ttest-mlogloss:0.530803\n",
      "[432]\ttrain-mlogloss:0.445622\ttest-mlogloss:0.53078\n",
      "[433]\ttrain-mlogloss:0.445422\ttest-mlogloss:0.530793\n",
      "[434]\ttrain-mlogloss:0.445167\ttest-mlogloss:0.530764\n",
      "[435]\ttrain-mlogloss:0.445016\ttest-mlogloss:0.530705\n",
      "[436]\ttrain-mlogloss:0.444761\ttest-mlogloss:0.530706\n",
      "[437]\ttrain-mlogloss:0.444548\ttest-mlogloss:0.53074\n",
      "[438]\ttrain-mlogloss:0.444344\ttest-mlogloss:0.53078\n",
      "[439]\ttrain-mlogloss:0.444181\ttest-mlogloss:0.53077\n",
      "[440]\ttrain-mlogloss:0.443956\ttest-mlogloss:0.530813\n",
      "[441]\ttrain-mlogloss:0.443748\ttest-mlogloss:0.53078\n",
      "[442]\ttrain-mlogloss:0.443545\ttest-mlogloss:0.530688\n",
      "[443]\ttrain-mlogloss:0.443338\ttest-mlogloss:0.530694\n",
      "[444]\ttrain-mlogloss:0.44311\ttest-mlogloss:0.53064\n",
      "[445]\ttrain-mlogloss:0.442882\ttest-mlogloss:0.53059\n",
      "[446]\ttrain-mlogloss:0.442657\ttest-mlogloss:0.530607\n",
      "[447]\ttrain-mlogloss:0.442432\ttest-mlogloss:0.530583\n",
      "[448]\ttrain-mlogloss:0.442286\ttest-mlogloss:0.530571\n",
      "[449]\ttrain-mlogloss:0.44209\ttest-mlogloss:0.530533\n",
      "[450]\ttrain-mlogloss:0.441938\ttest-mlogloss:0.530581\n",
      "[451]\ttrain-mlogloss:0.441783\ttest-mlogloss:0.530546\n",
      "[452]\ttrain-mlogloss:0.441638\ttest-mlogloss:0.530538\n",
      "[453]\ttrain-mlogloss:0.441472\ttest-mlogloss:0.530605\n",
      "[454]\ttrain-mlogloss:0.441297\ttest-mlogloss:0.53058\n",
      "[455]\ttrain-mlogloss:0.441106\ttest-mlogloss:0.530519\n",
      "[456]\ttrain-mlogloss:0.440884\ttest-mlogloss:0.530437\n",
      "[457]\ttrain-mlogloss:0.440709\ttest-mlogloss:0.530458\n",
      "[458]\ttrain-mlogloss:0.440461\ttest-mlogloss:0.530438\n",
      "[459]\ttrain-mlogloss:0.440297\ttest-mlogloss:0.530392\n",
      "[460]\ttrain-mlogloss:0.440083\ttest-mlogloss:0.530332\n",
      "[461]\ttrain-mlogloss:0.439927\ttest-mlogloss:0.530384\n",
      "[462]\ttrain-mlogloss:0.439718\ttest-mlogloss:0.530334\n",
      "[463]\ttrain-mlogloss:0.439506\ttest-mlogloss:0.530285\n",
      "[464]\ttrain-mlogloss:0.439291\ttest-mlogloss:0.530249\n",
      "[465]\ttrain-mlogloss:0.439104\ttest-mlogloss:0.530162\n",
      "[466]\ttrain-mlogloss:0.438899\ttest-mlogloss:0.530194\n",
      "[467]\ttrain-mlogloss:0.438699\ttest-mlogloss:0.530204\n",
      "[468]\ttrain-mlogloss:0.438531\ttest-mlogloss:0.530188\n",
      "[469]\ttrain-mlogloss:0.438394\ttest-mlogloss:0.530219\n",
      "[470]\ttrain-mlogloss:0.438225\ttest-mlogloss:0.530211\n",
      "[471]\ttrain-mlogloss:0.438009\ttest-mlogloss:0.530143\n",
      "[472]\ttrain-mlogloss:0.437776\ttest-mlogloss:0.530131\n",
      "[473]\ttrain-mlogloss:0.437525\ttest-mlogloss:0.530087\n",
      "[474]\ttrain-mlogloss:0.437394\ttest-mlogloss:0.53008\n",
      "[475]\ttrain-mlogloss:0.437224\ttest-mlogloss:0.530085\n",
      "[476]\ttrain-mlogloss:0.436999\ttest-mlogloss:0.530124\n",
      "[477]\ttrain-mlogloss:0.436716\ttest-mlogloss:0.53002\n",
      "[478]\ttrain-mlogloss:0.436514\ttest-mlogloss:0.529997\n",
      "[479]\ttrain-mlogloss:0.436276\ttest-mlogloss:0.530008\n",
      "[480]\ttrain-mlogloss:0.436069\ttest-mlogloss:0.530042\n",
      "[481]\ttrain-mlogloss:0.435876\ttest-mlogloss:0.529918\n",
      "[482]\ttrain-mlogloss:0.435672\ttest-mlogloss:0.52989\n",
      "[483]\ttrain-mlogloss:0.435495\ttest-mlogloss:0.529872\n",
      "[484]\ttrain-mlogloss:0.435352\ttest-mlogloss:0.529854\n",
      "[485]\ttrain-mlogloss:0.43507\ttest-mlogloss:0.529764\n",
      "[486]\ttrain-mlogloss:0.434927\ttest-mlogloss:0.529683\n",
      "[487]\ttrain-mlogloss:0.434843\ttest-mlogloss:0.529633\n",
      "[488]\ttrain-mlogloss:0.434644\ttest-mlogloss:0.529639\n",
      "[489]\ttrain-mlogloss:0.434486\ttest-mlogloss:0.529621\n",
      "[490]\ttrain-mlogloss:0.434253\ttest-mlogloss:0.529631\n",
      "[491]\ttrain-mlogloss:0.434028\ttest-mlogloss:0.529589\n",
      "[492]\ttrain-mlogloss:0.433855\ttest-mlogloss:0.529594\n",
      "[493]\ttrain-mlogloss:0.433688\ttest-mlogloss:0.529563\n",
      "[494]\ttrain-mlogloss:0.433549\ttest-mlogloss:0.529517\n",
      "[495]\ttrain-mlogloss:0.433322\ttest-mlogloss:0.529466\n",
      "[496]\ttrain-mlogloss:0.433131\ttest-mlogloss:0.52954\n",
      "[497]\ttrain-mlogloss:0.433007\ttest-mlogloss:0.529544\n",
      "[498]\ttrain-mlogloss:0.432765\ttest-mlogloss:0.529515\n",
      "[499]\ttrain-mlogloss:0.432557\ttest-mlogloss:0.529592\n",
      "[500]\ttrain-mlogloss:0.432411\ttest-mlogloss:0.52961\n",
      "[501]\ttrain-mlogloss:0.432199\ttest-mlogloss:0.529709\n",
      "[502]\ttrain-mlogloss:0.43202\ttest-mlogloss:0.529659\n",
      "[503]\ttrain-mlogloss:0.431881\ttest-mlogloss:0.529683\n",
      "[504]\ttrain-mlogloss:0.431704\ttest-mlogloss:0.529661\n",
      "[505]\ttrain-mlogloss:0.431477\ttest-mlogloss:0.529672\n",
      "[506]\ttrain-mlogloss:0.431265\ttest-mlogloss:0.529616\n",
      "[507]\ttrain-mlogloss:0.431122\ttest-mlogloss:0.529579\n",
      "[508]\ttrain-mlogloss:0.430898\ttest-mlogloss:0.529592\n",
      "[509]\ttrain-mlogloss:0.430739\ttest-mlogloss:0.529561\n",
      "[510]\ttrain-mlogloss:0.430566\ttest-mlogloss:0.52962\n",
      "[511]\ttrain-mlogloss:0.430391\ttest-mlogloss:0.529669\n",
      "[512]\ttrain-mlogloss:0.430176\ttest-mlogloss:0.529676\n",
      "[513]\ttrain-mlogloss:0.429969\ttest-mlogloss:0.529691\n",
      "[514]\ttrain-mlogloss:0.429813\ttest-mlogloss:0.529625\n",
      "[515]\ttrain-mlogloss:0.429632\ttest-mlogloss:0.52962\n",
      "[516]\ttrain-mlogloss:0.429467\ttest-mlogloss:0.529635\n",
      "[517]\ttrain-mlogloss:0.429325\ttest-mlogloss:0.529656\n",
      "[518]\ttrain-mlogloss:0.429118\ttest-mlogloss:0.529654\n",
      "[519]\ttrain-mlogloss:0.428944\ttest-mlogloss:0.529597\n",
      "[520]\ttrain-mlogloss:0.428824\ttest-mlogloss:0.529551\n",
      "[521]\ttrain-mlogloss:0.428677\ttest-mlogloss:0.529514\n",
      "[522]\ttrain-mlogloss:0.428507\ttest-mlogloss:0.529508\n",
      "[523]\ttrain-mlogloss:0.428351\ttest-mlogloss:0.529488\n",
      "[524]\ttrain-mlogloss:0.428193\ttest-mlogloss:0.529488\n",
      "[525]\ttrain-mlogloss:0.428061\ttest-mlogloss:0.529476\n",
      "[526]\ttrain-mlogloss:0.427852\ttest-mlogloss:0.529515\n",
      "[527]\ttrain-mlogloss:0.427659\ttest-mlogloss:0.529481\n",
      "[528]\ttrain-mlogloss:0.427554\ttest-mlogloss:0.529454\n",
      "[529]\ttrain-mlogloss:0.427404\ttest-mlogloss:0.529507\n",
      "[530]\ttrain-mlogloss:0.427189\ttest-mlogloss:0.529413\n",
      "[531]\ttrain-mlogloss:0.426998\ttest-mlogloss:0.529347\n",
      "[532]\ttrain-mlogloss:0.426899\ttest-mlogloss:0.529413\n",
      "[533]\ttrain-mlogloss:0.426699\ttest-mlogloss:0.52937\n",
      "[534]\ttrain-mlogloss:0.426473\ttest-mlogloss:0.52936\n",
      "[535]\ttrain-mlogloss:0.426317\ttest-mlogloss:0.529331\n",
      "[536]\ttrain-mlogloss:0.426119\ttest-mlogloss:0.529362\n",
      "[537]\ttrain-mlogloss:0.425979\ttest-mlogloss:0.52936\n",
      "[538]\ttrain-mlogloss:0.42582\ttest-mlogloss:0.529342\n",
      "[539]\ttrain-mlogloss:0.42565\ttest-mlogloss:0.529373\n",
      "[540]\ttrain-mlogloss:0.425452\ttest-mlogloss:0.529373\n",
      "[541]\ttrain-mlogloss:0.425254\ttest-mlogloss:0.529381\n",
      "[542]\ttrain-mlogloss:0.425019\ttest-mlogloss:0.529363\n",
      "[543]\ttrain-mlogloss:0.424834\ttest-mlogloss:0.529328\n",
      "[544]\ttrain-mlogloss:0.424682\ttest-mlogloss:0.529347\n",
      "[545]\ttrain-mlogloss:0.42455\ttest-mlogloss:0.529356\n",
      "[546]\ttrain-mlogloss:0.42439\ttest-mlogloss:0.529334\n",
      "[547]\ttrain-mlogloss:0.424184\ttest-mlogloss:0.529336\n",
      "[548]\ttrain-mlogloss:0.424035\ttest-mlogloss:0.529233\n",
      "[549]\ttrain-mlogloss:0.423887\ttest-mlogloss:0.52922\n",
      "[550]\ttrain-mlogloss:0.423747\ttest-mlogloss:0.529212\n",
      "[551]\ttrain-mlogloss:0.423559\ttest-mlogloss:0.529192\n",
      "[552]\ttrain-mlogloss:0.423391\ttest-mlogloss:0.529134\n",
      "[553]\ttrain-mlogloss:0.423241\ttest-mlogloss:0.529156\n",
      "[554]\ttrain-mlogloss:0.423006\ttest-mlogloss:0.529069\n",
      "[555]\ttrain-mlogloss:0.422837\ttest-mlogloss:0.529049\n",
      "[556]\ttrain-mlogloss:0.422682\ttest-mlogloss:0.529095\n",
      "[557]\ttrain-mlogloss:0.422511\ttest-mlogloss:0.529083\n",
      "[558]\ttrain-mlogloss:0.422342\ttest-mlogloss:0.529064\n",
      "[559]\ttrain-mlogloss:0.422115\ttest-mlogloss:0.529096\n",
      "[560]\ttrain-mlogloss:0.421937\ttest-mlogloss:0.529095\n",
      "[561]\ttrain-mlogloss:0.421726\ttest-mlogloss:0.52908\n",
      "[562]\ttrain-mlogloss:0.421554\ttest-mlogloss:0.529028\n",
      "[563]\ttrain-mlogloss:0.421344\ttest-mlogloss:0.528989\n",
      "[564]\ttrain-mlogloss:0.421182\ttest-mlogloss:0.528992\n",
      "[565]\ttrain-mlogloss:0.421009\ttest-mlogloss:0.528936\n",
      "[566]\ttrain-mlogloss:0.420897\ttest-mlogloss:0.52888\n",
      "[567]\ttrain-mlogloss:0.420716\ttest-mlogloss:0.528805\n",
      "[568]\ttrain-mlogloss:0.420541\ttest-mlogloss:0.528798\n",
      "[569]\ttrain-mlogloss:0.42034\ttest-mlogloss:0.528757\n",
      "[570]\ttrain-mlogloss:0.420151\ttest-mlogloss:0.52872\n",
      "[571]\ttrain-mlogloss:0.419977\ttest-mlogloss:0.528718\n",
      "[572]\ttrain-mlogloss:0.419835\ttest-mlogloss:0.528777\n",
      "[573]\ttrain-mlogloss:0.419652\ttest-mlogloss:0.528817\n",
      "[574]\ttrain-mlogloss:0.419484\ttest-mlogloss:0.528781\n",
      "[575]\ttrain-mlogloss:0.419295\ttest-mlogloss:0.528813\n",
      "[576]\ttrain-mlogloss:0.419136\ttest-mlogloss:0.528796\n",
      "[577]\ttrain-mlogloss:0.41903\ttest-mlogloss:0.528807\n",
      "[578]\ttrain-mlogloss:0.418908\ttest-mlogloss:0.528846\n",
      "[579]\ttrain-mlogloss:0.418733\ttest-mlogloss:0.528822\n",
      "[580]\ttrain-mlogloss:0.418509\ttest-mlogloss:0.528729\n",
      "[581]\ttrain-mlogloss:0.418328\ttest-mlogloss:0.528691\n",
      "[582]\ttrain-mlogloss:0.418134\ttest-mlogloss:0.528656\n",
      "[583]\ttrain-mlogloss:0.41796\ttest-mlogloss:0.528704\n",
      "[584]\ttrain-mlogloss:0.417777\ttest-mlogloss:0.528752\n",
      "[585]\ttrain-mlogloss:0.417601\ttest-mlogloss:0.528744\n",
      "[586]\ttrain-mlogloss:0.417462\ttest-mlogloss:0.528734\n",
      "[587]\ttrain-mlogloss:0.417316\ttest-mlogloss:0.528765\n",
      "[588]\ttrain-mlogloss:0.417174\ttest-mlogloss:0.528747\n",
      "[589]\ttrain-mlogloss:0.41708\ttest-mlogloss:0.528797\n",
      "[590]\ttrain-mlogloss:0.416874\ttest-mlogloss:0.528779\n",
      "[591]\ttrain-mlogloss:0.416664\ttest-mlogloss:0.528852\n",
      "[592]\ttrain-mlogloss:0.416451\ttest-mlogloss:0.528838\n",
      "[593]\ttrain-mlogloss:0.416257\ttest-mlogloss:0.528894\n",
      "[594]\ttrain-mlogloss:0.41605\ttest-mlogloss:0.528909\n",
      "[595]\ttrain-mlogloss:0.415859\ttest-mlogloss:0.528928\n",
      "[596]\ttrain-mlogloss:0.41563\ttest-mlogloss:0.528863\n",
      "[597]\ttrain-mlogloss:0.415483\ttest-mlogloss:0.528864\n",
      "[598]\ttrain-mlogloss:0.415272\ttest-mlogloss:0.528882\n",
      "[599]\ttrain-mlogloss:0.415059\ttest-mlogloss:0.528934\n",
      "[600]\ttrain-mlogloss:0.414903\ttest-mlogloss:0.528916\n",
      "[601]\ttrain-mlogloss:0.414699\ttest-mlogloss:0.528912\n",
      "[602]\ttrain-mlogloss:0.414534\ttest-mlogloss:0.528912\n",
      "[603]\ttrain-mlogloss:0.414314\ttest-mlogloss:0.528893\n",
      "[604]\ttrain-mlogloss:0.41416\ttest-mlogloss:0.528861\n",
      "[605]\ttrain-mlogloss:0.414032\ttest-mlogloss:0.528889\n",
      "[606]\ttrain-mlogloss:0.413853\ttest-mlogloss:0.528937\n",
      "[607]\ttrain-mlogloss:0.413617\ttest-mlogloss:0.528965\n",
      "[608]\ttrain-mlogloss:0.41345\ttest-mlogloss:0.528998\n",
      "[609]\ttrain-mlogloss:0.413304\ttest-mlogloss:0.528967\n",
      "[610]\ttrain-mlogloss:0.41312\ttest-mlogloss:0.528981\n",
      "[611]\ttrain-mlogloss:0.412953\ttest-mlogloss:0.528979\n",
      "[612]\ttrain-mlogloss:0.412753\ttest-mlogloss:0.529011\n",
      "[613]\ttrain-mlogloss:0.412581\ttest-mlogloss:0.528987\n",
      "[614]\ttrain-mlogloss:0.412397\ttest-mlogloss:0.529006\n",
      "[615]\ttrain-mlogloss:0.412232\ttest-mlogloss:0.529021\n",
      "[616]\ttrain-mlogloss:0.412023\ttest-mlogloss:0.528935\n",
      "[617]\ttrain-mlogloss:0.411803\ttest-mlogloss:0.528922\n",
      "[618]\ttrain-mlogloss:0.411625\ttest-mlogloss:0.528958\n",
      "[619]\ttrain-mlogloss:0.41147\ttest-mlogloss:0.528938\n",
      "[620]\ttrain-mlogloss:0.411269\ttest-mlogloss:0.52887\n",
      "[621]\ttrain-mlogloss:0.411089\ttest-mlogloss:0.528871\n",
      "[622]\ttrain-mlogloss:0.410971\ttest-mlogloss:0.528859\n",
      "[623]\ttrain-mlogloss:0.410831\ttest-mlogloss:0.528867\n",
      "[624]\ttrain-mlogloss:0.410653\ttest-mlogloss:0.528905\n",
      "[625]\ttrain-mlogloss:0.410412\ttest-mlogloss:0.528883\n",
      "[626]\ttrain-mlogloss:0.410245\ttest-mlogloss:0.528913\n",
      "[627]\ttrain-mlogloss:0.410084\ttest-mlogloss:0.528928\n",
      "[628]\ttrain-mlogloss:0.409947\ttest-mlogloss:0.52892\n",
      "[629]\ttrain-mlogloss:0.409791\ttest-mlogloss:0.528903\n",
      "[630]\ttrain-mlogloss:0.409629\ttest-mlogloss:0.52885\n",
      "[631]\ttrain-mlogloss:0.409459\ttest-mlogloss:0.528886\n",
      "[632]\ttrain-mlogloss:0.409333\ttest-mlogloss:0.528895\n",
      "[633]\ttrain-mlogloss:0.409226\ttest-mlogloss:0.528886\n",
      "[634]\ttrain-mlogloss:0.409027\ttest-mlogloss:0.5288\n",
      "[635]\ttrain-mlogloss:0.408913\ttest-mlogloss:0.528831\n",
      "[636]\ttrain-mlogloss:0.408799\ttest-mlogloss:0.52877\n",
      "[637]\ttrain-mlogloss:0.408549\ttest-mlogloss:0.528701\n",
      "[638]\ttrain-mlogloss:0.40842\ttest-mlogloss:0.528684\n",
      "[639]\ttrain-mlogloss:0.408276\ttest-mlogloss:0.528658\n",
      "[640]\ttrain-mlogloss:0.408109\ttest-mlogloss:0.52864\n",
      "[641]\ttrain-mlogloss:0.407912\ttest-mlogloss:0.528596\n",
      "[642]\ttrain-mlogloss:0.407709\ttest-mlogloss:0.528615\n",
      "[643]\ttrain-mlogloss:0.407625\ttest-mlogloss:0.528578\n",
      "[644]\ttrain-mlogloss:0.407516\ttest-mlogloss:0.528609\n",
      "[645]\ttrain-mlogloss:0.407304\ttest-mlogloss:0.528615\n",
      "[646]\ttrain-mlogloss:0.407148\ttest-mlogloss:0.528634\n",
      "[647]\ttrain-mlogloss:0.407031\ttest-mlogloss:0.528588\n",
      "[648]\ttrain-mlogloss:0.406886\ttest-mlogloss:0.528684\n",
      "[649]\ttrain-mlogloss:0.406685\ttest-mlogloss:0.528661\n",
      "[650]\ttrain-mlogloss:0.40656\ttest-mlogloss:0.52866\n",
      "[651]\ttrain-mlogloss:0.406361\ttest-mlogloss:0.528634\n",
      "[652]\ttrain-mlogloss:0.406205\ttest-mlogloss:0.528553\n",
      "[653]\ttrain-mlogloss:0.406019\ttest-mlogloss:0.528582\n",
      "[654]\ttrain-mlogloss:0.40582\ttest-mlogloss:0.528551\n",
      "[655]\ttrain-mlogloss:0.405616\ttest-mlogloss:0.528585\n",
      "[656]\ttrain-mlogloss:0.405476\ttest-mlogloss:0.528513\n",
      "[657]\ttrain-mlogloss:0.405296\ttest-mlogloss:0.528416\n",
      "[658]\ttrain-mlogloss:0.405125\ttest-mlogloss:0.52836\n",
      "[659]\ttrain-mlogloss:0.404866\ttest-mlogloss:0.528328\n",
      "[660]\ttrain-mlogloss:0.404664\ttest-mlogloss:0.528319\n",
      "[661]\ttrain-mlogloss:0.404492\ttest-mlogloss:0.528274\n",
      "[662]\ttrain-mlogloss:0.404282\ttest-mlogloss:0.528344\n",
      "[663]\ttrain-mlogloss:0.404141\ttest-mlogloss:0.528399\n",
      "[664]\ttrain-mlogloss:0.403999\ttest-mlogloss:0.528436\n",
      "[665]\ttrain-mlogloss:0.403798\ttest-mlogloss:0.528463\n",
      "[666]\ttrain-mlogloss:0.403577\ttest-mlogloss:0.528475\n",
      "[667]\ttrain-mlogloss:0.403406\ttest-mlogloss:0.528475\n",
      "[668]\ttrain-mlogloss:0.4033\ttest-mlogloss:0.528422\n",
      "[669]\ttrain-mlogloss:0.403102\ttest-mlogloss:0.528473\n",
      "[670]\ttrain-mlogloss:0.402944\ttest-mlogloss:0.528525\n",
      "[671]\ttrain-mlogloss:0.402847\ttest-mlogloss:0.528502\n",
      "[672]\ttrain-mlogloss:0.402676\ttest-mlogloss:0.52847\n",
      "[673]\ttrain-mlogloss:0.402551\ttest-mlogloss:0.528455\n",
      "[674]\ttrain-mlogloss:0.402436\ttest-mlogloss:0.528391\n",
      "[675]\ttrain-mlogloss:0.40228\ttest-mlogloss:0.528439\n",
      "[676]\ttrain-mlogloss:0.402112\ttest-mlogloss:0.528499\n",
      "[677]\ttrain-mlogloss:0.401977\ttest-mlogloss:0.528477\n",
      "[678]\ttrain-mlogloss:0.401849\ttest-mlogloss:0.528454\n",
      "[679]\ttrain-mlogloss:0.401675\ttest-mlogloss:0.528485\n",
      "[680]\ttrain-mlogloss:0.401503\ttest-mlogloss:0.528445\n",
      "[681]\ttrain-mlogloss:0.401342\ttest-mlogloss:0.528448\n",
      "[682]\ttrain-mlogloss:0.401147\ttest-mlogloss:0.528422\n",
      "[683]\ttrain-mlogloss:0.400991\ttest-mlogloss:0.528374\n",
      "[684]\ttrain-mlogloss:0.40087\ttest-mlogloss:0.52839\n",
      "[685]\ttrain-mlogloss:0.40067\ttest-mlogloss:0.528381\n",
      "[686]\ttrain-mlogloss:0.400504\ttest-mlogloss:0.528396\n",
      "[687]\ttrain-mlogloss:0.400338\ttest-mlogloss:0.528519\n",
      "[688]\ttrain-mlogloss:0.40023\ttest-mlogloss:0.528514\n",
      "[689]\ttrain-mlogloss:0.4001\ttest-mlogloss:0.528495\n",
      "[690]\ttrain-mlogloss:0.400019\ttest-mlogloss:0.528496\n",
      "[691]\ttrain-mlogloss:0.39979\ttest-mlogloss:0.528508\n",
      "[692]\ttrain-mlogloss:0.399644\ttest-mlogloss:0.528514\n",
      "[693]\ttrain-mlogloss:0.399476\ttest-mlogloss:0.528384\n",
      "[694]\ttrain-mlogloss:0.39934\ttest-mlogloss:0.528366\n",
      "[695]\ttrain-mlogloss:0.399156\ttest-mlogloss:0.528314\n",
      "[696]\ttrain-mlogloss:0.398964\ttest-mlogloss:0.528329\n",
      "[697]\ttrain-mlogloss:0.398815\ttest-mlogloss:0.528408\n",
      "[698]\ttrain-mlogloss:0.398646\ttest-mlogloss:0.528306\n",
      "[699]\ttrain-mlogloss:0.398475\ttest-mlogloss:0.528326\n",
      "[700]\ttrain-mlogloss:0.398284\ttest-mlogloss:0.528264\n",
      "[701]\ttrain-mlogloss:0.398148\ttest-mlogloss:0.528262\n",
      "[702]\ttrain-mlogloss:0.397967\ttest-mlogloss:0.528255\n",
      "[703]\ttrain-mlogloss:0.39786\ttest-mlogloss:0.528307\n",
      "[704]\ttrain-mlogloss:0.397654\ttest-mlogloss:0.528292\n",
      "[705]\ttrain-mlogloss:0.397502\ttest-mlogloss:0.528261\n",
      "[706]\ttrain-mlogloss:0.397368\ttest-mlogloss:0.528297\n",
      "[707]\ttrain-mlogloss:0.397244\ttest-mlogloss:0.52831\n",
      "[708]\ttrain-mlogloss:0.397085\ttest-mlogloss:0.528306\n",
      "[709]\ttrain-mlogloss:0.396898\ttest-mlogloss:0.528309\n",
      "[710]\ttrain-mlogloss:0.396766\ttest-mlogloss:0.528351\n",
      "[711]\ttrain-mlogloss:0.396633\ttest-mlogloss:0.528295\n",
      "[712]\ttrain-mlogloss:0.396475\ttest-mlogloss:0.528309\n",
      "[713]\ttrain-mlogloss:0.39626\ttest-mlogloss:0.52832\n",
      "[714]\ttrain-mlogloss:0.396125\ttest-mlogloss:0.5283\n",
      "[715]\ttrain-mlogloss:0.395976\ttest-mlogloss:0.528279\n",
      "[716]\ttrain-mlogloss:0.395807\ttest-mlogloss:0.528363\n",
      "[717]\ttrain-mlogloss:0.395683\ttest-mlogloss:0.528411\n",
      "[718]\ttrain-mlogloss:0.39551\ttest-mlogloss:0.528396\n",
      "[719]\ttrain-mlogloss:0.395322\ttest-mlogloss:0.52841\n",
      "[720]\ttrain-mlogloss:0.395249\ttest-mlogloss:0.528405\n",
      "[721]\ttrain-mlogloss:0.395072\ttest-mlogloss:0.528326\n",
      "[722]\ttrain-mlogloss:0.394929\ttest-mlogloss:0.528279\n",
      "[723]\ttrain-mlogloss:0.394809\ttest-mlogloss:0.528245\n",
      "[724]\ttrain-mlogloss:0.394626\ttest-mlogloss:0.528175\n",
      "[725]\ttrain-mlogloss:0.394516\ttest-mlogloss:0.528155\n",
      "[726]\ttrain-mlogloss:0.39436\ttest-mlogloss:0.52816\n",
      "[727]\ttrain-mlogloss:0.394172\ttest-mlogloss:0.52809\n",
      "[728]\ttrain-mlogloss:0.394032\ttest-mlogloss:0.528096\n",
      "[729]\ttrain-mlogloss:0.393868\ttest-mlogloss:0.52812\n",
      "[730]\ttrain-mlogloss:0.393759\ttest-mlogloss:0.528124\n",
      "[731]\ttrain-mlogloss:0.393628\ttest-mlogloss:0.528071\n",
      "[732]\ttrain-mlogloss:0.393492\ttest-mlogloss:0.528048\n",
      "[733]\ttrain-mlogloss:0.393363\ttest-mlogloss:0.528091\n",
      "[734]\ttrain-mlogloss:0.393204\ttest-mlogloss:0.528142\n",
      "[735]\ttrain-mlogloss:0.393064\ttest-mlogloss:0.528177\n",
      "[736]\ttrain-mlogloss:0.392926\ttest-mlogloss:0.528157\n",
      "[737]\ttrain-mlogloss:0.392733\ttest-mlogloss:0.528173\n",
      "[738]\ttrain-mlogloss:0.392538\ttest-mlogloss:0.528252\n",
      "[739]\ttrain-mlogloss:0.392415\ttest-mlogloss:0.528255\n",
      "[740]\ttrain-mlogloss:0.392256\ttest-mlogloss:0.528248\n",
      "[741]\ttrain-mlogloss:0.392161\ttest-mlogloss:0.528271\n",
      "[742]\ttrain-mlogloss:0.391978\ttest-mlogloss:0.528234\n",
      "[743]\ttrain-mlogloss:0.391822\ttest-mlogloss:0.528197\n",
      "[744]\ttrain-mlogloss:0.391667\ttest-mlogloss:0.528183\n",
      "[745]\ttrain-mlogloss:0.391537\ttest-mlogloss:0.528198\n",
      "[746]\ttrain-mlogloss:0.391397\ttest-mlogloss:0.528122\n",
      "[747]\ttrain-mlogloss:0.39126\ttest-mlogloss:0.528091\n",
      "[748]\ttrain-mlogloss:0.391124\ttest-mlogloss:0.528103\n",
      "[749]\ttrain-mlogloss:0.390947\ttest-mlogloss:0.528142\n",
      "[750]\ttrain-mlogloss:0.390794\ttest-mlogloss:0.528133\n",
      "[751]\ttrain-mlogloss:0.390652\ttest-mlogloss:0.528087\n",
      "[752]\ttrain-mlogloss:0.390502\ttest-mlogloss:0.528038\n",
      "[753]\ttrain-mlogloss:0.390348\ttest-mlogloss:0.528007\n",
      "[754]\ttrain-mlogloss:0.390169\ttest-mlogloss:0.527985\n",
      "[755]\ttrain-mlogloss:0.390008\ttest-mlogloss:0.528047\n",
      "[756]\ttrain-mlogloss:0.389873\ttest-mlogloss:0.528077\n",
      "[757]\ttrain-mlogloss:0.389726\ttest-mlogloss:0.528076\n",
      "[758]\ttrain-mlogloss:0.389569\ttest-mlogloss:0.528095\n",
      "[759]\ttrain-mlogloss:0.389414\ttest-mlogloss:0.528042\n",
      "[760]\ttrain-mlogloss:0.389237\ttest-mlogloss:0.528099\n",
      "[761]\ttrain-mlogloss:0.389068\ttest-mlogloss:0.528024\n",
      "[762]\ttrain-mlogloss:0.388923\ttest-mlogloss:0.528053\n",
      "[763]\ttrain-mlogloss:0.388769\ttest-mlogloss:0.528085\n",
      "[764]\ttrain-mlogloss:0.388622\ttest-mlogloss:0.528127\n",
      "[765]\ttrain-mlogloss:0.388484\ttest-mlogloss:0.528154\n",
      "[766]\ttrain-mlogloss:0.388367\ttest-mlogloss:0.528181\n",
      "[767]\ttrain-mlogloss:0.38826\ttest-mlogloss:0.52817\n",
      "[768]\ttrain-mlogloss:0.388077\ttest-mlogloss:0.528222\n",
      "[769]\ttrain-mlogloss:0.387915\ttest-mlogloss:0.528235\n",
      "[770]\ttrain-mlogloss:0.387804\ttest-mlogloss:0.528264\n",
      "[771]\ttrain-mlogloss:0.387628\ttest-mlogloss:0.528249\n",
      "[772]\ttrain-mlogloss:0.387447\ttest-mlogloss:0.528254\n",
      "[773]\ttrain-mlogloss:0.387272\ttest-mlogloss:0.528255\n",
      "[774]\ttrain-mlogloss:0.387116\ttest-mlogloss:0.528212\n",
      "[775]\ttrain-mlogloss:0.386966\ttest-mlogloss:0.528219\n",
      "[776]\ttrain-mlogloss:0.386827\ttest-mlogloss:0.528189\n",
      "[777]\ttrain-mlogloss:0.38668\ttest-mlogloss:0.528231\n",
      "[778]\ttrain-mlogloss:0.386539\ttest-mlogloss:0.528241\n",
      "[779]\ttrain-mlogloss:0.386373\ttest-mlogloss:0.528183\n",
      "[780]\ttrain-mlogloss:0.38621\ttest-mlogloss:0.528231\n",
      "[781]\ttrain-mlogloss:0.386045\ttest-mlogloss:0.528167\n",
      "[782]\ttrain-mlogloss:0.385936\ttest-mlogloss:0.528155\n",
      "[783]\ttrain-mlogloss:0.385799\ttest-mlogloss:0.528115\n",
      "[784]\ttrain-mlogloss:0.385638\ttest-mlogloss:0.528068\n",
      "[785]\ttrain-mlogloss:0.385489\ttest-mlogloss:0.528046\n",
      "[786]\ttrain-mlogloss:0.385346\ttest-mlogloss:0.528037\n",
      "[787]\ttrain-mlogloss:0.385196\ttest-mlogloss:0.528079\n",
      "[788]\ttrain-mlogloss:0.385023\ttest-mlogloss:0.528031\n",
      "[789]\ttrain-mlogloss:0.384863\ttest-mlogloss:0.527976\n",
      "[790]\ttrain-mlogloss:0.384739\ttest-mlogloss:0.527988\n",
      "[791]\ttrain-mlogloss:0.3846\ttest-mlogloss:0.528013\n",
      "[792]\ttrain-mlogloss:0.384449\ttest-mlogloss:0.527964\n",
      "[793]\ttrain-mlogloss:0.384294\ttest-mlogloss:0.527962\n",
      "[794]\ttrain-mlogloss:0.384161\ttest-mlogloss:0.528099\n",
      "[795]\ttrain-mlogloss:0.383994\ttest-mlogloss:0.528122\n",
      "[796]\ttrain-mlogloss:0.38384\ttest-mlogloss:0.528173\n",
      "[797]\ttrain-mlogloss:0.3837\ttest-mlogloss:0.528119\n",
      "[798]\ttrain-mlogloss:0.383584\ttest-mlogloss:0.528135\n",
      "[799]\ttrain-mlogloss:0.383443\ttest-mlogloss:0.528148\n",
      "[800]\ttrain-mlogloss:0.383334\ttest-mlogloss:0.528145\n",
      "[801]\ttrain-mlogloss:0.383222\ttest-mlogloss:0.528145\n",
      "[802]\ttrain-mlogloss:0.383082\ttest-mlogloss:0.528112\n",
      "[803]\ttrain-mlogloss:0.382914\ttest-mlogloss:0.528058\n",
      "[804]\ttrain-mlogloss:0.382753\ttest-mlogloss:0.528058\n",
      "[805]\ttrain-mlogloss:0.382574\ttest-mlogloss:0.52803\n",
      "[806]\ttrain-mlogloss:0.38242\ttest-mlogloss:0.528029\n",
      "[807]\ttrain-mlogloss:0.38227\ttest-mlogloss:0.528045\n",
      "[808]\ttrain-mlogloss:0.382133\ttest-mlogloss:0.528066\n",
      "[809]\ttrain-mlogloss:0.381978\ttest-mlogloss:0.527959\n",
      "[810]\ttrain-mlogloss:0.381865\ttest-mlogloss:0.528019\n",
      "[811]\ttrain-mlogloss:0.381714\ttest-mlogloss:0.528017\n",
      "[812]\ttrain-mlogloss:0.381586\ttest-mlogloss:0.528003\n",
      "[813]\ttrain-mlogloss:0.381386\ttest-mlogloss:0.528027\n",
      "[814]\ttrain-mlogloss:0.381181\ttest-mlogloss:0.528055\n",
      "[815]\ttrain-mlogloss:0.380974\ttest-mlogloss:0.528077\n",
      "[816]\ttrain-mlogloss:0.380834\ttest-mlogloss:0.528043\n",
      "[817]\ttrain-mlogloss:0.380714\ttest-mlogloss:0.528062\n",
      "[818]\ttrain-mlogloss:0.380603\ttest-mlogloss:0.528018\n",
      "[819]\ttrain-mlogloss:0.380457\ttest-mlogloss:0.528034\n",
      "[820]\ttrain-mlogloss:0.380335\ttest-mlogloss:0.528058\n",
      "[821]\ttrain-mlogloss:0.380253\ttest-mlogloss:0.528077\n",
      "[822]\ttrain-mlogloss:0.380119\ttest-mlogloss:0.528151\n",
      "[823]\ttrain-mlogloss:0.37995\ttest-mlogloss:0.528141\n",
      "[824]\ttrain-mlogloss:0.379813\ttest-mlogloss:0.528175\n",
      "[825]\ttrain-mlogloss:0.379635\ttest-mlogloss:0.528199\n",
      "[826]\ttrain-mlogloss:0.379545\ttest-mlogloss:0.528213\n",
      "[827]\ttrain-mlogloss:0.379403\ttest-mlogloss:0.528179\n",
      "[828]\ttrain-mlogloss:0.379272\ttest-mlogloss:0.528212\n",
      "[829]\ttrain-mlogloss:0.37911\ttest-mlogloss:0.52823\n",
      "[830]\ttrain-mlogloss:0.378963\ttest-mlogloss:0.528232\n",
      "[831]\ttrain-mlogloss:0.378807\ttest-mlogloss:0.528238\n",
      "[832]\ttrain-mlogloss:0.378721\ttest-mlogloss:0.528192\n",
      "[833]\ttrain-mlogloss:0.378572\ttest-mlogloss:0.528167\n",
      "[834]\ttrain-mlogloss:0.378446\ttest-mlogloss:0.528218\n",
      "[835]\ttrain-mlogloss:0.378279\ttest-mlogloss:0.528207\n",
      "[836]\ttrain-mlogloss:0.37811\ttest-mlogloss:0.528206\n",
      "[837]\ttrain-mlogloss:0.377936\ttest-mlogloss:0.528204\n",
      "[838]\ttrain-mlogloss:0.377765\ttest-mlogloss:0.528172\n",
      "[839]\ttrain-mlogloss:0.377588\ttest-mlogloss:0.528132\n",
      "[840]\ttrain-mlogloss:0.377465\ttest-mlogloss:0.528155\n",
      "[841]\ttrain-mlogloss:0.377389\ttest-mlogloss:0.528159\n",
      "[842]\ttrain-mlogloss:0.377209\ttest-mlogloss:0.528137\n",
      "[843]\ttrain-mlogloss:0.377066\ttest-mlogloss:0.528142\n",
      "[844]\ttrain-mlogloss:0.37693\ttest-mlogloss:0.528107\n",
      "[845]\ttrain-mlogloss:0.376769\ttest-mlogloss:0.528157\n",
      "[846]\ttrain-mlogloss:0.376606\ttest-mlogloss:0.528183\n",
      "[847]\ttrain-mlogloss:0.376456\ttest-mlogloss:0.528214\n",
      "[848]\ttrain-mlogloss:0.376307\ttest-mlogloss:0.52821\n",
      "[849]\ttrain-mlogloss:0.376202\ttest-mlogloss:0.528236\n",
      "[850]\ttrain-mlogloss:0.376072\ttest-mlogloss:0.528318\n",
      "[851]\ttrain-mlogloss:0.375966\ttest-mlogloss:0.528308\n",
      "[852]\ttrain-mlogloss:0.375868\ttest-mlogloss:0.528302\n",
      "[853]\ttrain-mlogloss:0.375738\ttest-mlogloss:0.528254\n",
      "[854]\ttrain-mlogloss:0.375546\ttest-mlogloss:0.528208\n",
      "[855]\ttrain-mlogloss:0.375449\ttest-mlogloss:0.528253\n",
      "[856]\ttrain-mlogloss:0.375277\ttest-mlogloss:0.528222\n",
      "[857]\ttrain-mlogloss:0.375179\ttest-mlogloss:0.528214\n",
      "[858]\ttrain-mlogloss:0.375027\ttest-mlogloss:0.52814\n",
      "[859]\ttrain-mlogloss:0.374855\ttest-mlogloss:0.528104\n",
      "[860]\ttrain-mlogloss:0.374706\ttest-mlogloss:0.528085\n",
      "[861]\ttrain-mlogloss:0.374589\ttest-mlogloss:0.52806\n",
      "[862]\ttrain-mlogloss:0.374456\ttest-mlogloss:0.528046\n",
      "[863]\ttrain-mlogloss:0.37431\ttest-mlogloss:0.528\n",
      "[864]\ttrain-mlogloss:0.374134\ttest-mlogloss:0.528007\n",
      "[865]\ttrain-mlogloss:0.374012\ttest-mlogloss:0.527994\n",
      "[866]\ttrain-mlogloss:0.373868\ttest-mlogloss:0.528033\n",
      "[867]\ttrain-mlogloss:0.373719\ttest-mlogloss:0.527948\n",
      "[868]\ttrain-mlogloss:0.373599\ttest-mlogloss:0.527972\n",
      "[869]\ttrain-mlogloss:0.373456\ttest-mlogloss:0.527958\n",
      "[870]\ttrain-mlogloss:0.373358\ttest-mlogloss:0.527982\n",
      "[871]\ttrain-mlogloss:0.373231\ttest-mlogloss:0.528038\n",
      "[872]\ttrain-mlogloss:0.373126\ttest-mlogloss:0.528079\n",
      "[873]\ttrain-mlogloss:0.372996\ttest-mlogloss:0.528051\n",
      "[874]\ttrain-mlogloss:0.37281\ttest-mlogloss:0.52805\n",
      "[875]\ttrain-mlogloss:0.372638\ttest-mlogloss:0.527961\n",
      "[876]\ttrain-mlogloss:0.372479\ttest-mlogloss:0.527991\n",
      "[877]\ttrain-mlogloss:0.372399\ttest-mlogloss:0.528033\n",
      "[878]\ttrain-mlogloss:0.372258\ttest-mlogloss:0.528083\n",
      "[879]\ttrain-mlogloss:0.372128\ttest-mlogloss:0.528132\n",
      "[880]\ttrain-mlogloss:0.371971\ttest-mlogloss:0.528188\n",
      "[881]\ttrain-mlogloss:0.371824\ttest-mlogloss:0.528185\n",
      "[882]\ttrain-mlogloss:0.371692\ttest-mlogloss:0.528205\n",
      "[883]\ttrain-mlogloss:0.371555\ttest-mlogloss:0.528242\n",
      "[884]\ttrain-mlogloss:0.371366\ttest-mlogloss:0.528274\n",
      "[885]\ttrain-mlogloss:0.371226\ttest-mlogloss:0.528287\n",
      "[886]\ttrain-mlogloss:0.371109\ttest-mlogloss:0.528345\n",
      "[887]\ttrain-mlogloss:0.371013\ttest-mlogloss:0.528354\n",
      "[888]\ttrain-mlogloss:0.370814\ttest-mlogloss:0.528306\n",
      "[889]\ttrain-mlogloss:0.370666\ttest-mlogloss:0.528238\n",
      "[890]\ttrain-mlogloss:0.370488\ttest-mlogloss:0.528215\n",
      "[891]\ttrain-mlogloss:0.370369\ttest-mlogloss:0.528195\n",
      "[892]\ttrain-mlogloss:0.370247\ttest-mlogloss:0.528172\n",
      "[893]\ttrain-mlogloss:0.370077\ttest-mlogloss:0.528135\n",
      "[894]\ttrain-mlogloss:0.369944\ttest-mlogloss:0.528167\n",
      "[895]\ttrain-mlogloss:0.369798\ttest-mlogloss:0.528213\n",
      "[896]\ttrain-mlogloss:0.369633\ttest-mlogloss:0.528233\n",
      "[897]\ttrain-mlogloss:0.369504\ttest-mlogloss:0.528269\n",
      "[898]\ttrain-mlogloss:0.369354\ttest-mlogloss:0.528323\n",
      "[899]\ttrain-mlogloss:0.369224\ttest-mlogloss:0.52837\n",
      "[900]\ttrain-mlogloss:0.369106\ttest-mlogloss:0.52831\n",
      "[901]\ttrain-mlogloss:0.368973\ttest-mlogloss:0.528278\n",
      "[902]\ttrain-mlogloss:0.368788\ttest-mlogloss:0.528263\n",
      "[903]\ttrain-mlogloss:0.368648\ttest-mlogloss:0.528283\n",
      "[904]\ttrain-mlogloss:0.368518\ttest-mlogloss:0.528339\n",
      "[905]\ttrain-mlogloss:0.368396\ttest-mlogloss:0.528388\n",
      "[906]\ttrain-mlogloss:0.368263\ttest-mlogloss:0.528362\n",
      "[907]\ttrain-mlogloss:0.368135\ttest-mlogloss:0.528417\n",
      "[908]\ttrain-mlogloss:0.368016\ttest-mlogloss:0.52841\n",
      "[909]\ttrain-mlogloss:0.367838\ttest-mlogloss:0.528401\n",
      "[910]\ttrain-mlogloss:0.367657\ttest-mlogloss:0.528441\n",
      "[911]\ttrain-mlogloss:0.367506\ttest-mlogloss:0.528556\n",
      "[912]\ttrain-mlogloss:0.367338\ttest-mlogloss:0.528514\n",
      "[913]\ttrain-mlogloss:0.367166\ttest-mlogloss:0.528529\n",
      "[914]\ttrain-mlogloss:0.367018\ttest-mlogloss:0.52857\n",
      "[915]\ttrain-mlogloss:0.366853\ttest-mlogloss:0.528547\n",
      "[916]\ttrain-mlogloss:0.366745\ttest-mlogloss:0.528552\n",
      "[917]\ttrain-mlogloss:0.366606\ttest-mlogloss:0.528659\n",
      "[918]\ttrain-mlogloss:0.366473\ttest-mlogloss:0.528603\n",
      "[919]\ttrain-mlogloss:0.366324\ttest-mlogloss:0.528566\n",
      "[920]\ttrain-mlogloss:0.366155\ttest-mlogloss:0.528593\n",
      "[921]\ttrain-mlogloss:0.366046\ttest-mlogloss:0.528624\n",
      "[922]\ttrain-mlogloss:0.36591\ttest-mlogloss:0.52871\n",
      "[923]\ttrain-mlogloss:0.36577\ttest-mlogloss:0.528655\n",
      "[924]\ttrain-mlogloss:0.365619\ttest-mlogloss:0.528676\n",
      "[925]\ttrain-mlogloss:0.365512\ttest-mlogloss:0.528689\n",
      "[926]\ttrain-mlogloss:0.365342\ttest-mlogloss:0.528716\n",
      "[927]\ttrain-mlogloss:0.365233\ttest-mlogloss:0.528724\n",
      "[928]\ttrain-mlogloss:0.365117\ttest-mlogloss:0.528713\n",
      "[929]\ttrain-mlogloss:0.364969\ttest-mlogloss:0.528701\n",
      "[930]\ttrain-mlogloss:0.364833\ttest-mlogloss:0.528642\n",
      "[931]\ttrain-mlogloss:0.364722\ttest-mlogloss:0.528638\n",
      "Stopping. Best iteration:\n",
      "[867]\ttrain-mlogloss:0.373719\ttest-mlogloss:0.527948\n",
      "\n",
      "[0.5286377697939153]\n"
     ]
    }
   ],
   "source": [
    "cv_scores = []\n",
    "\n",
    "#mini_ranking = 15\n",
    "\n",
    "for dev_index, val_index in KF:\n",
    "        #split the orginal train set into dev_set and val_set\n",
    "        dev_set, val_set = train_df.iloc[dev_index,:] , train_df.iloc[val_index,:] \n",
    "        \n",
    "#====================================================================        \n",
    "        \"\"\"feature engineerings for the categorical features\"\"\"\n",
    "        #fill substitute the small size values by their mean\n",
    "        for f in ['display_address','manager_id','building_id','street_name']:\n",
    "            dev_set,val_set  = singleValueConvert(dev_set,val_set,f,1)\n",
    "        \n",
    "        \n",
    "        #K-FOLD evaluation for the manager skill\n",
    "        \n",
    "        skf=StratifiedKFold(dev_set['interest_level'],5,shuffle=True,random_state = 42)\n",
    "        #dev set adding manager skill\n",
    "        for feature in ['manager_id']:\n",
    "            for train,test in skf:\n",
    "                performance_eval(dev_set.iloc[train,:],dev_set.iloc[test,:],feature=feature,k=5,g=10,\n",
    "                               update_df = dev_set,random = 0.01)\n",
    "                \n",
    "                \n",
    "                hcc_scoring(dev_set.iloc[train,:],dev_set.iloc[test,:],'building_id','high',randomize=0.01,\\\n",
    "                             unrank_threshold =1,update_df =dev_set)\n",
    "                hcc_scoring(dev_set.iloc[train,:],dev_set.iloc[test,:],'building_id','medium',randomize=0.01,\\\n",
    "                             unrank_threshold =1,update_df =dev_set)\n",
    "                \n",
    "            \n",
    "            performance_eval(dev_set,val_set,feature=feature,k=5,g=10,random = 0.01)\n",
    "            \n",
    "            hcc_scoring(dev_set,val_set,'building_id','high',randomize=0.01,\\\n",
    "                             unrank_threshold =1)\n",
    "            hcc_scoring(dev_set,val_set,'building_id','medium',randomize=0.01,\\\n",
    "                            unrank_threshold =1)\n",
    "            \n",
    "        for f in categorical:\n",
    "\n",
    "            if dev_set[f].dtype=='object':\n",
    "                #print(f)\n",
    "                lbl = preprocessing.LabelEncoder()\n",
    "                lbl.fit(list(dev_set[f])+list(val_set[f]))\n",
    "                dev_set[f] = lbl.transform(list(dev_set[f].values))\n",
    "                val_set[f] = lbl.transform(list(val_set[f].values))\n",
    "        \n",
    "#===================================================================\n",
    "                \n",
    "        #filter the features\n",
    "        dev_X, val_X = dev_set[features_to_use].as_matrix(), val_set[features_to_use].as_matrix()\n",
    "        dev_y, val_y = train_y[dev_index], train_y[val_index]\n",
    "        \n",
    "        \"\"\"\n",
    "        runXGB(train_X, train_y, test_X, test_y=None, feature_names=None, \\\n",
    "        seed_val=0, early_stop = 20,num_rounds=10000, eta = 0.1, max_depth = 6)\n",
    "        \"\"\"        \n",
    "        \n",
    "        preds, model = runXGB(dev_X, dev_y, val_X, val_y,\\\n",
    "        feature_names=features_to_use,early_stop=64,\n",
    "        num_rounds = 20000, eta = 0.1,max_depth = 4)\n",
    "    \n",
    "        #using rf for feature choosing\n",
    "        #model = ensemble.RandomForestClassifier(500,random_state = 42,class_weight='balanced')\n",
    "        #model.fit(dev_X,dev_y)\n",
    "        #pred_prob = model.predict_proba(val_X)\n",
    "        #pred = model.predict(val_X)\n",
    "            \n",
    "        cv_scores.append(log_loss(val_y, preds))\n",
    "        break\n",
    "print cv_scores\n",
    "#print accuracy_score(val_y,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'ManHigh', u'ManLow', u'ManMedium'], dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:123: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n"
     ]
    }
   ],
   "source": [
    "#features_to_use.append('manager_skill')\n",
    "#categorical = [\"display_address\", \"manager_id\", \"building_id\", \"street_address\",\"street_name\"]\n",
    "#features_to_use.extend(categorical)\n",
    "#features_to_use.extend(['diff_price','diff_price_per_bed','diff_price_per_bath','diff_price_per_room'])\n",
    "\n",
    "#====================================================================        \n",
    "\"\"\"feature engineerings for the categorical features\"\"\"\n",
    "\n",
    "train_set, test_set =manager_skill_eval(train_df,test_df,\\\n",
    "unrank_threshold = mini_ranking)\n",
    "\n",
    "\n",
    "#fill substitute the small size values by their mean\n",
    "for f in categorical:\n",
    "    train_set,test_set  = singleValueConvert(train_set,test_set,f,mini_ranking)\n",
    "\n",
    "    if train_set[f].dtype=='object':\n",
    "        #print(f)\n",
    "        lbl = preprocessing.LabelEncoder()\n",
    "        lbl.fit(list(train_df[f])+list(test_df[f]))\n",
    "        train_set[f] = lbl.transform(list(train_set[f].values))\n",
    "        test_set[f] = lbl.transform(list(test_set[f].values))\n",
    "\n",
    "addAvgDiff(train_set,test_set,nn=15)\n",
    "\n",
    "#===================================================================\n",
    "\n",
    "train_X = train_set[features_to_use]\n",
    "test_X = test_set[features_to_use]\n",
    "\n",
    "train_X_m = train_X.as_matrix()\n",
    "test_X_m = test_X.as_matrix()\n",
    "\n",
    "preds, model = runXGB(train_X_m, train_y, test_X_m, num_rounds=243)\n",
    "out_df = pd.DataFrame(preds)\n",
    "out_df.columns = [\"high\", \"medium\", \"low\"]\n",
    "out_df[\"listing_id\"] = test_df.listing_id.values\n",
    "out_df.to_csv(\"xgb_beta1point251-nndiff.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([            u'bathrooms',              u'bedrooms',\n",
       "                 u'building_id',               u'created',\n",
       "                 u'description',       u'display_address',\n",
       "                    u'features',        u'interest_level',\n",
       "                    u'latitude',            u'listing_id',\n",
       "                   u'longitude',            u'manager_id',\n",
       "                      u'photos',                 u'price',\n",
       "              u'street_address',            u'num_photos',\n",
       "                u'num_features', u'num_description_words',\n",
       "                u'created_year',         u'created_month',\n",
       "                 u'created_day',          u'created_hour'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_set.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bathrooms': 0.010285346346753424,\n",
       " 'bedrooms': 0.030466314219872576,\n",
       " 'building_id': 0.06857462383082553,\n",
       " 'created_day': 0.046309475396502646,\n",
       " 'created_hour': 0.04346278975193168,\n",
       " 'created_month': 0.006015317879896977,\n",
       " 'display_address': 0.0806899823776603,\n",
       " 'latitude': 0.09202589128371967,\n",
       " 'listing_id': 0.09887149247661652,\n",
       " 'longitude': 0.07911413853870138,\n",
       " 'manager_id': 0.09904093805069812,\n",
       " 'num_description_words': 0.0829605530703538,\n",
       " 'num_features': 0.04493696624644164,\n",
       " 'num_photos': 0.04109055171478921,\n",
       " 'price': 0.0970753693913515,\n",
       " 'street_address': 0.07908024942388504}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ananlysis by the feature importance by weight\n",
    "weight = model.get_score()\n",
    "total = sum(weight.values())\n",
    "for key in weight:\n",
    "    weight[key] = weight[key]*1.0/total\n",
    "weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('manager_id_perf', 0.04709964072683501),\n",
       " ('with_simplex', 0.02968914818799002),\n",
       " ('with_no_fee', 0.029298257528266352),\n",
       " ('with_lowrise', 0.023912050387596282),\n",
       " ('price', 0.02202479254158485),\n",
       " ('with_furnished', 0.020903440252948775),\n",
       " ('bathrooms', 0.01792761554434289),\n",
       " ('price_per_room', 0.016951330036144553),\n",
       " ('price_per_bed', 0.015700963312388724),\n",
       " ('with_short_term_allowed', 0.014658801839222645),\n",
       " ('with_hardwood', 0.014121620081753267),\n",
       " ('with_reduced_fee', 0.014043652268649731),\n",
       " ('num_photos', 0.01368353075338423),\n",
       " ('with_hardwood_floors', 0.013151664252601943),\n",
       " ('created_hour', 0.013146475100738351),\n",
       " ('bedrooms', 0.012474472186877427),\n",
       " ('building_id', 0.012098465299834478),\n",
       " ('longitude', 0.011937894265548778),\n",
       " ('with_central_a/c', 0.011430144867299144),\n",
       " ('with_laundry_in_unit', 0.011405272794044864),\n",
       " ('latitude', 0.011275234019783935),\n",
       " ('with_high_ceiling', 0.01102655510295255),\n",
       " ('with_laundry_in_building', 0.010939565474292718),\n",
       " ('with_parking_space', 0.010815250225099677),\n",
       " ('display_address', 0.010343669844243878),\n",
       " ('bath_per_bed', 0.010196844425461338),\n",
       " ('with_actual_apt._photos', 0.01004340677134139),\n",
       " ('with_laundry_room', 0.009878567121416899),\n",
       " ('with_private_outdoor_space', 0.009795988471189477),\n",
       " ('num_features', 0.009772363758659575),\n",
       " ('with_dogs_allowed', 0.009765959894507502),\n",
       " ('with_doorman', 0.00965806234368644),\n",
       " ('with_high_ceilings', 0.009558022108415512),\n",
       " ('with_concierge', 0.009440978067530128),\n",
       " ('with_common_outdoor_space', 0.009420500330046752),\n",
       " ('with_wheelchair_access', 0.009374997509946534),\n",
       " ('with_balcony', 0.009300424987199551),\n",
       " ('with_parking', 0.009171666178090785),\n",
       " ('with_exclusive', 0.009150745702576062),\n",
       " ('with_washer_in_unit', 0.009008358068085438),\n",
       " ('with_stainless_steel_appliances', 0.008888077625019997),\n",
       " ('listing_id', 0.008859756959355298),\n",
       " ('street_name', 0.00841534385920738),\n",
       " ('with_prewar', 0.008330176482127423),\n",
       " ('street_address', 0.00831447509302104),\n",
       " ('with_multi_level', 0.008271117596062732),\n",
       " ('with_terrace', 0.008231783565820749),\n",
       " ('with_walk_in_closet(s)', 0.008191891556064776),\n",
       " ('with_storage', 0.008152782959673165),\n",
       " ('with_swimming_pool', 0.008142138020563976),\n",
       " ('with_common_parking/garage', 0.008136561089596752),\n",
       " ('with_dishwasher', 0.008078633074809664),\n",
       " ('with_on_site_garage', 0.008049744842587076),\n",
       " ('with_gym/fitness', 0.008010083176663225),\n",
       " ('with_common_roof_deck', 0.007921642153585158),\n",
       " ('with_fitness_center', 0.007871276376917181),\n",
       " ('num_description_words', 0.007842170807662538),\n",
       " ('with_new_construction', 0.00780834921372375),\n",
       " ('with_dryer_in_unit', 0.007755181002039843),\n",
       " ('with_cats_allowed', 0.007743082142229502),\n",
       " ('with_outdoor_space', 0.0075686660929582305),\n",
       " ('with_roof_deck', 0.0074946323981039615),\n",
       " ('with_duplex', 0.0074125503070081224),\n",
       " ('with_granite_kitchen', 0.007310611377027562),\n",
       " ('with_high_speed_internet', 0.007285992963517826),\n",
       " ('with_on_site_laundry', 0.007267719093261721),\n",
       " ('with_dining_room', 0.007192336957665909),\n",
       " ('created_day', 0.007141364201357911),\n",
       " ('created_month', 0.007069967096314955),\n",
       " ('with_live_in_super', 0.0070428008096815285),\n",
       " ('with_gym', 0.007029566545378267),\n",
       " ('with_garden/patio', 0.006984719711131274),\n",
       " ('with_elevator', 0.006894132319112441),\n",
       " ('with_bike_room', 0.006820619551658442),\n",
       " ('with_pre_war', 0.006787012303442025),\n",
       " ('with_garage', 0.006786329429707431),\n",
       " ('with_loft', 0.006745962010649164),\n",
       " ('with_light', 0.006609353017837239),\n",
       " ('with_marble_bath', 0.006548675467578464),\n",
       " ('with_green_building', 0.006547892623043173),\n",
       " ('with_renovated', 0.006512814633977764),\n",
       " ('with_outdoor_areas', 0.0065000836544087635),\n",
       " ('with_fireplace', 0.006467775237850313),\n",
       " ('with_no_pets', 0.006432178674360982),\n",
       " ('with_pets_on_approval', 0.00638297688939354),\n",
       " ('with_full_time_doorman', 0.0063286746279976845),\n",
       " ('with_publicoutdoor', 0.006230556642926704),\n",
       " ('with_eat_in_kitchen', 0.0060591292201528655),\n",
       " ('with_valet', 0.005915260159738131),\n",
       " ('with_luxury_building', 0.005635668029797313),\n",
       " ('with_view', 0.00560519767934529),\n",
       " ('with_laundry', 0.005465453649977284),\n",
       " ('with_newly_renovated', 0.005414390728255174),\n",
       " ('with_exposed_brick', 0.005290922092464839),\n",
       " ('with_washer/dryer', 0.005204395185575229),\n",
       " ('with_subway', 0.004920341416562042),\n",
       " ('with_private_balcony', 0.0048663172049885186),\n",
       " ('with_residents_lounge', 0.004803703860622004),\n",
       " ('with_roofdeck', 0.004695794462386124),\n",
       " ('with_live_in_superintendent', 0.004656380031164788),\n",
       " ('with_patio', 0.004646534026284283),\n",
       " ('with_post_war', 0.004224165484839927),\n",
       " ('with_pool', 0.0041329390759440015),\n",
       " ('with_highrise', 0.004078648762001449),\n",
       " ('with_childrens_playroom', 0.0023781340632396102)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ananlysis by the feature importance by gain\n",
    "gain = model.get_score(importance_type='gain')\n",
    "gain_list = []\n",
    "total = sum(gain.values())\n",
    "for key in gain:\n",
    "    gain[key] = gain[key]*1.0/total\n",
    "    gain_list.append((key,gain[key]))\n",
    "sorted(gain_list,key = lambda x:x[1],reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bathrooms': 0.15003324661763429,\n",
       " 'bedrooms': 0.11847222747849985,\n",
       " 'building_id': 0.05966144646752775,\n",
       " 'created_day': 0.027908091350767217,\n",
       " 'created_hour': 0.04913703475375256,\n",
       " 'created_month': 0.015463921187964249,\n",
       " 'display_address': 0.051917534421511584,\n",
       " 'latitude': 0.062329192852910546,\n",
       " 'listing_id': 0.05823796559748455,\n",
       " 'longitude': 0.05796867229011468,\n",
       " 'manager_id': 0.0658834209429622,\n",
       " 'num_description_words': 0.04385875263322271,\n",
       " 'num_features': 0.05493240649113651,\n",
       " 'num_photos': 0.053803480057786596,\n",
       " 'price': 0.07955324745771991,\n",
       " 'street_address': 0.050839359399004566}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ananlysis by the feature importance by coverage\n",
    "cover = model.get_score(importance_type='cover')\n",
    "total = sum(cover.values())\n",
    "for key in cover:\n",
    "    cover[key] = cover[key]*1.0/total\n",
    "cover"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
