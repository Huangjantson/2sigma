{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os,sys\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.metrics import log_loss\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import xgboost as xgb\n",
    "from mochi import CVstatistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def runXGB(train_X, train_y, test_X, test_y=None, feature_names=None,      \n",
    "           seed_val=0, early_stop = 20,num_rounds=10000, eta = 0.1,     \n",
    "           max_depth = 6,cv_dict = None,verbose_eval=True,\n",
    "          cb=0.7,sb=0.7):\n",
    "    param = {}\n",
    "    param['objective'] = 'multi:softprob'\n",
    "    param['eta'] = eta\n",
    "    param['max_depth'] = max_depth\n",
    "    param['silent'] = 1\n",
    "    param['num_class'] = 3\n",
    "    param['eval_metric'] = \"mlogloss\"\n",
    "    param['min_child_weight'] = 1\n",
    "    param['subsample'] = cb\n",
    "    param['colsample_bytree'] = sb\n",
    "    param['seed'] = seed_val\n",
    "    param['nthread'] = 4\n",
    "    num_rounds = num_rounds\n",
    "\n",
    "    plst = list(param.items())\n",
    "    xgtrain = xgb.DMatrix(train_X, label=train_y,feature_names=feature_names)\n",
    "\n",
    "    if test_y is not None:\n",
    "        xgtest = xgb.DMatrix(test_X, label=test_y,feature_names=feature_names)\n",
    "        watchlist = [ (xgtrain,'train'), (xgtest, 'test') ]\n",
    "        model = xgb.train(plst, xgtrain, num_rounds, watchlist,        \n",
    "            early_stopping_rounds=early_stop,evals_result = cv_dict,verbose_eval = verbose_eval)\n",
    "    else:\n",
    "        xgtest = xgb.DMatrix(test_X,feature_names=feature_names)\n",
    "        model = xgb.train(plst, xgtrain, num_rounds)\n",
    "\n",
    "    pred_test_y = model.predict(xgtest)\n",
    "    return pred_test_y, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#the data path list\n",
    "data_path = '/home/raku/kaggleData/2sigma/'\n",
    "#model_list = ['et2000','knn4','knn8','knn16','knn32','lr4','xgb142','rf2000']\n",
    "#new_model_list=['et1000mf140','loglrC03','lrl1C1','lrl2C3','rf1000mf70','nn','lgbm']\n",
    "model_list=['knn4','knn8','knn16','knn32','xgb142','et1000mf140','loglrC03','lrl1C1','lrl2C3','rf1000mf70','ann','lgbm'\n",
    "           ,'lr4','loglr','et2000','rf2000','lgb145']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "meta_train_temp_list=[]\n",
    "meta_test_temp_list=[]\n",
    "for model in model_list:\n",
    "    dp = os.listdir(data_path+model+'/')\n",
    "    fold_out_file = []\n",
    "    for filename in dp:\n",
    "        if re.match('\\S+-5fold-out-\\d.pickle',filename)!=None:\n",
    "            fold_out_file.append(filename)\n",
    "        elif re.match('\\S+-bulk-out.json',filename)!=None:\n",
    "            bulk_out_file = filename\n",
    "            \n",
    "    fold_out_file=sorted(fold_out_file)\n",
    "    #print fold_out_file\n",
    "    #print bulk_out_file\n",
    "    #load the pickles and combine into meta_train\n",
    "    #load the json bulk out into meta_test\n",
    "    pickle_data = []\n",
    "    json_data = pd.read_json(data_path+model+'/'+bulk_out_file)\n",
    "    temp_meta_test=pd.DataFrame(json_data['high'])\n",
    "    temp_meta_test.columns=[model+'_high']\n",
    "    temp_meta_test[model+'_medium']=json_data['medium']\n",
    "    temp_meta_test[model+'_low']=json_data['low']\n",
    "    if 'listing_id' in json_data.columns:\n",
    "        test_listing=json_data['listing_id']\n",
    "    \n",
    "    for pickle_file in fold_out_file:\n",
    "        pickl_file = data_path+model+'/'+pickle_file\n",
    "        fileObject = open(pickl_file,'r') \n",
    "        pickle_data.append(pd.DataFrame(pickle.load(fileObject)))   \n",
    "        fileObject.close()\n",
    "    temp_meta_train=pd.concat(pickle_data)\n",
    "    temp_meta_train.columns=[model+'_high',model+'_medium',model+'_low']\n",
    "    temp_meta_test.columns=[model+'_high',model+'_medium',model+'_low']\n",
    "    meta_train_temp_list.append(temp_meta_train)\n",
    "    meta_test_temp_list.append(temp_meta_test)\n",
    "    \n",
    "meta_train=pd.concat(meta_train_temp_list,axis=1)\n",
    "meta_test=pd.concat(meta_test_temp_list,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_data = []\n",
    "for pickle_file in ['y-5fold-out-0.pickle','y-5fold-out-1.pickle','y-5fold-out-2.pickle','y-5fold-out-3.pickle','y-5fold-out-4.pickle']:\n",
    "    pickl_file = data_path+'/'+pickle_file\n",
    "    fileObject = open(pickl_file,'r') \n",
    "    y_data.append(pd.DataFrame(pickle.load(fileObject)))   \n",
    "    fileObject.close()\n",
    "meta_train_y=np.array(pd.concat(y_data)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        7142618\n",
       "1        7210040\n",
       "10       6832604\n",
       "100      6830595\n",
       "1000     6843709\n",
       "10000    7232076\n",
       "10001    6832266\n",
       "10002    6931714\n",
       "10003    7316357\n",
       "10004    6839137\n",
       "10005    6879707\n",
       "10006    6866122\n",
       "10007    7154141\n",
       "10008    7194059\n",
       "10009    6849409\n",
       "1001     6880861\n",
       "10010    6850837\n",
       "10011    6915788\n",
       "10012    6922125\n",
       "10013    6816508\n",
       "10014    6915345\n",
       "10015    7107945\n",
       "10016    6841711\n",
       "10017    6832076\n",
       "10018    6868588\n",
       "10019    6855095\n",
       "1002     6927246\n",
       "10020    7185889\n",
       "10021    6851285\n",
       "10022    6911912\n",
       "          ...   \n",
       "9972     6812689\n",
       "9973     6945375\n",
       "9974     6838369\n",
       "9975     6876359\n",
       "9976     6871970\n",
       "9977     6911618\n",
       "9978     6879762\n",
       "9979     6834041\n",
       "998      6835259\n",
       "9980     6937182\n",
       "9981     6936112\n",
       "9982     6859557\n",
       "9983     7127420\n",
       "9984     6889376\n",
       "9985     6874327\n",
       "9986     6870171\n",
       "9987     6942777\n",
       "9988     6858105\n",
       "9989     6933079\n",
       "999      6878793\n",
       "9990     6850266\n",
       "9991     6924419\n",
       "9992     6868652\n",
       "9993     6883509\n",
       "9994     6832931\n",
       "9995     6915633\n",
       "9996     7100256\n",
       "9997     6945532\n",
       "9998     6881447\n",
       "9999     6892483\n",
       "Name: listing_id, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_listing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ann_high            0.933713\n",
       "et1000mf140_high    0.964709\n",
       "et2000_high         0.944836\n",
       "knn16_high          0.927173\n",
       "knn32_high          0.927173\n",
       "knn4_high           0.846329\n",
       "knn8_high           0.890040\n",
       "lgb145_high         0.996205\n",
       "lgbm_high           0.996205\n",
       "loglrC03_high       0.998727\n",
       "loglr_high          0.998727\n",
       "lr4_high            0.998918\n",
       "lrl1C1_high         0.996338\n",
       "lrl2C3_high         0.998918\n",
       "rf1000mf70_high     0.973423\n",
       "rf2000_high         0.973423\n",
       "xgb142_high         0.978066\n",
       "dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "highs=meta_train.filter(like='_high')\n",
    "coeff_matrix={}\n",
    "for features in highs.columns:\n",
    "    temp_matrix={}\n",
    "    for another_feat in highs.columns:\n",
    "        temp_matrix[another_feat]=pearsonr(highs[features],highs[another_feat])[0]\n",
    "    coeff_matrix[features]=temp_matrix\n",
    "high_coeff_df = pd.DataFrame(coeff_matrix).replace(1.0,-1)\n",
    "high_coeff_df.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ann_high</th>\n",
       "      <th>et1000mf140_high</th>\n",
       "      <th>et2000_high</th>\n",
       "      <th>knn16_high</th>\n",
       "      <th>knn32_high</th>\n",
       "      <th>knn4_high</th>\n",
       "      <th>knn8_high</th>\n",
       "      <th>lgb145_high</th>\n",
       "      <th>lgbm_high</th>\n",
       "      <th>loglrC03_high</th>\n",
       "      <th>loglr_high</th>\n",
       "      <th>lr4_high</th>\n",
       "      <th>lrl1C1_high</th>\n",
       "      <th>lrl2C3_high</th>\n",
       "      <th>rf1000mf70_high</th>\n",
       "      <th>rf2000_high</th>\n",
       "      <th>xgb142_high</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ann_high</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.783801</td>\n",
       "      <td>0.744929</td>\n",
       "      <td>0.723163</td>\n",
       "      <td>0.768169</td>\n",
       "      <td>0.562121</td>\n",
       "      <td>0.652650</td>\n",
       "      <td>0.801473</td>\n",
       "      <td>0.797217</td>\n",
       "      <td>0.933713</td>\n",
       "      <td>0.933024</td>\n",
       "      <td>0.930097</td>\n",
       "      <td>0.930800</td>\n",
       "      <td>0.923855</td>\n",
       "      <td>0.805705</td>\n",
       "      <td>0.810090</td>\n",
       "      <td>0.797396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>et1000mf140_high</th>\n",
       "      <td>0.783801</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.944836</td>\n",
       "      <td>0.671221</td>\n",
       "      <td>0.700832</td>\n",
       "      <td>0.556976</td>\n",
       "      <td>0.622569</td>\n",
       "      <td>0.828525</td>\n",
       "      <td>0.827946</td>\n",
       "      <td>0.748515</td>\n",
       "      <td>0.746597</td>\n",
       "      <td>0.762986</td>\n",
       "      <td>0.765281</td>\n",
       "      <td>0.762447</td>\n",
       "      <td>0.954150</td>\n",
       "      <td>0.964709</td>\n",
       "      <td>0.842248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>et2000_high</th>\n",
       "      <td>0.744929</td>\n",
       "      <td>0.944836</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.624637</td>\n",
       "      <td>0.655123</td>\n",
       "      <td>0.513843</td>\n",
       "      <td>0.576704</td>\n",
       "      <td>0.762313</td>\n",
       "      <td>0.762964</td>\n",
       "      <td>0.718713</td>\n",
       "      <td>0.716768</td>\n",
       "      <td>0.718594</td>\n",
       "      <td>0.721633</td>\n",
       "      <td>0.716591</td>\n",
       "      <td>0.882602</td>\n",
       "      <td>0.937338</td>\n",
       "      <td>0.780305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn16_high</th>\n",
       "      <td>0.723163</td>\n",
       "      <td>0.671221</td>\n",
       "      <td>0.624637</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.927173</td>\n",
       "      <td>0.753741</td>\n",
       "      <td>0.890040</td>\n",
       "      <td>0.638831</td>\n",
       "      <td>0.634207</td>\n",
       "      <td>0.713997</td>\n",
       "      <td>0.710163</td>\n",
       "      <td>0.704560</td>\n",
       "      <td>0.704489</td>\n",
       "      <td>0.699562</td>\n",
       "      <td>0.703869</td>\n",
       "      <td>0.713161</td>\n",
       "      <td>0.631619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn32_high</th>\n",
       "      <td>0.768169</td>\n",
       "      <td>0.700832</td>\n",
       "      <td>0.655123</td>\n",
       "      <td>0.927173</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.698403</td>\n",
       "      <td>0.822283</td>\n",
       "      <td>0.669413</td>\n",
       "      <td>0.663734</td>\n",
       "      <td>0.761322</td>\n",
       "      <td>0.757097</td>\n",
       "      <td>0.748948</td>\n",
       "      <td>0.749143</td>\n",
       "      <td>0.743270</td>\n",
       "      <td>0.736366</td>\n",
       "      <td>0.746184</td>\n",
       "      <td>0.660193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn4_high</th>\n",
       "      <td>0.562121</td>\n",
       "      <td>0.556976</td>\n",
       "      <td>0.513843</td>\n",
       "      <td>0.753741</td>\n",
       "      <td>0.698403</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.846329</td>\n",
       "      <td>0.515898</td>\n",
       "      <td>0.513133</td>\n",
       "      <td>0.552377</td>\n",
       "      <td>0.549731</td>\n",
       "      <td>0.550288</td>\n",
       "      <td>0.550636</td>\n",
       "      <td>0.547383</td>\n",
       "      <td>0.580875</td>\n",
       "      <td>0.587759</td>\n",
       "      <td>0.516235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn8_high</th>\n",
       "      <td>0.652650</td>\n",
       "      <td>0.622569</td>\n",
       "      <td>0.576704</td>\n",
       "      <td>0.890040</td>\n",
       "      <td>0.822283</td>\n",
       "      <td>0.846329</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.587051</td>\n",
       "      <td>0.583570</td>\n",
       "      <td>0.643003</td>\n",
       "      <td>0.639919</td>\n",
       "      <td>0.636677</td>\n",
       "      <td>0.637135</td>\n",
       "      <td>0.632795</td>\n",
       "      <td>0.652416</td>\n",
       "      <td>0.659898</td>\n",
       "      <td>0.582678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgb145_high</th>\n",
       "      <td>0.801473</td>\n",
       "      <td>0.828525</td>\n",
       "      <td>0.762313</td>\n",
       "      <td>0.638831</td>\n",
       "      <td>0.669413</td>\n",
       "      <td>0.515898</td>\n",
       "      <td>0.587051</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.996205</td>\n",
       "      <td>0.746534</td>\n",
       "      <td>0.745697</td>\n",
       "      <td>0.807313</td>\n",
       "      <td>0.806100</td>\n",
       "      <td>0.811686</td>\n",
       "      <td>0.879079</td>\n",
       "      <td>0.845978</td>\n",
       "      <td>0.976357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgbm_high</th>\n",
       "      <td>0.797217</td>\n",
       "      <td>0.827946</td>\n",
       "      <td>0.762964</td>\n",
       "      <td>0.634207</td>\n",
       "      <td>0.663734</td>\n",
       "      <td>0.513133</td>\n",
       "      <td>0.583570</td>\n",
       "      <td>0.996205</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.741386</td>\n",
       "      <td>0.740706</td>\n",
       "      <td>0.802943</td>\n",
       "      <td>0.801731</td>\n",
       "      <td>0.807414</td>\n",
       "      <td>0.877088</td>\n",
       "      <td>0.844601</td>\n",
       "      <td>0.978066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loglrC03_high</th>\n",
       "      <td>0.933713</td>\n",
       "      <td>0.748515</td>\n",
       "      <td>0.718713</td>\n",
       "      <td>0.713997</td>\n",
       "      <td>0.761322</td>\n",
       "      <td>0.552377</td>\n",
       "      <td>0.643003</td>\n",
       "      <td>0.746534</td>\n",
       "      <td>0.741386</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.998727</td>\n",
       "      <td>0.934713</td>\n",
       "      <td>0.935900</td>\n",
       "      <td>0.923461</td>\n",
       "      <td>0.768700</td>\n",
       "      <td>0.782385</td>\n",
       "      <td>0.740111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loglr_high</th>\n",
       "      <td>0.933024</td>\n",
       "      <td>0.746597</td>\n",
       "      <td>0.716768</td>\n",
       "      <td>0.710163</td>\n",
       "      <td>0.757097</td>\n",
       "      <td>0.549731</td>\n",
       "      <td>0.639919</td>\n",
       "      <td>0.745697</td>\n",
       "      <td>0.740706</td>\n",
       "      <td>0.998727</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.936976</td>\n",
       "      <td>0.937560</td>\n",
       "      <td>0.926062</td>\n",
       "      <td>0.766092</td>\n",
       "      <td>0.779536</td>\n",
       "      <td>0.739330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lr4_high</th>\n",
       "      <td>0.930097</td>\n",
       "      <td>0.762986</td>\n",
       "      <td>0.718594</td>\n",
       "      <td>0.704560</td>\n",
       "      <td>0.748948</td>\n",
       "      <td>0.550288</td>\n",
       "      <td>0.636677</td>\n",
       "      <td>0.807313</td>\n",
       "      <td>0.802943</td>\n",
       "      <td>0.934713</td>\n",
       "      <td>0.936976</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.996338</td>\n",
       "      <td>0.998918</td>\n",
       "      <td>0.795682</td>\n",
       "      <td>0.792761</td>\n",
       "      <td>0.800894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lrl1C1_high</th>\n",
       "      <td>0.930800</td>\n",
       "      <td>0.765281</td>\n",
       "      <td>0.721633</td>\n",
       "      <td>0.704489</td>\n",
       "      <td>0.749143</td>\n",
       "      <td>0.550636</td>\n",
       "      <td>0.637135</td>\n",
       "      <td>0.806100</td>\n",
       "      <td>0.801731</td>\n",
       "      <td>0.935900</td>\n",
       "      <td>0.937560</td>\n",
       "      <td>0.996338</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.995841</td>\n",
       "      <td>0.797661</td>\n",
       "      <td>0.795717</td>\n",
       "      <td>0.799493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lrl2C3_high</th>\n",
       "      <td>0.923855</td>\n",
       "      <td>0.762447</td>\n",
       "      <td>0.716591</td>\n",
       "      <td>0.699562</td>\n",
       "      <td>0.743270</td>\n",
       "      <td>0.547383</td>\n",
       "      <td>0.632795</td>\n",
       "      <td>0.811686</td>\n",
       "      <td>0.807414</td>\n",
       "      <td>0.923461</td>\n",
       "      <td>0.926062</td>\n",
       "      <td>0.998918</td>\n",
       "      <td>0.995841</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.796629</td>\n",
       "      <td>0.791915</td>\n",
       "      <td>0.805238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf1000mf70_high</th>\n",
       "      <td>0.805705</td>\n",
       "      <td>0.954150</td>\n",
       "      <td>0.882602</td>\n",
       "      <td>0.703869</td>\n",
       "      <td>0.736366</td>\n",
       "      <td>0.580875</td>\n",
       "      <td>0.652416</td>\n",
       "      <td>0.879079</td>\n",
       "      <td>0.877088</td>\n",
       "      <td>0.768700</td>\n",
       "      <td>0.766092</td>\n",
       "      <td>0.795682</td>\n",
       "      <td>0.797661</td>\n",
       "      <td>0.796629</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.973423</td>\n",
       "      <td>0.886038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf2000_high</th>\n",
       "      <td>0.810090</td>\n",
       "      <td>0.964709</td>\n",
       "      <td>0.937338</td>\n",
       "      <td>0.713161</td>\n",
       "      <td>0.746184</td>\n",
       "      <td>0.587759</td>\n",
       "      <td>0.659898</td>\n",
       "      <td>0.845978</td>\n",
       "      <td>0.844601</td>\n",
       "      <td>0.782385</td>\n",
       "      <td>0.779536</td>\n",
       "      <td>0.792761</td>\n",
       "      <td>0.795717</td>\n",
       "      <td>0.791915</td>\n",
       "      <td>0.973423</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.857448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb142_high</th>\n",
       "      <td>0.797396</td>\n",
       "      <td>0.842248</td>\n",
       "      <td>0.780305</td>\n",
       "      <td>0.631619</td>\n",
       "      <td>0.660193</td>\n",
       "      <td>0.516235</td>\n",
       "      <td>0.582678</td>\n",
       "      <td>0.976357</td>\n",
       "      <td>0.978066</td>\n",
       "      <td>0.740111</td>\n",
       "      <td>0.739330</td>\n",
       "      <td>0.800894</td>\n",
       "      <td>0.799493</td>\n",
       "      <td>0.805238</td>\n",
       "      <td>0.886038</td>\n",
       "      <td>0.857448</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ann_high  et1000mf140_high  et2000_high  knn16_high  \\\n",
       "ann_high         -1.000000          0.783801     0.744929    0.723163   \n",
       "et1000mf140_high  0.783801         -1.000000     0.944836    0.671221   \n",
       "et2000_high       0.744929          0.944836    -1.000000    0.624637   \n",
       "knn16_high        0.723163          0.671221     0.624637   -1.000000   \n",
       "knn32_high        0.768169          0.700832     0.655123    0.927173   \n",
       "knn4_high         0.562121          0.556976     0.513843    0.753741   \n",
       "knn8_high         0.652650          0.622569     0.576704    0.890040   \n",
       "lgb145_high       0.801473          0.828525     0.762313    0.638831   \n",
       "lgbm_high         0.797217          0.827946     0.762964    0.634207   \n",
       "loglrC03_high     0.933713          0.748515     0.718713    0.713997   \n",
       "loglr_high        0.933024          0.746597     0.716768    0.710163   \n",
       "lr4_high          0.930097          0.762986     0.718594    0.704560   \n",
       "lrl1C1_high       0.930800          0.765281     0.721633    0.704489   \n",
       "lrl2C3_high       0.923855          0.762447     0.716591    0.699562   \n",
       "rf1000mf70_high   0.805705          0.954150     0.882602    0.703869   \n",
       "rf2000_high       0.810090          0.964709     0.937338    0.713161   \n",
       "xgb142_high       0.797396          0.842248     0.780305    0.631619   \n",
       "\n",
       "                  knn32_high  knn4_high  knn8_high  lgb145_high  lgbm_high  \\\n",
       "ann_high            0.768169   0.562121   0.652650     0.801473   0.797217   \n",
       "et1000mf140_high    0.700832   0.556976   0.622569     0.828525   0.827946   \n",
       "et2000_high         0.655123   0.513843   0.576704     0.762313   0.762964   \n",
       "knn16_high          0.927173   0.753741   0.890040     0.638831   0.634207   \n",
       "knn32_high         -1.000000   0.698403   0.822283     0.669413   0.663734   \n",
       "knn4_high           0.698403  -1.000000   0.846329     0.515898   0.513133   \n",
       "knn8_high           0.822283   0.846329  -1.000000     0.587051   0.583570   \n",
       "lgb145_high         0.669413   0.515898   0.587051    -1.000000   0.996205   \n",
       "lgbm_high           0.663734   0.513133   0.583570     0.996205  -1.000000   \n",
       "loglrC03_high       0.761322   0.552377   0.643003     0.746534   0.741386   \n",
       "loglr_high          0.757097   0.549731   0.639919     0.745697   0.740706   \n",
       "lr4_high            0.748948   0.550288   0.636677     0.807313   0.802943   \n",
       "lrl1C1_high         0.749143   0.550636   0.637135     0.806100   0.801731   \n",
       "lrl2C3_high         0.743270   0.547383   0.632795     0.811686   0.807414   \n",
       "rf1000mf70_high     0.736366   0.580875   0.652416     0.879079   0.877088   \n",
       "rf2000_high         0.746184   0.587759   0.659898     0.845978   0.844601   \n",
       "xgb142_high         0.660193   0.516235   0.582678     0.976357   0.978066   \n",
       "\n",
       "                  loglrC03_high  loglr_high  lr4_high  lrl1C1_high  \\\n",
       "ann_high               0.933713    0.933024  0.930097     0.930800   \n",
       "et1000mf140_high       0.748515    0.746597  0.762986     0.765281   \n",
       "et2000_high            0.718713    0.716768  0.718594     0.721633   \n",
       "knn16_high             0.713997    0.710163  0.704560     0.704489   \n",
       "knn32_high             0.761322    0.757097  0.748948     0.749143   \n",
       "knn4_high              0.552377    0.549731  0.550288     0.550636   \n",
       "knn8_high              0.643003    0.639919  0.636677     0.637135   \n",
       "lgb145_high            0.746534    0.745697  0.807313     0.806100   \n",
       "lgbm_high              0.741386    0.740706  0.802943     0.801731   \n",
       "loglrC03_high         -1.000000    0.998727  0.934713     0.935900   \n",
       "loglr_high             0.998727   -1.000000  0.936976     0.937560   \n",
       "lr4_high               0.934713    0.936976 -1.000000     0.996338   \n",
       "lrl1C1_high            0.935900    0.937560  0.996338    -1.000000   \n",
       "lrl2C3_high            0.923461    0.926062  0.998918     0.995841   \n",
       "rf1000mf70_high        0.768700    0.766092  0.795682     0.797661   \n",
       "rf2000_high            0.782385    0.779536  0.792761     0.795717   \n",
       "xgb142_high            0.740111    0.739330  0.800894     0.799493   \n",
       "\n",
       "                  lrl2C3_high  rf1000mf70_high  rf2000_high  xgb142_high  \n",
       "ann_high             0.923855         0.805705     0.810090     0.797396  \n",
       "et1000mf140_high     0.762447         0.954150     0.964709     0.842248  \n",
       "et2000_high          0.716591         0.882602     0.937338     0.780305  \n",
       "knn16_high           0.699562         0.703869     0.713161     0.631619  \n",
       "knn32_high           0.743270         0.736366     0.746184     0.660193  \n",
       "knn4_high            0.547383         0.580875     0.587759     0.516235  \n",
       "knn8_high            0.632795         0.652416     0.659898     0.582678  \n",
       "lgb145_high          0.811686         0.879079     0.845978     0.976357  \n",
       "lgbm_high            0.807414         0.877088     0.844601     0.978066  \n",
       "loglrC03_high        0.923461         0.768700     0.782385     0.740111  \n",
       "loglr_high           0.926062         0.766092     0.779536     0.739330  \n",
       "lr4_high             0.998918         0.795682     0.792761     0.800894  \n",
       "lrl1C1_high          0.995841         0.797661     0.795717     0.799493  \n",
       "lrl2C3_high         -1.000000         0.796629     0.791915     0.805238  \n",
       "rf1000mf70_high      0.796629        -1.000000     0.973423     0.886038  \n",
       "rf2000_high          0.791915         0.973423    -1.000000     0.857448  \n",
       "xgb142_high          0.805238         0.886038     0.857448    -1.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "high_coeff_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "et1000mf140_medium    0.953708\n",
       "et2000_medium         0.936937\n",
       "knn16_medium          0.934426\n",
       "knn32_medium          0.934426\n",
       "knn4_medium           0.849902\n",
       "knn8_medium           0.894516\n",
       "lgbm_medium           0.977196\n",
       "loglrC03_medium       0.999508\n",
       "loglr_medium          0.999508\n",
       "lr4_medium            0.999656\n",
       "lrl1C1_medium         0.990533\n",
       "lrl2C3_medium         0.999656\n",
       "nn_medium             0.946818\n",
       "rf1000mf70_medium     0.971443\n",
       "rf2000_medium         0.971443\n",
       "xgb142_medium         0.977196\n",
       "dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mediums=meta_train.filter(like='_medium')\n",
    "coeff_matrix={}\n",
    "for features in mediums.columns:\n",
    "    temp_matrix={}\n",
    "    for another_feat in mediums.columns:\n",
    "        temp_matrix[another_feat]=pearsonr(mediums[features],mediums[another_feat])[0]\n",
    "    coeff_matrix[features]=temp_matrix\n",
    "medium_coeff_df = pd.DataFrame(coeff_matrix).replace(1.0,-1)\n",
    "medium_coeff_df.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ann_low            0.962808\n",
       "et1000mf140_low    0.970532\n",
       "et2000_low         0.958324\n",
       "knn16_low          0.965450\n",
       "knn32_low          0.965450\n",
       "knn4_low           0.905308\n",
       "knn8_low           0.940407\n",
       "lgb145_low         0.998522\n",
       "lgbm_low           0.998522\n",
       "loglrC03_low       0.999602\n",
       "loglr_low          0.999602\n",
       "lr4_low            0.999688\n",
       "lrl1C1_low         0.994035\n",
       "lrl2C3_low         0.999688\n",
       "rf1000mf70_low     0.980853\n",
       "rf2000_low         0.980853\n",
       "xgb142_low         0.990092\n",
       "dtype: float64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lows=meta_train.filter(like='_low')\n",
    "coeff_matrix={}\n",
    "for features in lows.columns:\n",
    "    temp_matrix={}\n",
    "    for another_feat in lows.columns:\n",
    "        temp_matrix[another_feat]=pearsonr(lows[features],lows[another_feat])[0]\n",
    "    coeff_matrix[features]=temp_matrix\n",
    "low_coeff_df = pd.DataFrame(coeff_matrix).replace(1.0,-1)\n",
    "low_coeff_df.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knn4 knn4_high\n",
      "knn4 knn4_medium\n",
      "knn4 knn4_low\n",
      "knn8 knn8_high\n",
      "knn8 knn8_medium\n",
      "knn8 knn8_low\n",
      "knn16 knn16_high\n",
      "knn16 knn16_medium\n",
      "knn16 knn16_low\n",
      "knn32 knn32_high\n",
      "knn32 knn32_medium\n",
      "knn32 knn32_low\n",
      "xgb142 xgb142_high\n",
      "xgb142 xgb142_medium\n",
      "xgb142 xgb142_low\n",
      "et1000mf140 et1000mf140_high\n",
      "et1000mf140 et1000mf140_medium\n",
      "et1000mf140 et1000mf140_low\n",
      "loglrC03 loglrC03_high\n",
      "loglrC03 loglrC03_medium\n",
      "loglrC03 loglrC03_low\n",
      "lrl2C3 lrl2C3_high\n",
      "lrl2C3 lrl2C3_medium\n",
      "lrl2C3 lrl2C3_low\n",
      "rf1000mf70 rf1000mf70_high\n",
      "rf1000mf70 rf1000mf70_medium\n",
      "rf1000mf70 rf1000mf70_low\n",
      "ann ann_high\n",
      "ann ann_medium\n",
      "ann ann_low\n",
      "lgb145 lgb145_high\n",
      "lgb145 lgb145_medium\n",
      "lgb145 lgb145_low\n"
     ]
    }
   ],
   "source": [
    "#model_list=['knn4','knn8','knn16','knn32','xgb142','et1000mf140','loglrC03','lrl1C1','lrl2C3','rf1000mf70','nn','lgbm'\n",
    "#           ,'lr4','loglr','et2000','rf2000','lgb145']\n",
    "meta_features = []\n",
    "chosen_model=['knn4','knn8','knn16','knn32','xgb142','et1000mf140','loglrC03','lrl2C3','rf1000mf70','ann','lgb145']\n",
    "for feature in meta_train:\n",
    "    for model in chosen_model:\n",
    "        if model in feature:\n",
    "            print model,feature\n",
    "            meta_features.append(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "KF=StratifiedKFold(5,shuffle=True,random_state = 66666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:1.0206\ttest-mlogloss:1.02084\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.492589\ttest-mlogloss:0.501716\n",
      "Stopping. Best iteration:\n",
      "[108]\ttrain-mlogloss:0.491308\ttest-mlogloss:0.501646\n",
      "\n",
      "loss for the turn 1 is 0.501890412987\n",
      "[0]\ttrain-mlogloss:1.02084\ttest-mlogloss:1.02054\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.493364\ttest-mlogloss:0.497193\n",
      "Stopping. Best iteration:\n",
      "[173]\ttrain-mlogloss:0.483334\ttest-mlogloss:0.496629\n",
      "\n",
      "loss for the turn 2 is 0.496654262807\n",
      "[0]\ttrain-mlogloss:1.02044\ttest-mlogloss:1.02015\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.492491\ttest-mlogloss:0.500773\n",
      "Stopping. Best iteration:\n",
      "[145]\ttrain-mlogloss:0.486439\ttest-mlogloss:0.500472\n",
      "\n",
      "loss for the turn 3 is 0.500770567584\n",
      "[0]\ttrain-mlogloss:1.02049\ttest-mlogloss:1.02137\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.490006\ttest-mlogloss:0.511406\n",
      "Stopping. Best iteration:\n",
      "[152]\ttrain-mlogloss:0.483092\ttest-mlogloss:0.511223\n",
      "\n",
      "loss for the turn 4 is 0.511426389326\n",
      "[0]\ttrain-mlogloss:1.02353\ttest-mlogloss:1.024\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.489363\ttest-mlogloss:0.513633\n",
      "Stopping. Best iteration:\n",
      "[91]\ttrain-mlogloss:0.490785\ttest-mlogloss:0.51353\n",
      "\n",
      "loss for the turn 5 is 0.513831672577\n",
      "The mean of the cv_scores is:\n",
      "0.504914661056\n"
     ]
    }
   ],
   "source": [
    "cv_scores = []\n",
    "cv_result = []\n",
    "\n",
    "i=0        \n",
    "for dev_index, val_index in KF.split(meta_train,meta_train_y): \n",
    "    result_dict = {}\n",
    "\n",
    "    dev_X, val_X = meta_train[meta_features].iloc[dev_index,:].as_matrix(), meta_train[meta_features].iloc[val_index,:].as_matrix()\n",
    "    dev_y, val_y = meta_train_y[dev_index], meta_train_y[val_index]\n",
    "    \n",
    "    preds,model = runXGB(dev_X, dev_y, val_X, val_y,feature_names=meta_features,\\\n",
    "           early_stop = 20,num_rounds=780,eta = 0.1,max_depth=3,cv_dict = result_dict,verbose_eval=100)\n",
    "\n",
    "    loss = log_loss(val_y, preds)\n",
    "    \n",
    "    cv_scores.append(loss)\n",
    "    cv_result.append(result_dict)\n",
    "    i+=1\n",
    "    print 'loss for the turn '+str(i)+' is '+str(loss)\n",
    "    \n",
    "print 'The mean of the cv_scores is:'\n",
    "print np.mean(cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "173    0.496629\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "cvResult = CVstatistics(cv_result,'mlogloss')\n",
    "\n",
    "meanTestError = cvResult.result.filter(like='test').mean(axis=1)\n",
    "\n",
    "print meanTestError[meanTestError==np.min(meanTestError)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:1.0208\ttest-mlogloss:1.02103\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.490906\ttest-mlogloss:0.502085\n",
      "Stopping. Best iteration:\n",
      "[91]\ttrain-mlogloss:0.492516\ttest-mlogloss:0.502012\n",
      "\n",
      "loss for the turn 1 is 0.502116002189\n",
      "[0]\ttrain-mlogloss:1.02117\ttest-mlogloss:1.02099\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.492325\ttest-mlogloss:0.49735\n",
      "Stopping. Best iteration:\n",
      "[143]\ttrain-mlogloss:0.485708\ttest-mlogloss:0.496824\n",
      "\n",
      "loss for the turn 2 is 0.496885017369\n",
      "[0]\ttrain-mlogloss:1.02092\ttest-mlogloss:1.02049\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.491575\ttest-mlogloss:0.500391\n",
      "Stopping. Best iteration:\n",
      "[123]\ttrain-mlogloss:0.487911\ttest-mlogloss:0.499792\n",
      "\n",
      "loss for the turn 3 is 0.499882339324\n",
      "[0]\ttrain-mlogloss:1.02061\ttest-mlogloss:1.02159\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.489243\ttest-mlogloss:0.511035\n",
      "Stopping. Best iteration:\n",
      "[135]\ttrain-mlogloss:0.483816\ttest-mlogloss:0.510784\n",
      "\n",
      "loss for the turn 4 is 0.511039829291\n",
      "[0]\ttrain-mlogloss:1.01984\ttest-mlogloss:1.02027\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.48876\ttest-mlogloss:0.515068\n",
      "Stopping. Best iteration:\n",
      "[107]\ttrain-mlogloss:0.487473\ttest-mlogloss:0.514978\n",
      "\n",
      "loss for the turn 5 is 0.515116328959\n",
      "The mean of the cv_scores is:\n",
      "0.505007903426\n"
     ]
    }
   ],
   "source": [
    "cv_scores = []\n",
    "cv_result = []\n",
    "\n",
    "i=0        \n",
    "for dev_index, val_index in KF.split(meta_train,meta_train_y): \n",
    "    result_dict = {}\n",
    "\n",
    "    dev_X, val_X = meta_train.iloc[dev_index,:].as_matrix(), meta_train.iloc[val_index,:].as_matrix()\n",
    "    dev_y, val_y = meta_train_y[dev_index], meta_train_y[val_index]\n",
    "    \n",
    "    preds,model = runXGB(dev_X, dev_y, val_X, val_y,feature_names=list(meta_train.columns),\\\n",
    "           early_stop = 20,num_rounds=780,eta = 0.1,max_depth=3,cv_dict = result_dict,verbose_eval=100)\n",
    "\n",
    "    loss = log_loss(val_y, preds)\n",
    "    \n",
    "    cv_scores.append(loss)\n",
    "    cv_result.append(result_dict)\n",
    "    i+=1\n",
    "    print 'loss for the turn '+str(i)+' is '+str(loss)\n",
    "    \n",
    "print 'The mean of the cv_scores is:'\n",
    "print np.mean(cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161    0.496841\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "cvResult = CVstatistics(cv_result,'mlogloss')\n",
    "\n",
    "meanTestError = cvResult.result.filter(like='test').mean(axis=1)\n",
    "\n",
    "print meanTestError[meanTestError==np.min(meanTestError)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:1.01991\ttest-mlogloss:1.02029\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.480154\ttest-mlogloss:0.501342\n",
      "Stopping. Best iteration:\n",
      "[101]\ttrain-mlogloss:0.479939\ttest-mlogloss:0.501299\n",
      "\n",
      "loss for the turn 1 is 0.501445885033\n",
      "[0]\ttrain-mlogloss:1.02031\ttest-mlogloss:1.02011\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.481668\ttest-mlogloss:0.497235\n",
      "Stopping. Best iteration:\n",
      "[111]\ttrain-mlogloss:0.478996\ttest-mlogloss:0.497042\n",
      "\n",
      "loss for the turn 2 is 0.497388884625\n",
      "[0]\ttrain-mlogloss:1.01987\ttest-mlogloss:1.01976\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.480093\ttest-mlogloss:0.500882\n",
      "Stopping. Best iteration:\n",
      "[87]\ttrain-mlogloss:0.4835\ttest-mlogloss:0.500801\n",
      "\n",
      "loss for the turn 3 is 0.500871448794\n",
      "[0]\ttrain-mlogloss:1.01978\ttest-mlogloss:1.0208\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.477969\ttest-mlogloss:0.511105\n",
      "Stopping. Best iteration:\n",
      "[114]\ttrain-mlogloss:0.474581\ttest-mlogloss:0.510978\n",
      "\n",
      "loss for the turn 4 is 0.511215337485\n",
      "[0]\ttrain-mlogloss:1.02246\ttest-mlogloss:1.02308\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.476958\ttest-mlogloss:0.513948\n",
      "Stopping. Best iteration:\n",
      "[87]\ttrain-mlogloss:0.48043\ttest-mlogloss:0.513643\n",
      "\n",
      "loss for the turn 5 is 0.514181969391\n",
      "The mean of the cv_scores is:\n",
      "0.505020705066\n"
     ]
    }
   ],
   "source": [
    "cv_scores = []\n",
    "cv_result = []\n",
    "\n",
    "i=0        \n",
    "for dev_index, val_index in KF.split(meta_train,meta_train_y): \n",
    "    result_dict = {}\n",
    "\n",
    "    dev_X, val_X = meta_train[meta_features].iloc[dev_index,:].as_matrix(), meta_train[meta_features].iloc[val_index,:].as_matrix()\n",
    "    dev_y, val_y = meta_train_y[dev_index], meta_train_y[val_index]\n",
    "    \n",
    "    preds,model = runXGB(dev_X, dev_y, val_X, val_y,feature_names=meta_features,\\\n",
    "           early_stop = 20,num_rounds=780,eta = 0.1,max_depth=4,cv_dict = result_dict,verbose_eval=100)\n",
    "\n",
    "    loss = log_loss(val_y, preds)\n",
    "    \n",
    "    cv_scores.append(loss)\n",
    "    cv_result.append(result_dict)\n",
    "    i+=1\n",
    "    print 'loss for the turn '+str(i)+' is '+str(loss)\n",
    "    \n",
    "print 'The mean of the cv_scores is:'\n",
    "print np.mean(cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111    0.503164\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "cvResult = CVstatistics(cv_result,'mlogloss')\n",
    "\n",
    "meanTestError = cvResult.result.filter(like='test').mean(axis=1)\n",
    "\n",
    "print meanTestError[meanTestError==np.min(meanTestError)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:1.01891\ttest-mlogloss:1.01945\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.454882\ttest-mlogloss:0.502141\n",
      "Stopping. Best iteration:\n",
      "[90]\ttrain-mlogloss:0.459796\ttest-mlogloss:0.501752\n",
      "\n",
      "loss for the turn 1 is 0.502394617457\n",
      "[0]\ttrain-mlogloss:1.01911\ttest-mlogloss:1.01961\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.455619\ttest-mlogloss:0.496718\n",
      "Stopping. Best iteration:\n",
      "[91]\ttrain-mlogloss:0.459829\ttest-mlogloss:0.496498\n",
      "\n",
      "loss for the turn 2 is 0.497082633031\n",
      "[0]\ttrain-mlogloss:1.01878\ttest-mlogloss:1.01899\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.454768\ttest-mlogloss:0.500512\n",
      "Stopping. Best iteration:\n",
      "[87]\ttrain-mlogloss:0.460937\ttest-mlogloss:0.500291\n",
      "\n",
      "loss for the turn 3 is 0.500555672911\n",
      "[0]\ttrain-mlogloss:1.01876\ttest-mlogloss:1.02012\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "Stopping. Best iteration:\n",
      "[77]\ttrain-mlogloss:0.46416\ttest-mlogloss:0.511037\n",
      "\n",
      "loss for the turn 4 is 0.511384408979\n",
      "[0]\ttrain-mlogloss:1.01876\ttest-mlogloss:1.01988\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "Stopping. Best iteration:\n",
      "[70]\ttrain-mlogloss:0.466011\ttest-mlogloss:0.514083\n",
      "\n",
      "loss for the turn 5 is 0.514718026849\n",
      "The mean of the cv_scores is:\n",
      "0.505227071845\n"
     ]
    }
   ],
   "source": [
    "cv_scores = []\n",
    "cv_result = []\n",
    "\n",
    "i=0        \n",
    "for dev_index, val_index in KF.split(meta_train,meta_train_y): \n",
    "    result_dict = {}\n",
    "\n",
    "    dev_X, val_X = meta_train[meta_features].iloc[dev_index,:].as_matrix(), meta_train[meta_features].iloc[val_index,:].as_matrix()\n",
    "    dev_y, val_y = meta_train_y[dev_index], meta_train_y[val_index]\n",
    "    \n",
    "    preds,model = runXGB(dev_X, dev_y, val_X, val_y,feature_names=meta_features,\\\n",
    "           early_stop = 20,num_rounds=780,eta = 0.1,max_depth=5,cv_dict = result_dict,verbose_eval=100)\n",
    "\n",
    "    loss = log_loss(val_y, preds)\n",
    "    \n",
    "    cv_scores.append(loss)\n",
    "    cv_result.append(result_dict)\n",
    "    i+=1\n",
    "    print 'loss for the turn '+str(i)+' is '+str(loss)\n",
    "    \n",
    "print 'The mean of the cv_scores is:'\n",
    "print np.mean(cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110    0.497042\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "cvResult = CVstatistics(cv_result,'mlogloss')\n",
    "\n",
    "meanTestError = cvResult.result.filter(like='test').mean(axis=1)\n",
    "\n",
    "print meanTestError[meanTestError==np.min(meanTestError)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:1.02077\ttest-mlogloss:1.02094\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.493798\ttest-mlogloss:0.502639\n",
      "Stopping. Best iteration:\n",
      "[97]\ttrain-mlogloss:0.494143\ttest-mlogloss:0.50241\n",
      "\n",
      "loss for the turn 1 is 0.502522365694\n",
      "[0]\ttrain-mlogloss:1.02091\ttest-mlogloss:1.02046\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.49512\ttest-mlogloss:0.497614\n",
      "Stopping. Best iteration:\n",
      "[174]\ttrain-mlogloss:0.485616\ttest-mlogloss:0.496537\n",
      "\n",
      "loss for the turn 2 is 0.497178686073\n",
      "[0]\ttrain-mlogloss:1.02067\ttest-mlogloss:1.02044\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.494544\ttest-mlogloss:0.501161\n",
      "Stopping. Best iteration:\n",
      "[105]\ttrain-mlogloss:0.493817\ttest-mlogloss:0.500793\n",
      "\n",
      "loss for the turn 3 is 0.501295000398\n",
      "[0]\ttrain-mlogloss:1.02042\ttest-mlogloss:1.02121\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.491379\ttest-mlogloss:0.512148\n",
      "Stopping. Best iteration:\n",
      "[135]\ttrain-mlogloss:0.48686\ttest-mlogloss:0.511597\n",
      "\n",
      "loss for the turn 4 is 0.512008521948\n",
      "[0]\ttrain-mlogloss:1.02349\ttest-mlogloss:1.024\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.490808\ttest-mlogloss:0.514668\n",
      "Stopping. Best iteration:\n",
      "[113]\ttrain-mlogloss:0.489131\ttest-mlogloss:0.514437\n",
      "\n",
      "loss for the turn 5 is 0.514764767875\n",
      "The mean of the cv_scores is:\n",
      "0.505553868398\n",
      "[0]\ttrain-mlogloss:1.02062\ttest-mlogloss:1.02071\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.492723\ttest-mlogloss:0.502067\n",
      "Stopping. Best iteration:\n",
      "[99]\ttrain-mlogloss:0.492834\ttest-mlogloss:0.502065\n",
      "\n",
      "loss for the turn 1 is 0.50217545663\n",
      "[0]\ttrain-mlogloss:1.0209\ttest-mlogloss:1.0206\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.494294\ttest-mlogloss:0.498061\n",
      "Stopping. Best iteration:\n",
      "[129]\ttrain-mlogloss:0.490373\ttest-mlogloss:0.497591\n",
      "\n",
      "loss for the turn 2 is 0.497843598756\n",
      "[0]\ttrain-mlogloss:1.02058\ttest-mlogloss:1.02028\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.493293\ttest-mlogloss:0.501043\n",
      "Stopping. Best iteration:\n",
      "[115]\ttrain-mlogloss:0.49121\ttest-mlogloss:0.500615\n",
      "\n",
      "loss for the turn 3 is 0.50091470239\n",
      "[0]\ttrain-mlogloss:1.02045\ttest-mlogloss:1.0213\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.490584\ttest-mlogloss:0.51197\n",
      "Stopping. Best iteration:\n",
      "[146]\ttrain-mlogloss:0.484\ttest-mlogloss:0.510941\n",
      "\n",
      "loss for the turn 4 is 0.511177202185\n",
      "[0]\ttrain-mlogloss:1.02348\ttest-mlogloss:1.02392\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.490262\ttest-mlogloss:0.514021\n",
      "Stopping. Best iteration:\n",
      "[80]\ttrain-mlogloss:0.493251\ttest-mlogloss:0.514018\n",
      "\n",
      "loss for the turn 5 is 0.514021105012\n",
      "The mean of the cv_scores is:\n",
      "0.505226412995\n",
      "[0]\ttrain-mlogloss:1.02051\ttest-mlogloss:1.02077\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.492855\ttest-mlogloss:0.502265\n",
      "Stopping. Best iteration:\n",
      "[135]\ttrain-mlogloss:0.487904\ttest-mlogloss:0.501932\n",
      "\n",
      "loss for the turn 1 is 0.502020653995\n",
      "[0]\ttrain-mlogloss:1.02085\ttest-mlogloss:1.02056\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.493791\ttest-mlogloss:0.497811\n",
      "[200]\ttrain-mlogloss:0.481029\ttest-mlogloss:0.497092\n",
      "Stopping. Best iteration:\n",
      "[181]\ttrain-mlogloss:0.483275\ttest-mlogloss:0.496825\n",
      "\n",
      "loss for the turn 2 is 0.497148976908\n",
      "[0]\ttrain-mlogloss:1.02056\ttest-mlogloss:1.02031\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.492863\ttest-mlogloss:0.500621\n",
      "Stopping. Best iteration:\n",
      "[146]\ttrain-mlogloss:0.486637\ttest-mlogloss:0.500083\n",
      "\n",
      "loss for the turn 3 is 0.500360688673\n",
      "[0]\ttrain-mlogloss:1.02051\ttest-mlogloss:1.02139\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.490368\ttest-mlogloss:0.511667\n",
      "Stopping. Best iteration:\n",
      "[142]\ttrain-mlogloss:0.484924\ttest-mlogloss:0.511213\n",
      "\n",
      "loss for the turn 4 is 0.511350472888\n",
      "[0]\ttrain-mlogloss:1.02359\ttest-mlogloss:1.02412\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.489552\ttest-mlogloss:0.514086\n",
      "Stopping. Best iteration:\n",
      "[122]\ttrain-mlogloss:0.486449\ttest-mlogloss:0.513925\n",
      "\n",
      "loss for the turn 5 is 0.514057565277\n",
      "The mean of the cv_scores is:\n",
      "0.504987671548\n",
      "[0]\ttrain-mlogloss:1.02072\ttest-mlogloss:1.02086\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.491799\ttest-mlogloss:0.501801\n",
      "Stopping. Best iteration:\n",
      "[116]\ttrain-mlogloss:0.489414\ttest-mlogloss:0.501383\n",
      "\n",
      "loss for the turn 1 is 0.501451993171\n",
      "[0]\ttrain-mlogloss:1.02086\ttest-mlogloss:1.02046\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.49331\ttest-mlogloss:0.497056\n",
      "Stopping. Best iteration:\n",
      "[90]\ttrain-mlogloss:0.494695\ttest-mlogloss:0.496983\n",
      "\n",
      "loss for the turn 2 is 0.497253999406\n",
      "[0]\ttrain-mlogloss:1.02065\ttest-mlogloss:1.02042\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.492383\ttest-mlogloss:0.499908\n",
      "Stopping. Best iteration:\n",
      "[111]\ttrain-mlogloss:0.490898\ttest-mlogloss:0.499541\n",
      "\n",
      "loss for the turn 3 is 0.499926602902\n",
      "[0]\ttrain-mlogloss:1.02032\ttest-mlogloss:1.02114\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.489623\ttest-mlogloss:0.511277\n",
      "Stopping. Best iteration:\n",
      "[127]\ttrain-mlogloss:0.486013\ttest-mlogloss:0.511003\n",
      "\n",
      "loss for the turn 4 is 0.511075851043\n",
      "[0]\ttrain-mlogloss:1.02042\ttest-mlogloss:1.02093\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.488911\ttest-mlogloss:0.513953\n",
      "Stopping. Best iteration:\n",
      "[112]\ttrain-mlogloss:0.48701\ttest-mlogloss:0.513575\n",
      "\n",
      "loss for the turn 5 is 0.514113626729\n",
      "The mean of the cv_scores is:\n",
      "0.50476441465\n",
      "[0]\ttrain-mlogloss:1.02054\ttest-mlogloss:1.02067\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.4909\ttest-mlogloss:0.501244\n",
      "Stopping. Best iteration:\n",
      "[105]\ttrain-mlogloss:0.490205\ttest-mlogloss:0.501204\n",
      "\n",
      "loss for the turn 1 is 0.501427274054\n",
      "[0]\ttrain-mlogloss:1.0208\ttest-mlogloss:1.02057\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.492752\ttest-mlogloss:0.496841\n",
      "Stopping. Best iteration:\n",
      "[98]\ttrain-mlogloss:0.493016\ttest-mlogloss:0.496714\n",
      "\n",
      "loss for the turn 2 is 0.496882735501\n",
      "[0]\ttrain-mlogloss:1.0205\ttest-mlogloss:1.02022\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.491559\ttest-mlogloss:0.500037\n",
      "Stopping. Best iteration:\n",
      "[140]\ttrain-mlogloss:0.485717\ttest-mlogloss:0.499704\n",
      "\n",
      "loss for the turn 3 is 0.500077053822\n",
      "[0]\ttrain-mlogloss:1.02054\ttest-mlogloss:1.02143\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.489209\ttest-mlogloss:0.511768\n",
      "Stopping. Best iteration:\n",
      "[94]\ttrain-mlogloss:0.49006\ttest-mlogloss:0.511635\n",
      "\n",
      "loss for the turn 4 is 0.511844296219\n",
      "[0]\ttrain-mlogloss:1.02026\ttest-mlogloss:1.02083\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "Stopping. Best iteration:\n",
      "[74]\ttrain-mlogloss:0.492778\ttest-mlogloss:0.5135\n",
      "\n",
      "loss for the turn 5 is 0.513838198595\n",
      "The mean of the cv_scores is:\n",
      "0.504813911638\n",
      "[0]\ttrain-mlogloss:1.02043\ttest-mlogloss:1.02069\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.491213\ttest-mlogloss:0.501526\n",
      "Stopping. Best iteration:\n",
      "[105]\ttrain-mlogloss:0.490491\ttest-mlogloss:0.50146\n",
      "\n",
      "loss for the turn 1 is 0.501654714643\n",
      "[0]\ttrain-mlogloss:1.02078\ttest-mlogloss:1.02052\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.492211\ttest-mlogloss:0.496796\n",
      "Stopping. Best iteration:\n",
      "[140]\ttrain-mlogloss:0.486511\ttest-mlogloss:0.496368\n",
      "\n",
      "loss for the turn 2 is 0.496477431501\n",
      "[0]\ttrain-mlogloss:1.02049\ttest-mlogloss:1.02021\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.491295\ttest-mlogloss:0.500355\n",
      "Stopping. Best iteration:\n",
      "[121]\ttrain-mlogloss:0.488281\ttest-mlogloss:0.50006\n",
      "\n",
      "loss for the turn 3 is 0.500104942758\n",
      "[0]\ttrain-mlogloss:1.02045\ttest-mlogloss:1.02125\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.4891\ttest-mlogloss:0.510834\n",
      "Stopping. Best iteration:\n",
      "[102]\ttrain-mlogloss:0.488855\ttest-mlogloss:0.510831\n",
      "\n",
      "loss for the turn 4 is 0.51105852961\n",
      "[0]\ttrain-mlogloss:1.02019\ttest-mlogloss:1.02072\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.488186\ttest-mlogloss:0.513187\n",
      "Stopping. Best iteration:\n",
      "[90]\ttrain-mlogloss:0.48991\ttest-mlogloss:0.513005\n",
      "\n",
      "loss for the turn 5 is 0.513579638883\n",
      "The mean of the cv_scores is:\n",
      "0.504575051479\n",
      "[0]\ttrain-mlogloss:1.02017\ttest-mlogloss:1.0204\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.490795\ttest-mlogloss:0.501349\n",
      "Stopping. Best iteration:\n",
      "[85]\ttrain-mlogloss:0.49324\ttest-mlogloss:0.500973\n",
      "\n",
      "loss for the turn 1 is 0.501284508499\n",
      "[0]\ttrain-mlogloss:1.02018\ttest-mlogloss:1.01996\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.492274\ttest-mlogloss:0.497043\n",
      "Stopping. Best iteration:\n",
      "[112]\ttrain-mlogloss:0.490523\ttest-mlogloss:0.497011\n",
      "\n",
      "loss for the turn 2 is 0.497165588475\n",
      "[0]\ttrain-mlogloss:1.02008\ttest-mlogloss:1.01994\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.491427\ttest-mlogloss:0.499864\n",
      "Stopping. Best iteration:\n",
      "[94]\ttrain-mlogloss:0.492424\ttest-mlogloss:0.499627\n",
      "\n",
      "loss for the turn 3 is 0.499931095229\n",
      "[0]\ttrain-mlogloss:1.01961\ttest-mlogloss:1.02045\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.488951\ttest-mlogloss:0.511533\n",
      "Stopping. Best iteration:\n",
      "[104]\ttrain-mlogloss:0.488386\ttest-mlogloss:0.511254\n",
      "\n",
      "loss for the turn 4 is 0.511329741818\n",
      "[0]\ttrain-mlogloss:1.02038\ttest-mlogloss:1.02099\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.488318\ttest-mlogloss:0.514106\n",
      "Stopping. Best iteration:\n",
      "[103]\ttrain-mlogloss:0.4878\ttest-mlogloss:0.513984\n",
      "\n",
      "loss for the turn 5 is 0.514300008525\n",
      "The mean of the cv_scores is:\n",
      "0.504802188509\n",
      "[0]\ttrain-mlogloss:1.01994\ttest-mlogloss:1.02\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.489993\ttest-mlogloss:0.501373\n",
      "Stopping. Best iteration:\n",
      "[98]\ttrain-mlogloss:0.490332\ttest-mlogloss:0.501315\n",
      "\n",
      "loss for the turn 1 is 0.501372842705\n",
      "[0]\ttrain-mlogloss:1.02022\ttest-mlogloss:1.01998\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.491887\ttest-mlogloss:0.496841\n",
      "Stopping. Best iteration:\n",
      "[126]\ttrain-mlogloss:0.487954\ttest-mlogloss:0.496371\n",
      "\n",
      "loss for the turn 2 is 0.49662612077\n",
      "[0]\ttrain-mlogloss:1.01994\ttest-mlogloss:1.0197\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.490517\ttest-mlogloss:0.500432\n",
      "Stopping. Best iteration:\n",
      "[114]\ttrain-mlogloss:0.488432\ttest-mlogloss:0.500264\n",
      "\n",
      "loss for the turn 3 is 0.500364924532\n",
      "[0]\ttrain-mlogloss:1.01982\ttest-mlogloss:1.02063\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.48845\ttest-mlogloss:0.510824\n",
      "Stopping. Best iteration:\n",
      "[89]\ttrain-mlogloss:0.490203\ttest-mlogloss:0.51065\n",
      "\n",
      "loss for the turn 4 is 0.510899937063\n",
      "[0]\ttrain-mlogloss:1.02026\ttest-mlogloss:1.02083\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "Stopping. Best iteration:\n",
      "[74]\ttrain-mlogloss:0.492211\ttest-mlogloss:0.513405\n",
      "\n",
      "loss for the turn 5 is 0.51368201832\n",
      "The mean of the cv_scores is:\n",
      "0.504589168678\n",
      "[0]\ttrain-mlogloss:1.01985\ttest-mlogloss:1.02009\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.49047\ttest-mlogloss:0.501704\n",
      "Stopping. Best iteration:\n",
      "[106]\ttrain-mlogloss:0.489453\ttest-mlogloss:0.501564\n",
      "\n",
      "loss for the turn 1 is 0.501779809094\n",
      "[0]\ttrain-mlogloss:1.0202\ttest-mlogloss:1.02004\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.491645\ttest-mlogloss:0.497283\n",
      "[200]\ttrain-mlogloss:0.477138\ttest-mlogloss:0.496529\n",
      "Stopping. Best iteration:\n",
      "[186]\ttrain-mlogloss:0.479178\ttest-mlogloss:0.49641\n",
      "\n",
      "loss for the turn 2 is 0.496556590625\n",
      "[0]\ttrain-mlogloss:1.0199\ttest-mlogloss:1.01957\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.490722\ttest-mlogloss:0.500258\n",
      "Stopping. Best iteration:\n",
      "[105]\ttrain-mlogloss:0.489922\ttest-mlogloss:0.500117\n",
      "\n",
      "loss for the turn 3 is 0.5002759975\n",
      "[0]\ttrain-mlogloss:1.01986\ttest-mlogloss:1.02055\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.488571\ttest-mlogloss:0.510579\n",
      "Stopping. Best iteration:\n",
      "[107]\ttrain-mlogloss:0.487501\ttest-mlogloss:0.51044\n",
      "\n",
      "loss for the turn 4 is 0.51070167098\n",
      "[0]\ttrain-mlogloss:1.02018\ttest-mlogloss:1.0207\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "Stopping. Best iteration:\n",
      "[70]\ttrain-mlogloss:0.493064\ttest-mlogloss:0.513407\n",
      "\n",
      "loss for the turn 5 is 0.513801088632\n",
      "The mean of the cv_scores is:\n",
      "0.504623031366\n"
     ]
    }
   ],
   "source": [
    "ss_list  = [0.25,0.5,0.75]\n",
    "csb_list = [0.25,0.5,0.75]\n",
    "another_dict = {}\n",
    "\n",
    "for ss in ss_list:\n",
    "     for csb in csb_list:\n",
    "        cv_scores = []\n",
    "        cv_result = []\n",
    "\n",
    "        i=0        \n",
    "        for dev_index, val_index in KF.split(meta_train,meta_train_y): \n",
    "            result_dict = {}\n",
    "\n",
    "            dev_X, val_X = meta_train[meta_features].iloc[dev_index,:].as_matrix(), meta_train[meta_features].iloc[val_index,:].as_matrix()\n",
    "            dev_y, val_y = meta_train_y[dev_index], meta_train_y[val_index]\n",
    "    \n",
    "            preds,model = runXGB(dev_X, dev_y, val_X, val_y,feature_names=meta_features,\n",
    "               early_stop = 20,num_rounds=780,eta = 0.1,max_depth=3,cv_dict = result_dict,verbose_eval=100,\n",
    "                                cb=csb,sb=ss)\n",
    "\n",
    "            loss = log_loss(val_y, preds)\n",
    "    \n",
    "            cv_scores.append(loss)\n",
    "            cv_result.append(result_dict)\n",
    "            i+=1\n",
    "            print 'loss for the turn '+str(i)+' is '+str(loss)\n",
    "    \n",
    "        print 'The mean of the cv_scores is:'\n",
    "        print np.mean(cv_scores) \n",
    "        another_dict[(ss,csb)]=np.mean(cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mini = 10\n",
    "best_ss = 0\n",
    "best_csb =0\n",
    "for ss in ss_list:\n",
    "    for csb in csb_list:\n",
    "        if another_dict[(ss,csb)] < mini:\n",
    "            mini = another_dict[(ss,csb)]\n",
    "            best_ss = ss\n",
    "            best_csb = csb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5 0.75\n"
     ]
    }
   ],
   "source": [
    "print best_ss,best_csb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "feature_names must have the same length as data",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-101-6e23f5cf05f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     preds,model = runXGB(dev_X, dev_y, val_X, val_y,feature_names=meta_features,           early_stop = None,num_rounds=2000,eta = 0.01,max_depth=3,cv_dict = result_dict,verbose_eval=100,\n\u001b[0;32m---> 12\u001b[0;31m                         sb=0.5,cb=0.75)\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-f4b90b60956f>\u001b[0m in \u001b[0;36mrunXGB\u001b[0;34m(train_X, train_y, test_X, test_y, feature_names, seed_val, early_stop, num_rounds, eta, max_depth, cv_dict, verbose_eval, cb, sb)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mplst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mxgtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtest_y\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda2/lib/python2.7/site-packages/xgboost-0.6-py2.7.egg/xgboost/core.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, label, missing, weight, silent, feature_names, feature_types)\u001b[0m\n\u001b[1;32m    278\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_types\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_types\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda2/lib/python2.7/site-packages/xgboost-0.6-py2.7.egg/xgboost/core.pyc\u001b[0m in \u001b[0;36mfeature_names\u001b[0;34m(self, feature_names)\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_col\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m                 \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'feature_names must have the same length as data'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 587\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    588\u001b[0m             \u001b[0;31m# prohibit to use symbols may affect to parse. e.g. []<\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m             if not all(isinstance(f, STRING_TYPES) and\n",
      "\u001b[0;31mValueError\u001b[0m: feature_names must have the same length as data"
     ]
    }
   ],
   "source": [
    "cv_scores = []\n",
    "cv_result = []\n",
    "\n",
    "i=0        \n",
    "for dev_index, val_index in KF.split(meta_train,meta_train_y): \n",
    "    result_dict = {}\n",
    "\n",
    "    dev_X, val_X = meta_train.iloc[dev_index,:].as_matrix(), meta_train.iloc[val_index,:].as_matrix()\n",
    "    dev_y, val_y = meta_train_y[dev_index], meta_train_y[val_index]\n",
    "    \n",
    "    preds,model = runXGB(dev_X, dev_y, val_X, val_y,feature_names=meta_features,\\\n",
    "           early_stop = None,num_rounds=2000,eta = 0.01,max_depth=3,cv_dict = result_dict,verbose_eval=100,\n",
    "                        sb=0.5,cb=0.75)\n",
    "\n",
    "    loss = log_loss(val_y, preds)\n",
    "    \n",
    "    cv_scores.append(loss)\n",
    "    cv_result.append(result_dict)\n",
    "    i+=1\n",
    "    print 'loss for the turn '+str(i)+' is '+str(loss)\n",
    "    \n",
    "print 'The mean of the cv_scores is:'\n",
    "print np.mean(cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1197    0.504237\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "cvResult = CVstatistics(cv_result,'mlogloss')\n",
    "\n",
    "meanTestError = cvResult.result.filter(like='test').mean(axis=1)\n",
    "\n",
    "print meanTestError[meanTestError==np.min(meanTestError)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['knn4_high',\n",
       " 'knn4_medium',\n",
       " 'knn4_low',\n",
       " 'knn8_high',\n",
       " 'knn8_medium',\n",
       " 'knn8_low',\n",
       " 'knn16_high',\n",
       " 'knn16_medium',\n",
       " 'knn16_low',\n",
       " 'knn32_high',\n",
       " 'knn32_medium',\n",
       " 'knn32_low',\n",
       " 'xgb142_high',\n",
       " 'xgb142_medium',\n",
       " 'xgb142_low',\n",
       " 'et1000mf140_high',\n",
       " 'et1000mf140_medium',\n",
       " 'et1000mf140_low',\n",
       " 'loglrC03_high',\n",
       " 'loglrC03_medium',\n",
       " 'loglrC03_low',\n",
       " 'lrl2C3_high',\n",
       " 'lrl2C3_medium',\n",
       " 'lrl2C3_low',\n",
       " 'rf1000mf70_high',\n",
       " 'rf1000mf70_medium',\n",
       " 'rf1000mf70_low',\n",
       " 'ann_high',\n",
       " 'ann_medium',\n",
       " 'ann_low',\n",
       " 'lgb145_high',\n",
       " 'lgb145_medium',\n",
       " 'lgb145_low']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_X, test_X = meta_train[meta_features].as_matrix(), meta_test[meta_features].as_matrix()\n",
    "\n",
    "preds, model = runXGB(train_X, meta_train_y, test_X,\n",
    "num_rounds = 1200, eta = 0.01,max_depth = 3,verbose_eval=100,\n",
    "                     sb=0.5,cb=0.75)\n",
    "\n",
    "out_df = pd.DataFrame(preds)\n",
    "out_df.columns = [\"high\", \"medium\", \"low\"]\n",
    "#out_df.to_json('stack-.json')\n",
    "out_df[\"listing_id\"] = test_listing.values\n",
    "out_df.to_csv(\"stack-beta-0.01eta-3mdsb5cb7.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knn4 knn4_high\n",
      "knn4 knn4_medium\n",
      "knn8 knn8_high\n",
      "knn8 knn8_medium\n",
      "knn16 knn16_high\n",
      "knn16 knn16_medium\n",
      "knn32 knn32_high\n",
      "knn32 knn32_medium\n",
      "xgb142 xgb142_high\n",
      "xgb142 xgb142_medium\n",
      "et1000mf140 et1000mf140_high\n",
      "et1000mf140 et1000mf140_medium\n",
      "loglrC03 loglrC03_high\n",
      "loglrC03 loglrC03_medium\n",
      "lrl2C3 lrl2C3_high\n",
      "lrl2C3 lrl2C3_medium\n",
      "rf1000mf70 rf1000mf70_high\n",
      "rf1000mf70 rf1000mf70_medium\n",
      "ann ann_high\n",
      "ann ann_medium\n",
      "lgb145 lgb145_high\n",
      "lgb145 lgb145_medium\n"
     ]
    }
   ],
   "source": [
    "#model_list=['knn4','knn8','knn16','knn32','xgb142','et1000mf140','loglrC03','lrl1C1','lrl2C3','rf1000mf70','nn','lgbm'\n",
    "#           ,'lr4','loglr','et2000','rf2000','lgb145']\n",
    "meta_features = []\n",
    "chosen_model=['knn4','knn8','knn16','knn32','xgb142','et1000mf140','loglrC03','lrl2C3','rf1000mf70','ann','lgb145']\n",
    "#chosen_model=['knn4','knn8','knn16','knn32','xgb142','et1000mf140','loglr','lrl1C1','rf1000mf70','ann','lgbm']\n",
    "for feature in meta_train:\n",
    "    for model in chosen_model:\n",
    "        if model in feature and 'low' not in feature:\n",
    "            print model,feature\n",
    "            meta_features.append(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:1.02146\ttest-mlogloss:1.02165\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.49262\ttest-mlogloss:0.502082\n",
      "Stopping. Best iteration:\n",
      "[146]\ttrain-mlogloss:0.48598\ttest-mlogloss:0.50165\n",
      "\n",
      "loss for the turn 1 is 0.501907494194\n",
      "[0]\ttrain-mlogloss:1.02133\ttest-mlogloss:1.02106\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.493241\ttest-mlogloss:0.497715\n",
      "Stopping. Best iteration:\n",
      "[162]\ttrain-mlogloss:0.484375\ttest-mlogloss:0.497247\n",
      "\n",
      "loss for the turn 2 is 0.497248538329\n",
      "[0]\ttrain-mlogloss:1.02136\ttest-mlogloss:1.021\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.492657\ttest-mlogloss:0.501183\n",
      "Stopping. Best iteration:\n",
      "[100]\ttrain-mlogloss:0.492657\ttest-mlogloss:0.501183\n",
      "\n",
      "loss for the turn 3 is 0.501438852129\n",
      "[0]\ttrain-mlogloss:1.02093\ttest-mlogloss:1.02182\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.490547\ttest-mlogloss:0.511698\n",
      "Stopping. Best iteration:\n",
      "[111]\ttrain-mlogloss:0.488886\ttest-mlogloss:0.511512\n",
      "\n",
      "loss for the turn 4 is 0.511601072764\n",
      "[0]\ttrain-mlogloss:1.02049\ttest-mlogloss:1.02096\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.489432\ttest-mlogloss:0.515458\n",
      "Stopping. Best iteration:\n",
      "[115]\ttrain-mlogloss:0.487077\ttest-mlogloss:0.515325\n",
      "\n",
      "loss for the turn 5 is 0.515543595565\n",
      "The mean of the cv_scores is:\n",
      "0.505547910596\n"
     ]
    }
   ],
   "source": [
    "cv_scores = []\n",
    "cv_result = []\n",
    "\n",
    "i=0        \n",
    "for dev_index, val_index in KF.split(meta_train,meta_train_y): \n",
    "    result_dict = {}\n",
    "\n",
    "    dev_X, val_X = meta_train[meta_features].iloc[dev_index,:].as_matrix(), meta_train[meta_features].iloc[val_index,:].as_matrix()\n",
    "    dev_y, val_y = meta_train_y[dev_index], meta_train_y[val_index]\n",
    "    \n",
    "    preds,model = runXGB(dev_X, dev_y, val_X, val_y,feature_names=meta_features,\\\n",
    "           early_stop = 20,num_rounds=780,eta = 0.1,max_depth=3,cv_dict = result_dict,verbose_eval=100)\n",
    "\n",
    "    loss = log_loss(val_y, preds)\n",
    "    \n",
    "    cv_scores.append(loss)\n",
    "    cv_result.append(result_dict)\n",
    "    i+=1\n",
    "    print 'loss for the turn '+str(i)+' is '+str(loss)\n",
    "    \n",
    "print 'The mean of the cv_scores is:'\n",
    "print np.mean(cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "181    0.497268\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "cvResult = CVstatistics(cv_result,'mlogloss')\n",
    "\n",
    "meanTestError = cvResult.result.filter(like='test').mean(axis=1)\n",
    "\n",
    "print meanTestError[meanTestError==np.min(meanTestError)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "high          5.874475e+03\n",
       "medium        1.707263e+04\n",
       "low           5.171307e+04\n",
       "listing_id    5.244067e+11\n",
       "dtype: float32"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(out_df,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knn4 knn4_high\n",
      "knn4 knn4_medium\n",
      "knn8 knn8_high\n",
      "knn8 knn8_medium\n",
      "knn16 knn16_high\n",
      "knn16 knn16_medium\n",
      "knn32 knn32_high\n",
      "knn32 knn32_medium\n",
      "xgb142 xgb142_high\n",
      "xgb142 xgb142_medium\n",
      "et1000mf140 et1000mf140_high\n",
      "et1000mf140 et1000mf140_medium\n",
      "loglrC03 loglrC03_high\n",
      "loglrC03 loglrC03_medium\n",
      "lrl2C3 lrl2C3_high\n",
      "lrl2C3 lrl2C3_medium\n",
      "rf1000mf70 rf1000mf70_high\n",
      "rf1000mf70 rf1000mf70_medium\n",
      "ann ann_high\n",
      "ann ann_medium\n",
      "lgb145 lgb145_high\n",
      "lgb145 lgb145_medium\n"
     ]
    }
   ],
   "source": [
    "#model_list=['knn4','knn8','knn16','knn32','xgb142','et1000mf140','loglrC03','lrl1C1','lrl2C3','rf1000mf70','nn','lgbm'\n",
    "#           ,'lr4','loglr','et2000','rf2000','lgb145']\n",
    "meta_features_explow = []\n",
    "chosen_model=['knn4','knn8','knn16','knn32','xgb142','et1000mf140','loglrC03','lrl2C3','rf1000mf70','ann','lgb145']\n",
    "#chosen_model=['knn4','knn8','knn16','knn32','xgb142','et1000mf140','loglr','lrl1C1','rf1000mf70','ann','lgbm']\n",
    "for feature in meta_train:\n",
    "    for model in chosen_model:\n",
    "        if model in feature and 'low' not in feature:\n",
    "            print model,feature\n",
    "            meta_features.append(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_X, test_X = meta_train[meta_features].as_matrix(), meta_test[meta_features].as_matrix()\n",
    "\n",
    "preds, model = runXGB(train_X, meta_train_y, test_X,\n",
    "num_rounds = 1200, eta = 0.01,max_depth = 3,verbose_eval=100\n",
    "                     ,sb=0.5,cb=0.75)\n",
    "\n",
    "out_df_explow = pd.DataFrame(preds)\n",
    "out_df_explow.columns = [\"high\", \"medium\", \"low\"]\n",
    "#out_df.to_json('stack-.json')\n",
    "out_df_explow[\"listing_id\"] = test_listing.values\n",
    "#out_df.to_csv(\"stack-beta-0.01eta-3mdsb5cb7.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knn4 knn4_high\n",
      "knn4 knn4_low\n",
      "knn8 knn8_high\n",
      "knn8 knn8_low\n",
      "knn16 knn16_high\n",
      "knn16 knn16_low\n",
      "knn32 knn32_high\n",
      "knn32 knn32_low\n",
      "xgb142 xgb142_high\n",
      "xgb142 xgb142_low\n",
      "et1000mf140 et1000mf140_high\n",
      "et1000mf140 et1000mf140_low\n",
      "loglrC03 loglrC03_high\n",
      "loglrC03 loglrC03_low\n",
      "lrl2C3 lrl2C3_high\n",
      "lrl2C3 lrl2C3_low\n",
      "rf1000mf70 rf1000mf70_high\n",
      "rf1000mf70 rf1000mf70_low\n",
      "ann ann_high\n",
      "ann ann_low\n",
      "lgb145 lgb145_high\n",
      "lgb145 lgb145_low\n"
     ]
    }
   ],
   "source": [
    "#model_list=['knn4','knn8','knn16','knn32','xgb142','et1000mf140','loglrC03','lrl1C1','lrl2C3','rf1000mf70','nn','lgbm'\n",
    "#           ,'lr4','loglr','et2000','rf2000','lgb145']\n",
    "meta_features = []\n",
    "chosen_model=['knn4','knn8','knn16','knn32','xgb142','et1000mf140','loglrC03','lrl2C3','rf1000mf70','ann','lgb145']\n",
    "#chosen_model=['knn4','knn8','knn16','knn32','xgb142','et1000mf140','loglr','lrl1C1','rf1000mf70','ann','lgbm']\n",
    "for feature in meta_train:\n",
    "    for model in chosen_model:\n",
    "        if model in feature and 'medium' not in feature:\n",
    "            print model,feature\n",
    "            meta_features.append(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_X, test_X = meta_train[meta_features].as_matrix(), meta_test[meta_features].as_matrix()\n",
    "\n",
    "preds, model = runXGB(train_X, meta_train_y, test_X,\n",
    "num_rounds = 1200, eta = 0.01,max_depth = 3,verbose_eval=100\n",
    "                     ,sb=0.5,cb=0.75)\n",
    "\n",
    "out_df_expmed = pd.DataFrame(preds)\n",
    "out_df_expmed.columns = [\"high\", \"medium\", \"low\"]\n",
    "#out_df.to_json('stack-.json')\n",
    "out_df_expmed[\"listing_id\"] = test_listing.values\n",
    "#out_df.to_csv(\"stack-beta-0.01eta-3mdsb5cb7.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knn4 knn4_medium\n",
      "knn4 knn4_low\n",
      "knn8 knn8_medium\n",
      "knn8 knn8_low\n",
      "knn16 knn16_medium\n",
      "knn16 knn16_low\n",
      "knn32 knn32_medium\n",
      "knn32 knn32_low\n",
      "xgb142 xgb142_medium\n",
      "xgb142 xgb142_low\n",
      "et1000mf140 et1000mf140_medium\n",
      "et1000mf140 et1000mf140_low\n",
      "loglrC03 loglrC03_medium\n",
      "loglrC03 loglrC03_low\n",
      "lrl2C3 lrl2C3_medium\n",
      "lrl2C3 lrl2C3_low\n",
      "rf1000mf70 rf1000mf70_medium\n",
      "rf1000mf70 rf1000mf70_low\n",
      "ann ann_medium\n",
      "ann ann_low\n",
      "lgb145 lgb145_medium\n",
      "lgb145 lgb145_low\n"
     ]
    }
   ],
   "source": [
    "#model_list=['knn4','knn8','knn16','knn32','xgb142','et1000mf140','loglrC03','lrl1C1','lrl2C3','rf1000mf70','nn','lgbm'\n",
    "#           ,'lr4','loglr','et2000','rf2000','lgb145']\n",
    "meta_features = []\n",
    "chosen_model=['knn4','knn8','knn16','knn32','xgb142','et1000mf140','loglrC03','lrl2C3','rf1000mf70','ann','lgb145']\n",
    "#chosen_model=['knn4','knn8','knn16','knn32','xgb142','et1000mf140','loglr','lrl1C1','rf1000mf70','ann','lgbm']\n",
    "for feature in meta_train:\n",
    "    for model in chosen_model:\n",
    "        if model in feature and 'high' not in feature:\n",
    "            print model,feature\n",
    "            meta_features.append(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_X, test_X = meta_train[meta_features].as_matrix(), meta_test[meta_features].as_matrix()\n",
    "\n",
    "preds, model = runXGB(train_X, meta_train_y, test_X,\n",
    "num_rounds = 1200, eta = 0.01,max_depth = 3,verbose_eval=100\n",
    "                     ,sb=0.5,cb=0.75)\n",
    "\n",
    "out_df_exphi = pd.DataFrame(preds)\n",
    "out_df_exphi.columns = [\"high\", \"medium\", \"low\"]\n",
    "#out_df.to_json('stack-.json')\n",
    "out_df_exphi[\"listing_id\"] = test_listing.values\n",
    "#out_df.to_csv(\"stack-beta-0.01eta-3mdsb5cb7.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_df_avg=pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.99776381, 0.0)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pearsonr(out_df_exphi['low'],out_df_expmed['low'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_df_avg['high']=out_df_exphi['high']+out_df_expmed['high']+out_df_explow['high']\n",
    "out_df_avg['medium']=out_df_exphi['medium']+out_df_expmed['medium']+out_df_explow['medium']\n",
    "out_df_avg['low']=out_df_exphi['low']+out_df_expmed['low']+out_df_explow['low']\n",
    "out_df_avg[\"listing_id\"] = test_listing.values\n",
    "out_df_avg.to_csv(\"stack-beta-0.01eta-3mdsb5cb7-avg.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "interest_levels = ['low', 'medium', 'high']\n",
    "\n",
    "tau = {\n",
    "    'low': 0.69195995, \n",
    "    'medium': 0.23108864,\n",
    "    'high': 0.07695141, \n",
    "}\n",
    "\n",
    "def correct(df):\n",
    "    y = df[interest_levels].mean()\n",
    "    a = [tau[k] / y[k]  for k in interest_levels]\n",
    "    print a\n",
    "\n",
    "    def f(p):\n",
    "        for k in range(len(interest_levels)):\n",
    "            p[k] *= a[k]\n",
    "        return p / p.sum()\n",
    "\n",
    "    df_correct = df.copy()\n",
    "    df_correct[interest_levels] = df_correct[interest_levels].apply(f, axis=1)\n",
    "\n",
    "    y = df_correct[interest_levels].mean()\n",
    "    a = [tau[k] / y[k]  for k in interest_levels]\n",
    "    print a\n",
    "\n",
    "    return df_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.33296415556942704, 0.33679921014048969, 0.32652470184604393]\n",
      "[1.0000620707379397, 1.0008657237176575, 0.99667484535127282]\n"
     ]
    }
   ],
   "source": [
    "out_df = correct(out_df_avg)\n",
    "out_df.to_csv(\"stack-beta-0.01eta-3mdsb5cb7-avg.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model_list=['knn4','knn8','knn16','knn32','xgb142','et1000mf140','loglrC03','lrl1C1','lrl2C3','rf1000mf70','nn','lgbm'\n",
    "#           ,'lr4','loglr','et2000','rf2000','lgb145']\n",
    "meta_features_explow = []\n",
    "meta_features_expmed = []\n",
    "meta_features_exphi = []\n",
    "chosen_model=['knn4','knn8','knn16','knn32','xgb142','et1000mf140','loglrC03','lrl2C3','rf1000mf70','ann','lgb145']\n",
    "#chosen_model=['knn4','knn8','knn16','knn32','xgb142','et1000mf140','loglr','lrl1C1','rf1000mf70','ann','lgbm']\n",
    "for feature in meta_train:\n",
    "    for model in chosen_model:\n",
    "        if model in feature and 'low' not in feature:\n",
    "            meta_features_explow.append(feature)\n",
    "        if model in feature and 'medium' not in feature:\n",
    "            meta_features_expmed.append(feature)\n",
    "        if model in feature and 'high' not in feature:\n",
    "            meta_features_exphi.append(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TKF=StratifiedKFold(5,shuffle=True,random_state = 3212)\n",
    "out_dfs=[]\n",
    "for train_id,test_id in TKF.split(meta_train,meta_train_y): \n",
    "    \n",
    "    train_X, test_X = meta_train[meta_features_explow].iloc[train_id].as_matrix(), meta_test[meta_features_explow].as_matrix()\n",
    "\n",
    "    preds, model = runXGB(train_X, meta_train_y[train_id], test_X,\n",
    "    num_rounds = 1200, eta = 0.01,max_depth = 3,verbose_eval=100\n",
    "                     ,sb=0.5,cb=0.75)\n",
    "\n",
    "    out_df_explow = pd.DataFrame(preds)\n",
    "    out_df_explow.columns = [\"high\", \"medium\", \"low\"]\n",
    "    out_df_explow[\"listing_id\"] = test_listing.values\n",
    "    \n",
    "    out_dfs.append(out_df_explow)\n",
    "    \n",
    "    train_X, test_X = meta_train[meta_features_expmed].iloc[train_id].as_matrix(), meta_test[meta_features_expmed].as_matrix()\n",
    "\n",
    "    preds, model = runXGB(train_X, meta_train_y[train_id],test_X,\n",
    "    num_rounds = 1200, eta = 0.01,max_depth = 3,verbose_eval=100\n",
    "                     ,sb=0.5,cb=0.75)\n",
    "\n",
    "    out_df_expmed = pd.DataFrame(preds)\n",
    "    out_df_expmed.columns = [\"high\", \"medium\", \"low\"]\n",
    "    out_df_expmed[\"listing_id\"] = test_listing.values\n",
    "    \n",
    "    out_dfs.append(out_df_expmed)\n",
    "    \n",
    "    train_X, test_X = meta_train[meta_features_exphi].iloc[train_id].as_matrix(), meta_test[meta_features_exphi].as_matrix()\n",
    "\n",
    "    preds, model = runXGB(train_X, meta_train_y[train_id], test_X,\n",
    "    num_rounds = 1200, eta = 0.01,max_depth = 3,verbose_eval=100\n",
    "                     ,sb=0.5,cb=0.75)\n",
    "\n",
    "    out_df_exphi = pd.DataFrame(preds)\n",
    "    out_df_exphi.columns = [\"high\", \"medium\", \"low\"]\n",
    "    out_df_exphi[\"listing_id\"] = test_listing.values\n",
    "    \n",
    "    out_dfs.append(out_df_exphi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(out_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74659"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([0 for i in range(len(out_dfs[0]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_df_avg2=pd.DataFrame()\n",
    "out_df_avg2['high'] =[0 for i in range(len(out_dfs[0]))]\n",
    "out_df_avg2['medium'] =[0 for i in range(len(out_dfs[0]))]\n",
    "out_df_avg2['low'] =[0 for i in range(len(out_dfs[0]))]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(out_dfs)):\n",
    "    out_df_avg2['high']+=out_dfs[0]['high']\n",
    "    out_df_avg2['medium']+=out_dfs[0]['medium']\n",
    "    out_df_avg2['low']+=out_dfs[0]['low']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_df_avg2['high']=out_df_avg2['high']/15\n",
    "out_df_avg2['medium']=out_df_avg2['medium']/15\n",
    "out_df_avg2['low']=out_df_avg2['low']/15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out_df_avg2[\"listing_id\"] = test_listing.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_df_avg2.to_csv(\"stack-beta-0.01eta-3mdsb5cb7-bagging.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
